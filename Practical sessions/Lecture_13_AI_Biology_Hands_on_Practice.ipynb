{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¬ AI Models and Biological Understanding: Hands-on Practice\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand protein sequence representation and embeddings\n",
    "- Practice using pre-trained biological language models\n",
    "- Explore AlphaFold structure prediction concepts\n",
    "- Analyze mutation effects using AI models\n",
    "\n",
    "## Practice Structure (4 Quick Labs - 30-45 minutes total)\n",
    "### Part 1: Foundation Models\n",
    "1. Protein Sequence as Language - Tokenization and Encoding\n",
    "2. Using ESM (Evolutionary Scale Modeling) Embeddings\n",
    "\n",
    "### Part 2: Biological Applications\n",
    "3. Protein Property Prediction from Sequence\n",
    "4. Visualizing Mutation Effects\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0. Environment Setup and Library Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if needed)\n",
    "# !pip install biopython numpy pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print('âœ… Libraries loaded successfully!')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Foundation Models\n",
    "\n",
    "Just like natural language has words and grammar, biological sequences (DNA, RNA, proteins) can be treated as a language that AI models can learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: Protein Sequence as Language - Tokenization and Encoding ðŸ§ª\n",
    "\n",
    "### ðŸ“š Concept Explanation\n",
    "**Proteins are composed of 20 amino acids:**\n",
    "- Each amino acid is represented by a single letter (A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y)\n",
    "- Protein sequences are like sentences: `MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQ`\n",
    "- AI models can learn patterns from these sequences\n",
    "\n",
    "**Key Approaches:**\n",
    "- **Character-level encoding**: Each amino acid â†’ one token\n",
    "- **K-mer encoding**: Overlapping subsequences (e.g., 3-mers: MKT, KTA, TAY, ...)\n",
    "- **Learned embeddings**: Transform amino acids into high-dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Define sample protein sequences\n",
    "proteins = {\n",
    "    'Protein_A': 'MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQAPILSRVGDGTQDNLSGAEKAVQ',\n",
    "    'Protein_B': 'MKWVTFISLLFLFSSAYSRGVFRRDAHKSEVAHRFKDLGEENFKALVLIAFAQYLQ',\n",
    "    'Protein_C': 'MNIFEMLRIDEGLRLKIYKDTEGYYTIGIGHLLTKSPSLNAAKSELDKAIGRNTNG'\n",
    "}\n",
    "\n",
    "print(\"ðŸ§¬ Sample Protein Sequences:\")\n",
    "print(\"=\" * 70)\n",
    "for name, seq in proteins.items():\n",
    "    print(f\"{name}: {seq[:30]}... (length: {len(seq)})\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Character-level tokenization\n",
    "def tokenize_protein(sequence):\n",
    "    \"\"\"Tokenize protein sequence at character level\"\"\"\n",
    "    return list(sequence)\n",
    "\n",
    "# Amino acid vocabulary (20 standard amino acids)\n",
    "amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "aa_to_idx = {aa: idx for idx, aa in enumerate(amino_acids)}\n",
    "idx_to_aa = {idx: aa for aa, idx in aa_to_idx.items()}\n",
    "\n",
    "print(\"\\nðŸ“ Tokenization Example:\")\n",
    "example_seq = proteins['Protein_A'][:20]\n",
    "tokens = tokenize_protein(example_seq)\n",
    "print(f\"Original: {example_seq}\")\n",
    "print(f\"Tokens:   {tokens}\")\n",
    "print(f\"\\nToken IDs: {[aa_to_idx[aa] for aa in tokens]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Amino acid composition analysis\n",
    "def analyze_composition(sequence):\n",
    "    \"\"\"Analyze amino acid composition\"\"\"\n",
    "    composition = {aa: 0 for aa in amino_acids}\n",
    "    for aa in sequence:\n",
    "        if aa in composition:\n",
    "            composition[aa] += 1\n",
    "    \n",
    "    # Convert to percentages\n",
    "    total = len(sequence)\n",
    "    composition_pct = {aa: (count/total)*100 for aa, count in composition.items()}\n",
    "    return composition_pct\n",
    "\n",
    "# Visualize composition\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for idx, (name, seq) in enumerate(proteins.items()):\n",
    "    comp = analyze_composition(seq)\n",
    "    \n",
    "    # Sort by frequency\n",
    "    sorted_comp = dict(sorted(comp.items(), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    axes[idx].bar(sorted_comp.keys(), sorted_comp.values(), alpha=0.7)\n",
    "    axes[idx].set_title(f'{name}\\nAmino Acid Composition', fontweight='bold')\n",
    "    axes[idx].set_xlabel('Amino Acid')\n",
    "    axes[idx].set_ylabel('Percentage (%)')\n",
    "    axes[idx].tick_params(axis='x', rotation=0)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Observation:\")\n",
    "print(\"- Each protein has a unique amino acid composition profile\")\n",
    "print(\"- This 'fingerprint' can be used as a simple feature for ML models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Using ESM (Evolutionary Scale Modeling) Embeddings ðŸ¤–\n",
    "\n",
    "### ðŸ“š Concept Explanation\n",
    "**ESM (Evolutionary Scale Modeling)** is a protein language model similar to BERT:\n",
    "- Trained on 250M+ protein sequences\n",
    "- Learns evolutionary patterns without explicit supervision\n",
    "- Produces dense vector representations (embeddings) for each amino acid\n",
    "- These embeddings capture:\n",
    "  - Amino acid properties (hydrophobicity, charge, size)\n",
    "  - Structural preferences (Î±-helix, Î²-sheet)\n",
    "  - Functional constraints\n",
    "\n",
    "**Note:** For this simplified lab, we'll simulate ESM-like embeddings using physicochemical properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Define simplified amino acid properties\n",
    "# Real ESM uses learned embeddings; here we use hand-crafted features\n",
    "aa_properties = {\n",
    "    # Format: [hydrophobicity, charge, size, polarity, aromaticity]\n",
    "    'A': [1.8, 0, 89, 0, 0],   # Alanine\n",
    "    'C': [2.5, 0, 121, 0, 0],  # Cysteine\n",
    "    'D': [-3.5, -1, 133, 1, 0],# Aspartic acid\n",
    "    'E': [-3.5, -1, 147, 1, 0],# Glutamic acid\n",
    "    'F': [2.8, 0, 165, 0, 1],  # Phenylalanine\n",
    "    'G': [-0.4, 0, 75, 0, 0],  # Glycine\n",
    "    'H': [-3.2, 0, 155, 1, 1], # Histidine\n",
    "    'I': [4.5, 0, 131, 0, 0],  # Isoleucine\n",
    "    'K': [-3.9, 1, 146, 1, 0], # Lysine\n",
    "    'L': [3.8, 0, 131, 0, 0],  # Leucine\n",
    "    'M': [1.9, 0, 149, 0, 0],  # Methionine\n",
    "    'N': [-3.5, 0, 132, 1, 0], # Asparagine\n",
    "    'P': [-1.6, 0, 115, 0, 0], # Proline\n",
    "    'Q': [-3.5, 0, 146, 1, 0], # Glutamine\n",
    "    'R': [-4.5, 1, 174, 1, 0], # Arginine\n",
    "    'S': [-0.8, 0, 105, 1, 0], # Serine\n",
    "    'T': [-0.7, 0, 119, 1, 0], # Threonine\n",
    "    'V': [4.2, 0, 117, 0, 0],  # Valine\n",
    "    'W': [-0.9, 0, 204, 0, 1], # Tryptophan\n",
    "    'Y': [-1.3, 0, 181, 1, 1]  # Tyrosine\n",
    "}\n",
    "\n",
    "property_names = ['Hydrophobicity', 'Charge', 'Size', 'Polarity', 'Aromaticity']\n",
    "\n",
    "print(\"ðŸ”¬ Amino Acid Properties (5D simplified embedding):\")\n",
    "print(\"=\" * 70)\n",
    "df_props = pd.DataFrame(aa_properties).T\n",
    "df_props.columns = property_names\n",
    "print(df_props.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Generate sequence embeddings\n",
    "def sequence_to_embedding(sequence, properties_dict):\n",
    "    \"\"\"Convert sequence to embedding by averaging amino acid properties\"\"\"\n",
    "    embeddings = []\n",
    "    for aa in sequence:\n",
    "        if aa in properties_dict:\n",
    "            embeddings.append(properties_dict[aa])\n",
    "    \n",
    "    # Average pooling over sequence\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    return np.zeros(5)\n",
    "\n",
    "# Generate embeddings for all proteins\n",
    "protein_embeddings = {}\n",
    "for name, seq in proteins.items():\n",
    "    protein_embeddings[name] = sequence_to_embedding(seq, aa_properties)\n",
    "\n",
    "print(\"\\nðŸ§  Protein Embeddings (averaged over sequence):\")\n",
    "print(\"=\" * 70)\n",
    "df_embeddings = pd.DataFrame(protein_embeddings).T\n",
    "df_embeddings.columns = property_names\n",
    "print(df_embeddings)\n",
    "\n",
    "# Visualize embeddings\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "df_embeddings.plot(kind='bar', ax=ax, alpha=0.8)\n",
    "ax.set_title('Protein Embeddings: Physicochemical Properties', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Protein', fontsize=12)\n",
    "ax.set_ylabel('Average Property Value', fontsize=12)\n",
    "ax.legend(title='Property', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insight:\")\n",
    "print(\"- These embeddings capture the 'essence' of each protein\")\n",
    "print(\"- Similar proteins will have similar embeddings\")\n",
    "print(\"- Real ESM models use 1280-dimensional learned embeddings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Biological Applications\n",
    "\n",
    "Now let's use these embeddings for practical biological predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3: Protein Property Prediction from Sequence ðŸŽ¯\n",
    "\n",
    "### ðŸ“š Concept Explanation\n",
    "**Goal:** Predict protein properties (e.g., solubility, stability) from sequence\n",
    "\n",
    "**Workflow:**\n",
    "1. **Input:** Protein sequence â†’ Embedding\n",
    "2. **Model:** Simple ML classifier (we'll simulate with rules)\n",
    "3. **Output:** Predicted property (e.g., soluble/insoluble)\n",
    "\n",
    "**Real applications:**\n",
    "- Predicting protein function (GO terms, EC numbers)\n",
    "- Estimating stability and expression levels\n",
    "- Identifying therapeutic candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Simulate protein property dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data\n",
    "n_proteins = 50\n",
    "protein_data = []\n",
    "\n",
    "for i in range(n_proteins):\n",
    "    # Random properties\n",
    "    hydrophobicity = np.random.normal(0, 2)\n",
    "    charge = np.random.normal(0, 0.5)\n",
    "    size = np.random.uniform(100, 180)\n",
    "    \n",
    "    # Simple rule-based solubility prediction\n",
    "    # More hydrophobic proteins tend to be less soluble\n",
    "    solubility_score = -hydrophobicity + np.random.normal(0, 0.5)\n",
    "    is_soluble = 1 if solubility_score > 0 else 0\n",
    "    \n",
    "    protein_data.append({\n",
    "        'Protein_ID': f'Prot_{i+1:03d}',\n",
    "        'Hydrophobicity': hydrophobicity,\n",
    "        'Charge': charge,\n",
    "        'Size': size,\n",
    "        'Solubility_Score': solubility_score,\n",
    "        'Soluble': is_soluble\n",
    "    })\n",
    "\n",
    "df_proteins = pd.DataFrame(protein_data)\n",
    "\n",
    "print(\"ðŸ§ª Simulated Protein Dataset:\")\n",
    "print(df_proteins.head(10))\n",
    "print(f\"\\nTotal proteins: {len(df_proteins)}\")\n",
    "print(f\"Soluble: {df_proteins['Soluble'].sum()} ({df_proteins['Soluble'].sum()/len(df_proteins)*100:.1f}%)\")\n",
    "print(f\"Insoluble: {len(df_proteins) - df_proteins['Soluble'].sum()} ({(1-df_proteins['Soluble'].sum()/len(df_proteins))*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Visualize property-solubility relationship\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Hydrophobicity vs Solubility\n",
    "ax1 = axes[0]\n",
    "colors = ['#e74c3c' if x == 0 else '#2ecc71' for x in df_proteins['Soluble']]\n",
    "ax1.scatter(df_proteins['Hydrophobicity'], df_proteins['Solubility_Score'], \n",
    "           c=colors, alpha=0.6, s=80, edgecolors='black', linewidth=0.5)\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', linewidth=1.5, label='Decision Boundary')\n",
    "ax1.set_xlabel('Hydrophobicity', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Solubility Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Hydrophobicity vs Solubility', fontsize=14, fontweight='bold')\n",
    "ax1.legend(['Decision Boundary', 'Insoluble', 'Soluble'], loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Distribution comparison\n",
    "ax2 = axes[1]\n",
    "soluble = df_proteins[df_proteins['Soluble'] == 1]['Hydrophobicity']\n",
    "insoluble = df_proteins[df_proteins['Soluble'] == 0]['Hydrophobicity']\n",
    "ax2.hist(soluble, bins=15, alpha=0.6, label='Soluble', color='#2ecc71', edgecolor='black')\n",
    "ax2.hist(insoluble, bins=15, alpha=0.6, label='Insoluble', color='#e74c3c', edgecolor='black')\n",
    "ax2.set_xlabel('Hydrophobicity', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Hydrophobicity Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Observation:\")\n",
    "print(\"- More hydrophobic proteins (positive values) tend to be insoluble\")\n",
    "print(\"- This pattern can be learned by ML models!\")\n",
    "print(\"- Real models use complex embeddings from ESM/ProtBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4: Visualizing Mutation Effects ðŸ§¬\n",
    "\n",
    "### ðŸ“š Concept Explanation\n",
    "**Mutations** are changes in amino acid sequence that can affect protein function:\n",
    "- **Point mutation:** Single amino acid change (e.g., Vâ†’F at position 20)\n",
    "- **Effect:** Can be benign, pathogenic, or improve function\n",
    "\n",
    "**AI prediction approach:**\n",
    "1. Get embedding for wild-type sequence\n",
    "2. Get embedding for mutant sequence\n",
    "3. Calculate embedding distance â†’ Predict impact\n",
    "\n",
    "**Applications:**\n",
    "- Clinical variant interpretation (ClinVar, COSMIC)\n",
    "- Protein engineering for stability\n",
    "- Drug resistance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Generate mutations\n",
    "def generate_mutation(sequence, position, new_aa):\n",
    "    \"\"\"Generate a point mutation in sequence\"\"\"\n",
    "    if position < 0 or position >= len(sequence):\n",
    "        raise ValueError(\"Position out of range\")\n",
    "    \n",
    "    seq_list = list(sequence)\n",
    "    old_aa = seq_list[position]\n",
    "    seq_list[position] = new_aa\n",
    "    mutant_seq = ''.join(seq_list)\n",
    "    \n",
    "    return mutant_seq, old_aa\n",
    "\n",
    "# Original sequence\n",
    "original_seq = proteins['Protein_A']\n",
    "print(\"ðŸ§¬ Original Sequence:\")\n",
    "print(f\"   {original_seq}\")\n",
    "print(f\"   Length: {len(original_seq)}\")\n",
    "\n",
    "# Generate several mutations\n",
    "mutations = [\n",
    "    (10, 'D'),  # Position 10: Change to D (Aspartic acid - charged)\n",
    "    (15, 'V'),  # Position 15: Change to V (Valine - hydrophobic)\n",
    "    (25, 'W'),  # Position 25: Change to W (Tryptophan - large aromatic)\n",
    "    (35, 'P'),  # Position 35: Change to P (Proline - helix breaker)\n",
    "]\n",
    "\n",
    "mutation_data = []\n",
    "original_embedding = sequence_to_embedding(original_seq, aa_properties)\n",
    "\n",
    "print(\"\\nðŸ”¬ Generated Mutations:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for pos, new_aa in mutations:\n",
    "    mutant_seq, old_aa = generate_mutation(original_seq, pos, new_aa)\n",
    "    mutant_embedding = sequence_to_embedding(mutant_seq, aa_properties)\n",
    "    \n",
    "    # Calculate embedding distance (Euclidean)\n",
    "    distance = np.linalg.norm(original_embedding - mutant_embedding)\n",
    "    \n",
    "    mutation_name = f\"{old_aa}{pos+1}{new_aa}\"\n",
    "    print(f\"Mutation: {mutation_name:6s} | Distance: {distance:.4f}\")\n",
    "    \n",
    "    mutation_data.append({\n",
    "        'Mutation': mutation_name,\n",
    "        'Position': pos + 1,\n",
    "        'Original_AA': old_aa,\n",
    "        'Mutant_AA': new_aa,\n",
    "        'Embedding_Distance': distance\n",
    "    })\n",
    "\n",
    "df_mutations = pd.DataFrame(mutation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Visualize mutation effects\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Mutation impact bar chart\n",
    "ax1 = axes[0, 0]\n",
    "colors_impact = ['#3498db' if x < 0.1 else '#e67e22' if x < 0.2 else '#e74c3c' \n",
    "                 for x in df_mutations['Embedding_Distance']]\n",
    "ax1.bar(df_mutations['Mutation'], df_mutations['Embedding_Distance'], \n",
    "        color=colors_impact, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax1.axhline(y=0.1, color='orange', linestyle='--', linewidth=1.5, label='Moderate impact')\n",
    "ax1.axhline(y=0.2, color='red', linestyle='--', linewidth=1.5, label='High impact')\n",
    "ax1.set_xlabel('Mutation', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Embedding Distance', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Mutation Impact Analysis', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Property changes\n",
    "ax2 = axes[0, 1]\n",
    "x_pos = np.arange(len(property_names))\n",
    "original_vals = original_embedding\n",
    "mutant_vals = sequence_to_embedding(\n",
    "    generate_mutation(original_seq, mutations[0][0], mutations[0][1])[0], \n",
    "    aa_properties\n",
    ")\n",
    "\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, original_vals, width, label='Original', alpha=0.8, color='#3498db')\n",
    "ax2.bar(x_pos + width/2, mutant_vals, width, label=f'Mutant ({df_mutations.iloc[0][\"Mutation\"]})', \n",
    "        alpha=0.8, color='#e74c3c')\n",
    "ax2.set_xlabel('Property', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Property Changes: {df_mutations.iloc[0][\"Mutation\"]}', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(property_names, rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Position along sequence\n",
    "ax3 = axes[1, 0]\n",
    "positions = df_mutations['Position']\n",
    "impacts = df_mutations['Embedding_Distance']\n",
    "ax3.scatter(positions, impacts, s=200, alpha=0.7, c=colors_impact, edgecolors='black', linewidth=2)\n",
    "for i, mutation in enumerate(df_mutations['Mutation']):\n",
    "    ax3.annotate(mutation, (positions.iloc[i], impacts.iloc[i]), \n",
    "                textcoords=\"offset points\", xytext=(0,10), ha='center', fontweight='bold')\n",
    "ax3.set_xlabel('Position in Sequence', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Embedding Distance', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Mutation Position vs Impact', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Amino acid substitution matrix preview\n",
    "ax4 = axes[1, 1]\n",
    "substitution_types = ['Same Property', 'Different Property', 'Opposite Property', 'Radical Change']\n",
    "mutation_counts = [1, 1, 1, 1]  # Simplified example\n",
    "colors_sub = ['#2ecc71', '#3498db', '#e67e22', '#e74c3c']\n",
    "ax4.pie(mutation_counts, labels=substitution_types, colors=colors_sub, \n",
    "        autopct='%1.0f%%', startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\n",
    "ax4.set_title('Mutation Type Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Key Insights:\")\n",
    "print(\"- Larger embedding distance â†’ potentially higher functional impact\")\n",
    "print(\"- Position matters: mutations in functional domains are more critical\")\n",
    "print(\"- Real tools (AlphaMissense, EVE) use deep learning for accurate predictions\")\n",
    "print(\"\\nðŸŽ¯ Clinical Application:\")\n",
    "print(\"- Classify variants: Benign / Uncertain / Likely Pathogenic / Pathogenic\")\n",
    "print(\"- Guide treatment decisions and genetic counseling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "#### Part 1: Foundation Models\n",
    "1. **Protein Sequences as Language**: Tokenization, encoding, and composition analysis\n",
    "2. **Sequence Embeddings**: Converting sequences to feature vectors using physicochemical properties\n",
    "\n",
    "#### Part 2: Biological Applications\n",
    "3. **Property Prediction**: Using embeddings to predict solubility and other protein properties\n",
    "4. **Mutation Analysis**: Quantifying and visualizing the impact of amino acid substitutions\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "âœ… **Biological sequences can be treated as language** - enabling NLP techniques\n",
    "\n",
    "âœ… **Embeddings capture essential information** - from simple properties to complex learned representations\n",
    "\n",
    "âœ… **AI models excel at pattern recognition** - predicting function, stability, and mutation effects\n",
    "\n",
    "âœ… **Real-world impact** - drug discovery, precision medicine, protein engineering\n",
    "\n",
    "### Real Tools to Explore:\n",
    "\n",
    "#### ðŸ§¬ Protein Language Models\n",
    "- **ESM-2** (Meta AI): State-of-the-art protein language model\n",
    "- **ProtBERT**: BERT for proteins\n",
    "- **AlphaFold** (DeepMind): 3D structure prediction\n",
    "\n",
    "#### ðŸ”¬ Web Tools\n",
    "- **ESMFold Server**: Fast structure prediction (https://esmatlas.com)\n",
    "- **AlphaFold Database**: Pre-computed structures for 200M+ proteins\n",
    "- **AlphaMissense**: Pathogenicity prediction for all possible missense variants\n",
    "\n",
    "#### ðŸ’» Python Libraries\n",
    "```python\n",
    "# Install these for advanced work\n",
    "pip install fair-esm  # ESM models\n",
    "pip install biopython  # Sequence manipulation\n",
    "pip install py3Dmol  # 3D structure visualization\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "ðŸš€ **Beginner Level:**\n",
    "- Try the ESMFold web server with your own sequences\n",
    "- Explore the AlphaFold Database\n",
    "- Read about BERT and transformers architecture\n",
    "\n",
    "ðŸŽ“ **Intermediate Level:**\n",
    "- Fine-tune ESM-2 on specific prediction tasks\n",
    "- Implement attention visualization for protein models\n",
    "- Build a simple mutation effect predictor\n",
    "\n",
    "ðŸ”¬ **Advanced Level:**\n",
    "- Train custom protein language models\n",
    "- Integrate structure prediction with function prediction\n",
    "- Develop novel protein designs using generative models\n",
    "\n",
    "### ðŸŒŸ Career Opportunities:\n",
    "\n",
    "This field is rapidly growing with opportunities in:\n",
    "- **Pharmaceutical companies**: Drug discovery and development\n",
    "- **Biotech startups**: AI-driven protein engineering\n",
    "- **Academic research**: Computational biology and bioinformatics\n",
    "- **Healthcare**: Precision medicine and clinical genomics\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Additional Resources:\n",
    "\n",
    "**Papers:**\n",
    "- Jumper et al. (2021) \"Highly accurate protein structure prediction with AlphaFold\" - *Nature*\n",
    "- Lin et al. (2022) \"Evolutionary-scale prediction of atomic-level protein structure with a language model\" - *Science*\n",
    "- Chowdhury et al. (2022) \"Single-sequence protein structure prediction using a language model\" - *Nature Biotechnology*\n",
    "\n",
    "**Tutorials:**\n",
    "- ESM Tutorial: https://github.com/facebookresearch/esm\n",
    "- AlphaFold Colab: https://colab.research.google.com/github/deepmind/alphafold\n",
    "- Protein Data Science Guide: https://www.rosettacommons.org/\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ™ Thank You!\n",
    "\n",
    "Questions? Feedback? Contact: **homin.park@ghent.ac.kr**\n",
    "\n",
    "Happy coding and exploring the fascinating world of AI in biology! ðŸ§¬ðŸ¤–âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
