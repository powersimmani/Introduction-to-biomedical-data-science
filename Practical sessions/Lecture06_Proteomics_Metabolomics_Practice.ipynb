{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Proteomics and Metabolomics: Hands-on Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [Mass Spectrometry Data Simulation](#practice-1-mass-spectrometry-data-simulation)\n",
    "2. [Peptide Mass Calculation](#practice-2-peptide-mass-calculation)\n",
    "3. [Protein Identification Scoring](#practice-3-protein-identification-scoring)\n",
    "4. [Quantitative Proteomics Analysis](#practice-4-quantitative-proteomics-analysis)\n",
    "5. [Metabolite Peak Detection](#practice-5-metabolite-peak-detection)\n",
    "6. [Pathway Enrichment Analysis](#practice-6-pathway-enrichment-analysis)\n",
    "7. [Biomarker Discovery Workflow](#practice-7-biomarker-discovery-workflow)\n",
    "8. [Integration: Multi-omics Data Visualization](#practice-8-integration-multi-omics-data-visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal, stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")\n",
    "print(\"üß¨ Ready for proteomics and metabolomics analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Mass Spectrometry Data Simulation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the structure of MS data\n",
    "- Simulate mass spectra with peaks\n",
    "- Visualize m/z (mass-to-charge ratio) vs intensity\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Mass Spectrum:** A plot showing the abundance (intensity) of ions at different mass-to-charge (m/z) ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Simulate a simple mass spectrum\n",
    "def simulate_mass_spectrum(num_peaks=10, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Simulate a mass spectrum with peaks\n",
    "    \n",
    "    Parameters:\n",
    "    - num_peaks: Number of peptide peaks\n",
    "    - noise_level: Baseline noise level\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate m/z values (300-2000 Da range, typical for peptides)\n",
    "    mz_range = np.linspace(300, 2000, 2000)\n",
    "    \n",
    "    # Initialize spectrum with baseline noise\n",
    "    spectrum = np.random.exponential(noise_level, len(mz_range))\n",
    "    \n",
    "    # Add peptide peaks\n",
    "    peak_positions = np.random.uniform(400, 1800, num_peaks)\n",
    "    peak_intensities = np.random.uniform(5, 50, num_peaks)\n",
    "    peak_widths = np.random.uniform(0.5, 2.0, num_peaks)\n",
    "    \n",
    "    for pos, intensity, width in zip(peak_positions, peak_intensities, peak_widths):\n",
    "        # Add Gaussian peaks\n",
    "        peak = intensity * np.exp(-((mz_range - pos) ** 2) / (2 * width ** 2))\n",
    "        spectrum += peak\n",
    "    \n",
    "    # Create DataFrame\n",
    "    ms_data = pd.DataFrame({\n",
    "        'm/z': mz_range,\n",
    "        'Intensity': spectrum\n",
    "    })\n",
    "    \n",
    "    return ms_data, peak_positions, peak_intensities\n",
    "\n",
    "# Generate and visualize\n",
    "ms_data, peak_pos, peak_int = simulate_mass_spectrum(num_peaks=15)\n",
    "\n",
    "print(\"üìä Mass Spectrum Generated\")\n",
    "print(f\"   - m/z range: {ms_data['m/z'].min():.1f} - {ms_data['m/z'].max():.1f}\")\n",
    "print(f\"   - Number of data points: {len(ms_data)}\")\n",
    "print(f\"   - Number of peaks: {len(peak_pos)}\")\n",
    "print(f\"   - Max intensity: {ms_data['Intensity'].max():.2f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(ms_data['m/z'], ms_data['Intensity'], linewidth=0.8, color='#1E64C8')\n",
    "plt.xlabel('m/z (Mass-to-Charge Ratio)', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Relative Intensity', fontsize=12, fontweight='bold')\n",
    "plt.title('üî¨ Simulated Mass Spectrum (MS1)', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(peak_pos, peak_int, s=100, c='#FF6B6B', alpha=0.6, edgecolors='black', linewidth=1.5)\n",
    "plt.xlabel('Peak m/z', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Peak Intensity', fontsize=12, fontweight='bold')\n",
    "plt.title('üìç Detected Peptide Peaks', fontsize=14, fontweight='bold')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Peptide Mass Calculation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Calculate theoretical peptide masses\n",
    "- Understand amino acid composition\n",
    "- Match theoretical to experimental masses\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Monoisotopic Mass:** The mass calculated using the most abundant isotope of each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Amino acid mass table and peptide mass calculator\n",
    "def calculate_peptide_mass(sequence):\n",
    "    \"\"\"\n",
    "    Calculate the monoisotopic mass of a peptide\n",
    "    \n",
    "    Parameters:\n",
    "    - sequence: Amino acid sequence (e.g., 'PEPTIDE')\n",
    "    \"\"\"\n",
    "    # Monoisotopic masses of amino acids (in Da)\n",
    "    aa_masses = {\n",
    "        'A': 71.037114,  'C': 103.009185, 'D': 115.026943, 'E': 129.042593,\n",
    "        'F': 147.068414, 'G': 57.021464,  'H': 137.058912, 'I': 113.084064,\n",
    "        'K': 128.094963, 'L': 113.084064, 'M': 131.040485, 'N': 114.042927,\n",
    "        'P': 97.052764,  'Q': 128.058578, 'R': 156.101111, 'S': 87.032028,\n",
    "        'T': 101.047679, 'V': 99.068414,  'W': 186.079313, 'Y': 163.063329\n",
    "    }\n",
    "    \n",
    "    # H2O mass (added to form peptide bond)\n",
    "    water_mass = 18.010565\n",
    "    \n",
    "    # Calculate mass\n",
    "    total_mass = water_mass  # Start with water\n",
    "    for aa in sequence.upper():\n",
    "        if aa in aa_masses:\n",
    "            total_mass += aa_masses[aa]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Unknown amino acid: {aa}\")\n",
    "    \n",
    "    return total_mass\n",
    "\n",
    "# Example peptides from trypsin digestion\n",
    "peptides = [\n",
    "    'PEPTIDER',      # Example peptide 1\n",
    "    'MVHLTPEEK',     # From hemoglobin\n",
    "    'LFTGHPETLEK',   # From hemoglobin\n",
    "    'FLASVSTVLTSK',  # From hemoglobin\n",
    "]\n",
    "\n",
    "print(\"üßÆ Peptide Mass Calculator\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "peptide_data = []\n",
    "for peptide in peptides:\n",
    "    mass = calculate_peptide_mass(peptide)\n",
    "    peptide_data.append({\n",
    "        'Sequence': peptide,\n",
    "        'Length': len(peptide),\n",
    "        'Mass (Da)': mass,\n",
    "        'm/z (z=1)': mass + 1.007825,  # Add proton\n",
    "        'm/z (z=2)': (mass + 2 * 1.007825) / 2  # Doubly charged\n",
    "    })\n",
    "\n",
    "df_peptides = pd.DataFrame(peptide_data)\n",
    "print(df_peptides.to_string(index=False))\n",
    "print(\"\\n‚úÖ Mass calculations complete!\")\n",
    "\n",
    "# Visualize charge states\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.barh(df_peptides['Sequence'], df_peptides['Mass (Da)'], color='#4CAF50', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Monoisotopic Mass (Da)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('üíö Peptide Masses', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "width = 0.35\n",
    "x = np.arange(len(df_peptides))\n",
    "ax2.bar(x - width/2, df_peptides['m/z (z=1)'], width, label='z=1 (singly charged)', color='#2196F3', alpha=0.7, edgecolor='black')\n",
    "ax2.bar(x + width/2, df_peptides['m/z (z=2)'], width, label='z=2 (doubly charged)', color='#FF9800', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Peptide', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('m/z', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('‚ö° Charge State Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(range(1, len(df_peptides)+1))\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Protein Identification Scoring\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand peptide-spectrum matching (PSM)\n",
    "- Calculate basic identification scores\n",
    "- Apply false discovery rate (FDR) filtering\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**FDR (False Discovery Rate):** The expected proportion of false positives among identified peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Simulate peptide-spectrum matches with scores\n",
    "def simulate_psm_data(n_target=200, n_decoy=50):\n",
    "    \"\"\"\n",
    "    Simulate PSM (Peptide-Spectrum Match) data with target and decoy matches\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Target PSMs (real matches) - higher scores\n",
    "    target_scores = np.random.beta(8, 2, n_target) * 100  # Skewed towards high scores\n",
    "    target_data = pd.DataFrame({\n",
    "        'PSM_ID': [f'T_{i:04d}' for i in range(n_target)],\n",
    "        'Score': target_scores,\n",
    "        'Type': 'Target'\n",
    "    })\n",
    "    \n",
    "    # Decoy PSMs (false matches) - lower scores\n",
    "    decoy_scores = np.random.beta(2, 5, n_decoy) * 100  # Skewed towards low scores\n",
    "    decoy_data = pd.DataFrame({\n",
    "        'PSM_ID': [f'D_{i:04d}' for i in range(n_decoy)],\n",
    "        'Score': decoy_scores,\n",
    "        'Type': 'Decoy'\n",
    "    })\n",
    "    \n",
    "    # Combine and sort by score\n",
    "    psm_data = pd.concat([target_data, decoy_data], ignore_index=True)\n",
    "    psm_data = psm_data.sort_values('Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return psm_data\n",
    "\n",
    "# 3.2 Calculate FDR\n",
    "def calculate_fdr(psm_data, score_threshold):\n",
    "    \"\"\"\n",
    "    Calculate FDR at a given score threshold\n",
    "    FDR = (# Decoy hits) / (# Target hits)\n",
    "    \"\"\"\n",
    "    filtered = psm_data[psm_data['Score'] >= score_threshold]\n",
    "    n_decoy = (filtered['Type'] == 'Decoy').sum()\n",
    "    n_target = (filtered['Type'] == 'Target').sum()\n",
    "    \n",
    "    if n_target == 0:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    fdr = n_decoy / n_target\n",
    "    return fdr, n_target, n_decoy\n",
    "\n",
    "# Generate data\n",
    "psm_data = simulate_psm_data(n_target=200, n_decoy=50)\n",
    "\n",
    "print(\"üîç Protein Identification Scoring\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total PSMs: {len(psm_data)}\")\n",
    "print(f\"Target PSMs: {(psm_data['Type'] == 'Target').sum()}\")\n",
    "print(f\"Decoy PSMs: {(psm_data['Type'] == 'Decoy').sum()}\")\n",
    "\n",
    "# Calculate FDR at different thresholds\n",
    "thresholds = [50, 60, 70, 80, 90]\n",
    "print(\"\\nüìä FDR at Different Score Thresholds:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "fdr_results = []\n",
    "for thresh in thresholds:\n",
    "    fdr, n_target, n_decoy = calculate_fdr(psm_data, thresh)\n",
    "    fdr_results.append({\n",
    "        'Threshold': thresh,\n",
    "        'FDR': fdr,\n",
    "        'Target_PSMs': n_target,\n",
    "        'Decoy_PSMs': n_decoy\n",
    "    })\n",
    "    print(f\"  Score ‚â• {thresh:3d}: FDR = {fdr:.3f} ({n_target} targets, {n_decoy} decoys)\")\n",
    "\n",
    "# Find threshold for 1% FDR\n",
    "score_range = np.linspace(psm_data['Score'].min(), psm_data['Score'].max(), 100)\n",
    "fdr_curve = [calculate_fdr(psm_data, s)[0] for s in score_range]\n",
    "threshold_1pct = score_range[np.where(np.array(fdr_curve) <= 0.01)[0][0]] if any(np.array(fdr_curve) <= 0.01) else None\n",
    "\n",
    "if threshold_1pct:\n",
    "    print(f\"\\n‚úÖ Score threshold for 1% FDR: {threshold_1pct:.2f}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Cannot achieve 1% FDR with current data\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Plot 1: Score distributions\n",
    "axes[0].hist(psm_data[psm_data['Type']=='Target']['Score'], bins=30, alpha=0.7, \n",
    "             label='Target', color='#4CAF50', edgecolor='black')\n",
    "axes[0].hist(psm_data[psm_data['Type']=='Decoy']['Score'], bins=30, alpha=0.7, \n",
    "             label='Decoy', color='#F44336', edgecolor='black')\n",
    "axes[0].set_xlabel('PSM Score', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('üìä Score Distributions', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: FDR curve\n",
    "axes[1].plot(score_range, fdr_curve, linewidth=2, color='#2196F3')\n",
    "axes[1].axhline(y=0.01, color='red', linestyle='--', linewidth=2, label='1% FDR')\n",
    "if threshold_1pct:\n",
    "    axes[1].axvline(x=threshold_1pct, color='green', linestyle='--', linewidth=2, label=f'Threshold: {threshold_1pct:.1f}')\n",
    "axes[1].set_xlabel('Score Threshold', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('FDR', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('üìà FDR vs Score Threshold', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Number of identifications vs FDR\n",
    "n_targets = [calculate_fdr(psm_data, s)[1] for s in score_range]\n",
    "axes[2].plot(fdr_curve, n_targets, linewidth=2, color='#9C27B0', marker='o', markersize=3)\n",
    "axes[2].axvline(x=0.01, color='red', linestyle='--', linewidth=2, label='1% FDR')\n",
    "axes[2].set_xlabel('FDR', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Number of Target PSMs', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('üéØ PSMs vs FDR', fontsize=14, fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Quantitative Proteomics Analysis\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Compare label-free quantification methods\n",
    "- Analyze protein abundance changes\n",
    "- Identify differentially expressed proteins\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Label-Free Quantification (LFQ):** Comparing protein abundances without isotope labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Simulate quantitative proteomics data\n",
    "def simulate_proteomics_data(n_proteins=100, n_samples_per_group=6):\n",
    "    \"\"\"\n",
    "    Simulate LFQ intensities for control vs treatment\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    protein_names = [f'Protein_{i:03d}' for i in range(n_proteins)]\n",
    "    \n",
    "    # Control group\n",
    "    control_data = np.random.lognormal(mean=10, sigma=1.5, size=(n_proteins, n_samples_per_group))\n",
    "    \n",
    "    # Treatment group (some proteins change)\n",
    "    treatment_data = control_data.copy()\n",
    "    \n",
    "    # Make 20 proteins upregulated\n",
    "    upregulated = np.random.choice(n_proteins, 20, replace=False)\n",
    "    for idx in upregulated:\n",
    "        treatment_data[idx] *= np.random.uniform(1.5, 3.0)\n",
    "    \n",
    "    # Make 20 proteins downregulated\n",
    "    downregulated = np.random.choice([i for i in range(n_proteins) if i not in upregulated], 20, replace=False)\n",
    "    for idx in downregulated:\n",
    "        treatment_data[idx] *= np.random.uniform(0.3, 0.7)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    control_cols = [f'Control_{i+1}' for i in range(n_samples_per_group)]\n",
    "    treatment_cols = [f'Treatment_{i+1}' for i in range(n_samples_per_group)]\n",
    "    \n",
    "    df = pd.DataFrame(\n",
    "        np.column_stack([control_data, treatment_data]),\n",
    "        columns=control_cols + treatment_cols,\n",
    "        index=protein_names\n",
    "    )\n",
    "    \n",
    "    # Add metadata\n",
    "    df['True_Status'] = 'Unchanged'\n",
    "    df.loc[[f'Protein_{i:03d}' for i in upregulated], 'True_Status'] = 'Upregulated'\n",
    "    df.loc[[f'Protein_{i:03d}' for i in downregulated], 'True_Status'] = 'Downregulated'\n",
    "    \n",
    "    return df, control_cols, treatment_cols\n",
    "\n",
    "# Generate data\n",
    "proteomics_df, ctrl_cols, trt_cols = simulate_proteomics_data()\n",
    "\n",
    "print(\"üß™ Quantitative Proteomics Data Generated\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of proteins: {len(proteomics_df)}\")\n",
    "print(f\"Control samples: {len(ctrl_cols)}\")\n",
    "print(f\"Treatment samples: {len(trt_cols)}\")\n",
    "print(f\"\\nTrue differential expression:\")\n",
    "print(proteomics_df['True_Status'].value_counts())\n",
    "\n",
    "# Calculate statistics\n",
    "proteomics_df['Control_Mean'] = proteomics_df[ctrl_cols].mean(axis=1)\n",
    "proteomics_df['Treatment_Mean'] = proteomics_df[trt_cols].mean(axis=1)\n",
    "proteomics_df['Log2_FC'] = np.log2(proteomics_df['Treatment_Mean'] / proteomics_df['Control_Mean'])\n",
    "\n",
    "# T-test\n",
    "p_values = []\n",
    "for idx in proteomics_df.index:\n",
    "    ctrl = proteomics_df.loc[idx, ctrl_cols]\n",
    "    trt = proteomics_df.loc[idx, trt_cols]\n",
    "    _, p = stats.ttest_ind(ctrl, trt)\n",
    "    p_values.append(p)\n",
    "\n",
    "proteomics_df['P_value'] = p_values\n",
    "proteomics_df['-log10(P)'] = -np.log10(proteomics_df['P_value'])\n",
    "\n",
    "# Classify by statistical cutoffs\n",
    "proteomics_df['Significant'] = 'Not Significant'\n",
    "proteomics_df.loc[(proteomics_df['Log2_FC'] > 1) & (proteomics_df['P_value'] < 0.05), 'Significant'] = 'Upregulated'\n",
    "proteomics_df.loc[(proteomics_df['Log2_FC'] < -1) & (proteomics_df['P_value'] < 0.05), 'Significant'] = 'Downregulated'\n",
    "\n",
    "print(\"\\nüìä Statistical Analysis Results:\")\n",
    "print(\"-\" * 60)\n",
    "print(proteomics_df['Significant'].value_counts())\n",
    "\n",
    "# Visualize: Volcano plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Volcano plot\n",
    "colors = {'Not Significant': 'gray', 'Upregulated': '#F44336', 'Downregulated': '#2196F3'}\n",
    "for sig_type, color in colors.items():\n",
    "    data = proteomics_df[proteomics_df['Significant'] == sig_type]\n",
    "    axes[0].scatter(data['Log2_FC'], data['-log10(P)'], \n",
    "                   c=color, label=sig_type, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "axes[0].axhline(y=-np.log10(0.05), color='red', linestyle='--', linewidth=1.5, label='P = 0.05')\n",
    "axes[0].axvline(x=1, color='green', linestyle='--', linewidth=1.5, label='Log2FC = ¬±1')\n",
    "axes[0].axvline(x=-1, color='green', linestyle='--', linewidth=1.5)\n",
    "axes[0].set_xlabel('Log2 Fold Change', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('-Log10 P-value', fontsize=13, fontweight='bold')\n",
    "axes[0].set_title('üåã Volcano Plot', fontsize=15, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Heatmap of top 20 differentially expressed\n",
    "top_de = proteomics_df[proteomics_df['Significant'] != 'Not Significant'].nsmallest(20, 'P_value')\n",
    "heatmap_data = top_de[ctrl_cols + trt_cols]\n",
    "heatmap_data_log = np.log2(heatmap_data + 1)\n",
    "\n",
    "im = axes[1].imshow(heatmap_data_log, aspect='auto', cmap='RdBu_r')\n",
    "axes[1].set_yticks(range(len(top_de)))\n",
    "axes[1].set_yticklabels(top_de.index, fontsize=8)\n",
    "axes[1].set_xticks(range(len(ctrl_cols + trt_cols)))\n",
    "axes[1].set_xticklabels(ctrl_cols + trt_cols, rotation=45, ha='right', fontsize=9)\n",
    "axes[1].set_title('üî• Top 20 Differentially Expressed Proteins', fontsize=15, fontweight='bold')\n",
    "plt.colorbar(im, ax=axes[1], label='Log2 Intensity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Quantitative analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Metabolite Peak Detection\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Detect peaks in LC-MS chromatograms\n",
    "- Extract peak features (m/z, RT, intensity)\n",
    "- Understand signal processing basics\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Extracted Ion Chromatogram (XIC):** Intensity vs retention time for a specific m/z range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Simulate LC-MS chromatogram\n",
    "def simulate_chromatogram(n_peaks=8, noise_level=0.5, duration=20):\n",
    "    \"\"\"\n",
    "    Simulate an LC-MS chromatogram (retention time vs intensity)\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Time points (retention time in minutes)\n",
    "    time = np.linspace(0, duration, 1000)\n",
    "    \n",
    "    # Baseline + noise\n",
    "    signal = np.random.normal(noise_level, noise_level * 0.3, len(time))\n",
    "    \n",
    "    # Add metabolite peaks (Gaussian)\n",
    "    peak_rts = np.random.uniform(2, duration-2, n_peaks)\n",
    "    peak_intensities = np.random.uniform(5, 30, n_peaks)\n",
    "    peak_widths = np.random.uniform(0.15, 0.4, n_peaks)\n",
    "    \n",
    "    for rt, intensity, width in zip(peak_rts, peak_intensities, peak_widths):\n",
    "        peak = intensity * np.exp(-((time - rt) ** 2) / (2 * width ** 2))\n",
    "        signal += peak\n",
    "    \n",
    "    return time, signal, peak_rts, peak_intensities\n",
    "\n",
    "# Generate chromatogram\n",
    "time, signal, true_rts, true_ints = simulate_chromatogram(n_peaks=10)\n",
    "\n",
    "# Detect peaks using scipy\n",
    "peaks, properties = signal.find_peaks(signal, height=2, prominence=1.5, width=5)\n",
    "\n",
    "print(\"üìà LC-MS Chromatogram Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Retention time range: 0 - {time[-1]:.1f} minutes\")\n",
    "print(f\"True number of peaks: {len(true_rts)}\")\n",
    "print(f\"Detected peaks: {len(peaks)}\")\n",
    "\n",
    "# Extract peak features\n",
    "peak_data = []\n",
    "for i, peak_idx in enumerate(peaks):\n",
    "    peak_data.append({\n",
    "        'Peak_ID': i + 1,\n",
    "        'Retention_Time (min)': time[peak_idx],\n",
    "        'Intensity': signal[peak_idx],\n",
    "        'Width': properties['widths'][i] * (time[1] - time[0]),\n",
    "        'Prominence': properties['prominences'][i]\n",
    "    })\n",
    "\n",
    "df_peaks = pd.DataFrame(peak_data)\n",
    "print(\"\\nüéØ Detected Peak Features:\")\n",
    "print(df_peaks.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Full chromatogram\n",
    "axes[0].plot(time, signal, linewidth=1.5, color='#1E64C8', label='XIC Signal')\n",
    "axes[0].plot(time[peaks], signal[peaks], 'ro', markersize=10, label=f'Detected Peaks (n={len(peaks)})')\n",
    "axes[0].scatter(true_rts, true_ints, marker='x', s=200, c='green', linewidths=3, label='True Peaks', zorder=5)\n",
    "axes[0].set_xlabel('Retention Time (min)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Intensity', fontsize=13, fontweight='bold')\n",
    "axes[0].set_title('üìä Extracted Ion Chromatogram (XIC)', fontsize=15, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Peak features\n",
    "colors_map = plt.cm.viridis(np.linspace(0, 1, len(df_peaks)))\n",
    "axes[1].scatter(df_peaks['Retention_Time (min)'], df_peaks['Intensity'], \n",
    "               s=df_peaks['Width']*500, c=colors_map, alpha=0.6, edgecolors='black', linewidth=2)\n",
    "axes[1].set_xlabel('Retention Time (min)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Peak Intensity', fontsize=13, fontweight='bold')\n",
    "axes[1].set_title('üé® Peak Features (size = peak width)', fontsize=15, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "for i, row in df_peaks.iterrows():\n",
    "    if row['Intensity'] > 10:\n",
    "        axes[1].annotate(f\"P{row['Peak_ID']}\", \n",
    "                        xy=(row['Retention_Time (min)'], row['Intensity']),\n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Peak detection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: Pathway Enrichment Analysis\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand pathway analysis concepts\n",
    "- Calculate enrichment scores\n",
    "- Visualize metabolic pathways\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Pathway Enrichment:** Statistical test to determine if a set of metabolites is over-represented in biological pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Simulate pathway enrichment analysis\n",
    "def simulate_pathway_analysis():\n",
    "    \"\"\"\n",
    "    Simulate metabolite-pathway associations and enrichment\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Define pathways\n",
    "    pathways = {\n",
    "        'Glycolysis': ['Glucose', 'Glucose-6-P', 'Fructose-6-P', 'Pyruvate', 'Lactate', 'ATP', 'NADH'],\n",
    "        'TCA Cycle': ['Citrate', 'Isocitrate', 'Alpha-ketoglutarate', 'Succinate', 'Fumarate', 'Malate', 'Oxaloacetate'],\n",
    "        'Fatty Acid Oxidation': ['Palmitoyl-CoA', 'Acetyl-CoA', 'FADH2', 'NADH', 'ATP'],\n",
    "        'Amino Acid Metabolism': ['Glutamate', 'Glutamine', 'Alanine', 'Aspartate', 'Asparagine', 'Serine'],\n",
    "        'Nucleotide Metabolism': ['AMP', 'ADP', 'ATP', 'GMP', 'GDP', 'GTP', 'UMP', 'CMP'],\n",
    "        'Pentose Phosphate': ['Glucose-6-P', 'Ribulose-5-P', 'Ribose-5-P', 'NADPH'],\n",
    "    }\n",
    "    \n",
    "    # Simulated detected metabolites (enriched in Glycolysis and TCA)\n",
    "    detected_metabolites = [\n",
    "        'Glucose', 'Glucose-6-P', 'Pyruvate', 'Lactate', 'ATP',  # Glycolysis\n",
    "        'Citrate', 'Succinate', 'Fumarate', 'Malate',  # TCA\n",
    "        'Glutamate', 'Alanine',  # Amino acids\n",
    "        'Palmitoyl-CoA', 'Unknown-1', 'Unknown-2'  # Others\n",
    "    ]\n",
    "    \n",
    "    return pathways, detected_metabolites\n",
    "\n",
    "# 6.2 Calculate enrichment\n",
    "def calculate_enrichment(pathways, detected):\n",
    "    \"\"\"\n",
    "    Calculate pathway enrichment using hypergeometric test (simplified)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    total_unique = len(set([m for pathway in pathways.values() for m in pathway]))\n",
    "    n_detected = len(detected)\n",
    "    \n",
    "    for pathway_name, pathway_metabolites in pathways.items():\n",
    "        # Count overlap\n",
    "        overlap = set(pathway_metabolites) & set(detected)\n",
    "        n_overlap = len(overlap)\n",
    "        n_pathway = len(pathway_metabolites)\n",
    "        \n",
    "        # Enrichment score (simplified)\n",
    "        expected = (n_detected * n_pathway) / total_unique\n",
    "        enrichment = n_overlap / expected if expected > 0 else 0\n",
    "        \n",
    "        # Hypergeometric p-value (using scipy)\n",
    "        p_value = stats.hypergeom.sf(n_overlap - 1, total_unique, n_pathway, n_detected)\n",
    "        \n",
    "        results.append({\n",
    "            'Pathway': pathway_name,\n",
    "            'Total_in_Pathway': n_pathway,\n",
    "            'Detected': n_overlap,\n",
    "            'Expected': expected,\n",
    "            'Enrichment': enrichment,\n",
    "            'P_value': p_value,\n",
    "            'Metabolites': ', '.join(overlap) if overlap else 'None'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('P_value')\n",
    "\n",
    "# Run analysis\n",
    "pathways, detected = simulate_pathway_analysis()\n",
    "enrichment_results = calculate_enrichment(pathways, detected)\n",
    "\n",
    "print(\"üß¨ Pathway Enrichment Analysis\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total detected metabolites: {len(detected)}\")\n",
    "print(f\"Number of pathways analyzed: {len(pathways)}\")\n",
    "print(\"\\nüìä Enrichment Results:\")\n",
    "print(enrichment_results[['Pathway', 'Detected', 'Expected', 'Enrichment', 'P_value']].to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Enrichment scores\n",
    "enrichment_results_sorted = enrichment_results.sort_values('Enrichment', ascending=True)\n",
    "colors = ['#F44336' if p < 0.05 else '#BDBDBD' for p in enrichment_results_sorted['P_value']]\n",
    "axes[0].barh(enrichment_results_sorted['Pathway'], enrichment_results_sorted['Enrichment'], \n",
    "            color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0].axvline(x=1, color='black', linestyle='--', linewidth=2, label='Expected')\n",
    "axes[0].set_xlabel('Enrichment Score', fontsize=13, fontweight='bold')\n",
    "axes[0].set_title('üìä Pathway Enrichment Scores', fontsize=15, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: -log10(p-value)\n",
    "enrichment_results_sorted['-log10(P)'] = -np.log10(enrichment_results_sorted['P_value'] + 1e-10)\n",
    "colors2 = ['#2196F3' if p < 0.05 else '#BDBDBD' for p in enrichment_results_sorted['P_value']]\n",
    "axes[1].barh(enrichment_results_sorted['Pathway'], enrichment_results_sorted['-log10(P)'], \n",
    "            color=colors2, edgecolor='black', linewidth=1.5)\n",
    "axes[1].axvline(x=-np.log10(0.05), color='red', linestyle='--', linewidth=2, label='P = 0.05')\n",
    "axes[1].set_xlabel('-Log10(P-value)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_title('üìà Statistical Significance', fontsize=15, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Pathway analysis complete!\")\n",
    "print(f\"\\nüéØ Significantly enriched pathways (P < 0.05):\")\n",
    "sig_pathways = enrichment_results[enrichment_results['P_value'] < 0.05]\n",
    "for _, row in sig_pathways.iterrows():\n",
    "    print(f\"  ‚Ä¢ {row['Pathway']}: {row['Detected']} metabolites (P = {row['P_value']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 7: Biomarker Discovery Workflow\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Build a classification model for biomarker discovery\n",
    "- Perform feature selection\n",
    "- Evaluate diagnostic performance with ROC curves\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**ROC Curve:** Receiver Operating Characteristic - plots sensitivity vs (1-specificity) to evaluate classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Simulate clinical metabolomics data\n",
    "def simulate_clinical_data(n_samples=100, n_metabolites=50):\n",
    "    \"\"\"\n",
    "    Simulate metabolomics data for healthy vs disease groups\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate features\n",
    "    n_healthy = n_samples // 2\n",
    "    n_disease = n_samples - n_healthy\n",
    "    \n",
    "    # Most metabolites are similar between groups\n",
    "    healthy_data = np.random.normal(10, 2, (n_healthy, n_metabolites))\n",
    "    disease_data = np.random.normal(10, 2, (n_disease, n_metabolites))\n",
    "    \n",
    "    # But 10 metabolites are discriminative biomarkers\n",
    "    biomarker_indices = np.random.choice(n_metabolites, 10, replace=False)\n",
    "    for idx in biomarker_indices:\n",
    "        # Disease samples have different levels\n",
    "        disease_data[:, idx] += np.random.uniform(3, 8)\n",
    "    \n",
    "    # Combine data\n",
    "    X = np.vstack([healthy_data, disease_data])\n",
    "    y = np.array([0] * n_healthy + [1] * n_disease)  # 0=Healthy, 1=Disease\n",
    "    \n",
    "    # Create feature names\n",
    "    feature_names = [f'Metabolite_{i+1}' for i in range(n_metabolites)]\n",
    "    \n",
    "    return X, y, feature_names, biomarker_indices\n",
    "\n",
    "# Generate data\n",
    "X, y, feature_names, true_biomarkers = simulate_clinical_data(n_samples=120, n_metabolites=50)\n",
    "\n",
    "print(\"üè• Clinical Biomarker Discovery\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"  Healthy: {(y == 0).sum()}\")\n",
    "print(f\"  Disease: {(y == 1).sum()}\")\n",
    "print(f\"Total metabolites: {X.shape[1]}\")\n",
    "print(f\"True biomarkers (simulated): {len(true_biomarkers)}\")\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Feature importance\n",
    "importances = clf.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nüî¨ Top 10 Important Features (Potential Biomarkers):\")\n",
    "print(feature_importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"\\nüìà Model Performance:\")\n",
    "print(f\"  ROC AUC: {roc_auc:.3f}\")\n",
    "print(f\"  Accuracy: {(y_pred == y_test).mean():.3f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nüìä Confusion Matrix:\")\n",
    "print(f\"  True Negatives:  {cm[0, 0]}\")\n",
    "print(f\"  False Positives: {cm[0, 1]}\")\n",
    "print(f\"  False Negatives: {cm[1, 0]}\")\n",
    "print(f\"  True Positives:  {cm[1, 1]}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Feature importance\n",
    "top_features = feature_importance_df.head(15)\n",
    "axes[0, 0].barh(top_features['Feature'], top_features['Importance'], \n",
    "               color='#4CAF50', edgecolor='black', linewidth=1.5)\n",
    "axes[0, 0].set_xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('üî¨ Top 15 Feature Importances', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: ROC curve\n",
    "axes[0, 1].plot(fpr, tpr, color='#2196F3', linewidth=3, label=f'ROC (AUC = {roc_auc:.3f})')\n",
    "axes[0, 1].plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "axes[0, 1].fill_between(fpr, tpr, alpha=0.3, color='#2196F3')\n",
    "axes[0, 1].set_xlabel('False Positive Rate (1 - Specificity)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('True Positive Rate (Sensitivity)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('üìà ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(loc='lower right', fontsize=11)\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Confusion matrix heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, \n",
    "           xticklabels=['Healthy', 'Disease'], yticklabels=['Healthy', 'Disease'],\n",
    "           ax=axes[1, 0], linewidths=2, linecolor='black')\n",
    "axes[1, 0].set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('üìä Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 4: Predicted probabilities distribution\n",
    "healthy_probs = y_pred_proba[y_test == 0]\n",
    "disease_probs = y_pred_proba[y_test == 1]\n",
    "axes[1, 1].hist(healthy_probs, bins=15, alpha=0.7, label='Healthy', color='#4CAF50', edgecolor='black')\n",
    "axes[1, 1].hist(disease_probs, bins=15, alpha=0.7, label='Disease', color='#F44336', edgecolor='black')\n",
    "axes[1, 1].axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Threshold')\n",
    "axes[1, 1].set_xlabel('Predicted Probability (Disease)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('üéØ Prediction Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Biomarker discovery analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 8: Integration - Multi-omics Data Visualization\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Integrate proteomics and metabolomics data\n",
    "- Perform PCA for dimensionality reduction\n",
    "- Create comprehensive multi-omics visualizations\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Multi-omics Integration:** Combining different layers of biological data (proteins, metabolites) for holistic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Simulate integrated multi-omics dataset\n",
    "def simulate_multiomics_data(n_samples=60):\n",
    "    \"\"\"\n",
    "    Simulate combined proteomics and metabolomics data\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Three groups: Control, Treatment_A, Treatment_B\n",
    "    n_per_group = n_samples // 3\n",
    "    \n",
    "    # Proteomics data (30 proteins)\n",
    "    proteins_ctrl = np.random.normal(10, 1.5, (n_per_group, 30))\n",
    "    proteins_trtA = np.random.normal(12, 1.5, (n_per_group, 30))\n",
    "    proteins_trtB = np.random.normal(8, 1.5, (n_per_group, 30))\n",
    "    \n",
    "    # Metabolomics data (40 metabolites)\n",
    "    metabolites_ctrl = np.random.normal(5, 1, (n_per_group, 40))\n",
    "    metabolites_trtA = np.random.normal(6, 1, (n_per_group, 40))\n",
    "    metabolites_trtB = np.random.normal(4, 1, (n_per_group, 40))\n",
    "    \n",
    "    # Combine omics layers\n",
    "    X_proteins = np.vstack([proteins_ctrl, proteins_trtA, proteins_trtB])\n",
    "    X_metabolites = np.vstack([metabolites_ctrl, metabolites_trtA, metabolites_trtB])\n",
    "    X_integrated = np.hstack([X_proteins, X_metabolites])\n",
    "    \n",
    "    # Labels\n",
    "    groups = ['Control'] * n_per_group + ['Treatment_A'] * n_per_group + ['Treatment_B'] * n_per_group\n",
    "    \n",
    "    # Feature names\n",
    "    protein_names = [f'Protein_{i+1}' for i in range(30)]\n",
    "    metabolite_names = [f'Metabolite_{i+1}' for i in range(40)]\n",
    "    feature_names = protein_names + metabolite_names\n",
    "    \n",
    "    return X_integrated, X_proteins, X_metabolites, groups, feature_names\n",
    "\n",
    "# Generate data\n",
    "X_multi, X_prot, X_metab, groups, features = simulate_multiomics_data(n_samples=90)\n",
    "\n",
    "print(\"üî¨ Multi-omics Integration Analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total samples: {len(X_multi)}\")\n",
    "print(f\"  Control: {groups.count('Control')}\")\n",
    "print(f\"  Treatment A: {groups.count('Treatment_A')}\")\n",
    "print(f\"  Treatment B: {groups.count('Treatment_B')}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "print(f\"  Proteins: {X_prot.shape[1]}\")\n",
    "print(f\"  Metabolites: {X_metab.shape[1]}\")\n",
    "print(f\"  Total integrated: {X_multi.shape[1]}\")\n",
    "\n",
    "# PCA on integrated data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_multi)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"\\nüìä PCA Results:\")\n",
    "print(f\"  PC1 variance explained: {pca.explained_variance_ratio_[0]:.3f}\")\n",
    "print(f\"  PC2 variance explained: {pca.explained_variance_ratio_[1]:.3f}\")\n",
    "print(f\"  PC3 variance explained: {pca.explained_variance_ratio_[2]:.3f}\")\n",
    "print(f\"  Total variance (3 PCs): {pca.explained_variance_ratio_[:3].sum():.3f}\")\n",
    "\n",
    "# Separate PCA for each omics layer\n",
    "pca_prot = PCA(n_components=2)\n",
    "X_prot_pca = pca_prot.fit_transform(scaler.fit_transform(X_prot))\n",
    "\n",
    "pca_metab = PCA(n_components=2)\n",
    "X_metab_pca = pca_metab.fit_transform(scaler.fit_transform(X_metab))\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Define colors\n",
    "color_map = {'Control': '#4CAF50', 'Treatment_A': '#2196F3', 'Treatment_B': '#FF9800'}\n",
    "colors = [color_map[g] for g in groups]\n",
    "\n",
    "# Plot 1: Integrated PCA (2D)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "for group in ['Control', 'Treatment_A', 'Treatment_B']:\n",
    "    mask = [g == group for g in groups]\n",
    "    ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "               c=color_map[group], label=group, s=100, alpha=0.7, edgecolors='black', linewidth=1.5)\n",
    "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('üåê Integrated Multi-omics PCA', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Scree plot\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "n_components = min(10, len(pca.explained_variance_ratio_))\n",
    "ax2.bar(range(1, n_components+1), pca.explained_variance_ratio_[:n_components], \n",
    "       color='#9C27B0', edgecolor='black', linewidth=1.5, alpha=0.7)\n",
    "ax2.set_xlabel('Principal Component', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Variance Explained', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('üìä Scree Plot', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Proteomics PCA\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "for group in ['Control', 'Treatment_A', 'Treatment_B']:\n",
    "    mask = [g == group for g in groups]\n",
    "    ax3.scatter(X_prot_pca[mask, 0], X_prot_pca[mask, 1], \n",
    "               c=color_map[group], label=group, s=80, alpha=0.7, edgecolors='black', linewidth=1)\n",
    "ax3.set_xlabel('Protein PC1', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Protein PC2', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('üß¨ Proteomics Layer', fontsize=13, fontweight='bold')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Metabolomics PCA\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "for group in ['Control', 'Treatment_A', 'Treatment_B']:\n",
    "    mask = [g == group for g in groups]\n",
    "    ax4.scatter(X_metab_pca[mask, 0], X_metab_pca[mask, 1], \n",
    "               c=color_map[group], label=group, s=80, alpha=0.7, edgecolors='black', linewidth=1)\n",
    "ax4.set_xlabel('Metabolite PC1', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('Metabolite PC2', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('‚öóÔ∏è Metabolomics Layer', fontsize=13, fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# Plot 5: 3D PCA\n",
    "ax5 = fig.add_subplot(gs[1, 2], projection='3d')\n",
    "for group in ['Control', 'Treatment_A', 'Treatment_B']:\n",
    "    mask = [g == group for g in groups]\n",
    "    ax5.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n",
    "               c=color_map[group], label=group, s=60, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "ax5.set_xlabel('PC1', fontsize=10, fontweight='bold')\n",
    "ax5.set_ylabel('PC2', fontsize=10, fontweight='bold')\n",
    "ax5.set_zlabel('PC3', fontsize=10, fontweight='bold')\n",
    "ax5.set_title('üé® 3D PCA View', fontsize=13, fontweight='bold')\n",
    "ax5.legend(loc='best', fontsize=9)\n",
    "\n",
    "# Plot 6: Correlation heatmap (sample selection)\n",
    "ax6 = fig.add_subplot(gs[2, :])\n",
    "# Select 20 random features for visualization\n",
    "selected_features = np.random.choice(X_multi.shape[1], 20, replace=False)\n",
    "correlation_matrix = np.corrcoef(X_scaled[:, selected_features].T)\n",
    "im = ax6.imshow(correlation_matrix, cmap='coolwarm', aspect='auto', vmin=-1, vmax=1)\n",
    "ax6.set_title('üî• Feature Correlation Heatmap (Sample)', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Features', fontsize=11, fontweight='bold')\n",
    "ax6.set_ylabel('Features', fontsize=11, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax6, label='Correlation')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Multi-omics integration complete!\")\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"  ‚Ä¢ The integrated analysis shows clear separation between treatment groups\")\n",
    "print(\"  ‚Ä¢ Both proteomics and metabolomics contribute to the overall pattern\")\n",
    "print(\"  ‚Ä¢ Multi-omics provides more comprehensive biological insights than single-omics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **Mass Spectrometry Basics**: Simulating and visualizing MS data with m/z peaks\n",
    "2. **Peptide Analysis**: Calculating theoretical masses and charge states\n",
    "3. **Protein Identification**: Understanding PSM scoring and FDR control\n",
    "4. **Quantitative Proteomics**: Analyzing differential expression with volcano plots\n",
    "5. **Metabolite Detection**: Peak detection in LC-MS chromatograms\n",
    "6. **Pathway Analysis**: Enrichment testing for biological interpretation\n",
    "7. **Biomarker Discovery**: Building predictive models with ROC analysis\n",
    "8. **Multi-omics Integration**: Combining proteomics and metabolomics with PCA\n",
    "\n",
    "### Key Insights:\n",
    "- Proteomics and metabolomics provide complementary views of biological systems\n",
    "- Statistical methods (t-tests, FDR, ROC curves) are essential for data interpretation\n",
    "- Integration of multiple omics layers enhances biological understanding\n",
    "- Machine learning enables biomarker discovery from high-dimensional data\n",
    "\n",
    "### Real-World Applications:\n",
    "- **Clinical Diagnostics**: Disease biomarker discovery\n",
    "- **Drug Development**: Understanding drug mechanisms and toxicity\n",
    "- **Precision Medicine**: Patient stratification and treatment selection\n",
    "- **Systems Biology**: Mapping cellular networks and pathways\n",
    "\n",
    "### Next Steps:\n",
    "- Explore real datasets from public repositories (PRIDE, MetaboLights)\n",
    "- Learn advanced tools: MaxQuant, MetaboAnalyst, Perseus\n",
    "- Study time-series metabolomics and flux analysis\n",
    "- Integrate with genomics and transcriptomics data\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- **PRIDE Database**: https://www.ebi.ac.uk/pride/\n",
    "- **MetaboLights**: https://www.ebi.ac.uk/metabolights/\n",
    "- **Human Metabolome Database**: https://hmdb.ca/\n",
    "- **KEGG Pathways**: https://www.genome.jp/kegg/pathway.html\n",
    "\n",
    "### üéì Congratulations!\n",
    "You've completed a comprehensive hands-on introduction to proteomics and metabolomics analysis!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
