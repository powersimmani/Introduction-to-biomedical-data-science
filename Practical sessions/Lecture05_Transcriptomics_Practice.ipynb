{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Transcriptomics and Single-Cell Analysis: Hands-on Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to RNA-seq Data](#practice-1-introduction-to-rna-seq-data)\n",
    "2. [Data Normalization Methods](#practice-2-data-normalization-methods)\n",
    "3. [Differential Expression Analysis](#practice-3-differential-expression-analysis)\n",
    "4. [Single-Cell Data Processing](#practice-4-single-cell-data-processing)\n",
    "5. [Dimensionality Reduction (PCA, UMAP)](#practice-5-dimensionality-reduction)\n",
    "6. [Clustering and Cell Type Identification](#practice-6-clustering-and-cell-type-identification)\n",
    "7. [Visualization and Interpretation](#practice-7-visualization-and-interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try importing scanpy for single-cell analysis (optional)\n",
    "try:\n",
    "    import scanpy as sc\n",
    "    print(\"‚úÖ Scanpy available for advanced single-cell analysis\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Scanpy not installed. Install with: pip install scanpy\")\n",
    "    sc = None\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"‚úÖ All core libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Introduction to RNA-seq Data\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the structure of RNA-seq count matrices\n",
    "- Learn about genes √ó samples format\n",
    "- Explore basic data properties\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Count Matrix:** Rows = genes, Columns = samples/cells  \n",
    "**Raw Counts:** Integer values representing the number of reads mapped to each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Create simulated RNA-seq data\n",
    "def create_sample_data():\n",
    "    \"\"\"Generate synthetic bulk RNA-seq data for practice\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Parameters\n",
    "    n_genes = 100\n",
    "    n_samples_control = 5\n",
    "    n_samples_treatment = 5\n",
    "    \n",
    "    # Gene names\n",
    "    gene_names = [f\"Gene_{i:03d}\" for i in range(1, n_genes + 1)]\n",
    "    \n",
    "    # Sample names\n",
    "    control_names = [f\"Control_{i}\" for i in range(1, n_samples_control + 1)]\n",
    "    treatment_names = [f\"Treatment_{i}\" for i in range(1, n_samples_treatment + 1)]\n",
    "    sample_names = control_names + treatment_names\n",
    "    \n",
    "    # Generate count data (Negative Binomial distribution)\n",
    "    # Control samples\n",
    "    control_counts = np.random.negative_binomial(n=10, p=0.3, \n",
    "                                                   size=(n_genes, n_samples_control))\n",
    "    \n",
    "    # Treatment samples (some genes differentially expressed)\n",
    "    treatment_counts = np.random.negative_binomial(n=10, p=0.3, \n",
    "                                                     size=(n_genes, n_samples_treatment))\n",
    "    \n",
    "    # Make first 10 genes upregulated in treatment\n",
    "    treatment_counts[:10, :] = treatment_counts[:10, :] * 3\n",
    "    \n",
    "    # Make genes 10-20 downregulated in treatment\n",
    "    treatment_counts[10:20, :] = treatment_counts[10:20, :] // 3\n",
    "    \n",
    "    # Combine into full count matrix\n",
    "    counts = np.hstack([control_counts, treatment_counts])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    count_df = pd.DataFrame(counts, index=gene_names, columns=sample_names)\n",
    "    \n",
    "    # Create sample metadata\n",
    "    metadata = pd.DataFrame({\n",
    "        'sample': sample_names,\n",
    "        'condition': ['Control'] * n_samples_control + ['Treatment'] * n_samples_treatment,\n",
    "        'batch': [1, 1, 2, 2, 2, 1, 1, 2, 2, 2]\n",
    "    })\n",
    "    \n",
    "    print(\"üìä RNA-seq Count Matrix Created\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Dimensions: {count_df.shape[0]} genes √ó {count_df.shape[1]} samples\")\n",
    "    print(f\"\\nFirst 5 genes √ó 3 samples:\")\n",
    "    print(count_df.iloc[:5, :3])\n",
    "    print(f\"\\nüî¨ Sample Metadata:\")\n",
    "    print(metadata.head())\n",
    "    \n",
    "    return count_df, metadata\n",
    "\n",
    "counts, metadata = create_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Explore data properties\n",
    "def explore_count_data(counts):\n",
    "    \"\"\"Visualize basic properties of count data\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Distribution of counts\n",
    "    axes[0].hist(counts.values.flatten(), bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('Count Value')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Distribution of Raw Counts')\n",
    "    axes[0].set_yscale('log')\n",
    "    \n",
    "    # Library sizes (total counts per sample)\n",
    "    library_sizes = counts.sum(axis=0)\n",
    "    axes[1].bar(range(len(library_sizes)), library_sizes, color='steelblue', alpha=0.7)\n",
    "    axes[1].set_xlabel('Sample Index')\n",
    "    axes[1].set_ylabel('Total Counts')\n",
    "    axes[1].set_title('Library Sizes')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Genes detected per sample\n",
    "    genes_detected = (counts > 0).sum(axis=0)\n",
    "    axes[2].bar(range(len(genes_detected)), genes_detected, color='coral', alpha=0.7)\n",
    "    axes[2].set_xlabel('Sample Index')\n",
    "    axes[2].set_ylabel('Number of Genes')\n",
    "    axes[2].set_title('Genes Detected per Sample')\n",
    "    axes[2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìà Data Summary Statistics:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Mean count per gene: {counts.mean().mean():.2f}\")\n",
    "    print(f\"Median count per gene: {counts.median().median():.2f}\")\n",
    "    print(f\"Zero counts: {(counts == 0).sum().sum()} ({(counts == 0).sum().sum() / counts.size * 100:.1f}%)\")\n",
    "\n",
    "explore_count_data(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Data Normalization Methods\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Implement TPM (Transcripts Per Million) normalization\n",
    "- Compare different normalization strategies\n",
    "- Understand the importance of normalization\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**TPM:** Accounts for gene length and sequencing depth  \n",
    "**DESeq2 size factors:** Median-of-ratios normalization  \n",
    "**Log transformation:** Stabilizes variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Implement normalization methods\n",
    "def normalize_counts(counts):\n",
    "    \"\"\"Apply different normalization methods\"\"\"\n",
    "    \n",
    "    # Method 1: CPM (Counts Per Million)\n",
    "    library_sizes = counts.sum(axis=0)\n",
    "    cpm = counts / library_sizes * 1e6\n",
    "    \n",
    "    # Method 2: Log-transformed CPM (log2(CPM + 1))\n",
    "    log_cpm = np.log2(cpm + 1)\n",
    "    \n",
    "    # Method 3: Z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    z_score = pd.DataFrame(\n",
    "        scaler.fit_transform(counts.T).T,\n",
    "        index=counts.index,\n",
    "        columns=counts.columns\n",
    "    )\n",
    "    \n",
    "    print(\"üîß Normalization Methods Applied\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\n1. CPM (Counts Per Million)\")\n",
    "    print(cpm.iloc[:3, :3])\n",
    "    print(\"\\n2. Log2(CPM + 1)\")\n",
    "    print(log_cpm.iloc[:3, :3])\n",
    "    print(\"\\n3. Z-score Normalization\")\n",
    "    print(z_score.iloc[:3, :3])\n",
    "    \n",
    "    return cpm, log_cpm, z_score\n",
    "\n",
    "cpm, log_cpm, z_score = normalize_counts(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Visualize normalization effects\n",
    "def visualize_normalization(counts, log_cpm):\n",
    "    \"\"\"Compare raw and normalized data\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Raw counts boxplot\n",
    "    axes[0].boxplot([counts[col] for col in counts.columns], \n",
    "                     labels=range(1, len(counts.columns) + 1))\n",
    "    axes[0].set_xlabel('Sample')\n",
    "    axes[0].set_ylabel('Raw Count')\n",
    "    axes[0].set_title('Raw Counts Distribution')\n",
    "    axes[0].set_yscale('log')\n",
    "    \n",
    "    # Normalized counts boxplot\n",
    "    axes[1].boxplot([log_cpm[col] for col in log_cpm.columns],\n",
    "                     labels=range(1, len(log_cpm.columns) + 1))\n",
    "    axes[1].set_xlabel('Sample')\n",
    "    axes[1].set_ylabel('Log2(CPM + 1)')\n",
    "    axes[1].set_title('Normalized Counts Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Normalization reduces technical variation between samples\")\n",
    "\n",
    "visualize_normalization(counts, log_cpm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Differential Expression Analysis\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Perform simple differential expression analysis\n",
    "- Apply statistical tests (t-test)\n",
    "- Correct for multiple testing\n",
    "- Create volcano plots\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Fold Change:** log2(Treatment / Control)  \n",
    "**P-value:** Statistical significance  \n",
    "**FDR:** False Discovery Rate (adjusted p-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Differential expression testing\n",
    "def perform_de_analysis(log_cpm, metadata):\n",
    "    \"\"\"Identify differentially expressed genes\"\"\"\n",
    "    \n",
    "    # Separate control and treatment\n",
    "    control_samples = metadata[metadata['condition'] == 'Control']['sample']\n",
    "    treatment_samples = metadata[metadata['condition'] == 'Treatment']['sample']\n",
    "    \n",
    "    control_data = log_cpm[control_samples]\n",
    "    treatment_data = log_cpm[treatment_samples]\n",
    "    \n",
    "    # Calculate statistics for each gene\n",
    "    results = []\n",
    "    \n",
    "    for gene in log_cpm.index:\n",
    "        # Mean expression\n",
    "        control_mean = control_data.loc[gene].mean()\n",
    "        treatment_mean = treatment_data.loc[gene].mean()\n",
    "        \n",
    "        # Fold change (log2)\n",
    "        log2_fc = treatment_mean - control_mean\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_value = stats.ttest_ind(control_data.loc[gene], \n",
    "                                           treatment_data.loc[gene])\n",
    "        \n",
    "        results.append({\n",
    "            'gene': gene,\n",
    "            'control_mean': control_mean,\n",
    "            'treatment_mean': treatment_mean,\n",
    "            'log2_fc': log2_fc,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    de_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Multiple testing correction (Benjamini-Hochberg)\n",
    "    from scipy.stats import false_discovery_control\n",
    "    de_results['p_adj'] = false_discovery_control(de_results['p_value'])\n",
    "    \n",
    "    # Classify genes\n",
    "    de_results['significant'] = (de_results['p_adj'] < 0.05) & (np.abs(de_results['log2_fc']) > 1)\n",
    "    de_results['direction'] = 'Not Sig'\n",
    "    de_results.loc[(de_results['significant']) & (de_results['log2_fc'] > 1), 'direction'] = 'Up'\n",
    "    de_results.loc[(de_results['significant']) & (de_results['log2_fc'] < -1), 'direction'] = 'Down'\n",
    "    \n",
    "    # Sort by p-value\n",
    "    de_results = de_results.sort_values('p_value')\n",
    "    \n",
    "    print(\"üî¨ Differential Expression Analysis Results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Total genes tested: {len(de_results)}\")\n",
    "    print(f\"Upregulated (FDR < 0.05, log2FC > 1): {(de_results['direction'] == 'Up').sum()}\")\n",
    "    print(f\"Downregulated (FDR < 0.05, log2FC < -1): {(de_results['direction'] == 'Down').sum()}\")\n",
    "    print(f\"\\nTop 5 upregulated genes:\")\n",
    "    print(de_results[de_results['direction'] == 'Up'][['gene', 'log2_fc', 'p_adj']].head())\n",
    "    \n",
    "    return de_results\n",
    "\n",
    "de_results = perform_de_analysis(log_cpm, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Create volcano plot\n",
    "def create_volcano_plot(de_results):\n",
    "    \"\"\"Visualize differential expression with volcano plot\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Plot points by significance\n",
    "    colors = {'Up': 'red', 'Down': 'blue', 'Not Sig': 'gray'}\n",
    "    \n",
    "    for direction, color in colors.items():\n",
    "        subset = de_results[de_results['direction'] == direction]\n",
    "        plt.scatter(subset['log2_fc'], \n",
    "                   -np.log10(subset['p_value']),\n",
    "                   c=color, \n",
    "                   alpha=0.6, \n",
    "                   s=30,\n",
    "                   label=direction)\n",
    "    \n",
    "    # Add threshold lines\n",
    "    plt.axhline(y=-np.log10(0.05), color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.axvline(x=1, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    plt.axvline(x=-1, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    plt.xlabel('Log2 Fold Change', fontsize=12)\n",
    "    plt.ylabel('-Log10 P-value', fontsize=12)\n",
    "    plt.title('Volcano Plot: Treatment vs Control', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüåã Volcano plot shows:\")\n",
    "    print(\"   - X-axis: Log2 fold change (effect size)\")\n",
    "    print(\"   - Y-axis: -Log10 p-value (significance)\")\n",
    "    print(\"   - Red: Upregulated genes\")\n",
    "    print(\"   - Blue: Downregulated genes\")\n",
    "\n",
    "create_volcano_plot(de_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Single-Cell Data Processing\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Create simulated single-cell data\n",
    "- Apply QC filtering\n",
    "- Understand sparsity in scRNA-seq\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Sparsity:** Many zero values in single-cell data  \n",
    "**QC Metrics:** nGenes, nUMI, %mitochondrial  \n",
    "**Doublets:** Two cells captured in one droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Generate single-cell data\n",
    "def create_single_cell_data():\n",
    "    \"\"\"Simulate single-cell RNA-seq data with multiple cell types\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_genes = 200\n",
    "    n_cells = 300\n",
    "    \n",
    "    # Create three cell types with different expression patterns\n",
    "    n_type1 = 100  # Cell type 1\n",
    "    n_type2 = 100  # Cell type 2\n",
    "    n_type3 = 100  # Cell type 3\n",
    "    \n",
    "    # Gene names\n",
    "    gene_names = [f\"Gene_{i:03d}\" for i in range(1, n_genes + 1)]\n",
    "    \n",
    "    # Cell type 1: High expression of genes 1-50\n",
    "    type1 = np.random.poisson(lam=3, size=(n_genes, n_type1))\n",
    "    type1[:50, :] = np.random.poisson(lam=10, size=(50, n_type1))\n",
    "    \n",
    "    # Cell type 2: High expression of genes 51-100\n",
    "    type2 = np.random.poisson(lam=3, size=(n_genes, n_type2))\n",
    "    type2[50:100, :] = np.random.poisson(lam=10, size=(50, n_type2))\n",
    "    \n",
    "    # Cell type 3: High expression of genes 101-150\n",
    "    type3 = np.random.poisson(lam=3, size=(n_genes, n_type3))\n",
    "    type3[100:150, :] = np.random.poisson(lam=10, size=(50, n_type3))\n",
    "    \n",
    "    # Combine\n",
    "    sc_counts = np.hstack([type1, type2, type3])\n",
    "    \n",
    "    # Add sparsity (dropout events)\n",
    "    dropout_mask = np.random.rand(*sc_counts.shape) < 0.5\n",
    "    sc_counts[dropout_mask] = 0\n",
    "    \n",
    "    # Create DataFrame\n",
    "    cell_names = [f\"Cell_{i:03d}\" for i in range(1, n_cells + 1)]\n",
    "    sc_df = pd.DataFrame(sc_counts, index=gene_names, columns=cell_names)\n",
    "    \n",
    "    # Create cell metadata\n",
    "    cell_metadata = pd.DataFrame({\n",
    "        'cell': cell_names,\n",
    "        'true_type': ['Type1'] * n_type1 + ['Type2'] * n_type2 + ['Type3'] * n_type3,\n",
    "        'n_genes': (sc_df > 0).sum(axis=0).values,\n",
    "        'n_counts': sc_df.sum(axis=0).values\n",
    "    })\n",
    "    \n",
    "    print(\"üî¨ Single-Cell Data Created\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Dimensions: {sc_df.shape[0]} genes √ó {sc_df.shape[1]} cells\")\n",
    "    print(f\"Sparsity: {(sc_df == 0).sum().sum() / sc_df.size * 100:.1f}% zeros\")\n",
    "    print(f\"\\nCell types: {cell_metadata['true_type'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return sc_df, cell_metadata\n",
    "\n",
    "sc_counts, cell_metadata = create_single_cell_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Quality control visualization\n",
    "def visualize_qc_metrics(cell_metadata):\n",
    "    \"\"\"Visualize QC metrics for single-cell data\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Number of genes per cell\n",
    "    axes[0].hist(cell_metadata['n_genes'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0].axvline(cell_metadata['n_genes'].median(), color='red', linestyle='--', label='Median')\n",
    "    axes[0].set_xlabel('Number of Genes Detected')\n",
    "    axes[0].set_ylabel('Number of Cells')\n",
    "    axes[0].set_title('Genes per Cell')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Total counts per cell\n",
    "    axes[1].hist(cell_metadata['n_counts'], bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "    axes[1].axvline(cell_metadata['n_counts'].median(), color='red', linestyle='--', label='Median')\n",
    "    axes[1].set_xlabel('Total UMI Counts')\n",
    "    axes[1].set_ylabel('Number of Cells')\n",
    "    axes[1].set_title('UMI Counts per Cell')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    # Scatter: genes vs counts\n",
    "    axes[2].scatter(cell_metadata['n_counts'], cell_metadata['n_genes'], \n",
    "                    alpha=0.6, s=20, color='purple')\n",
    "    axes[2].set_xlabel('Total Counts')\n",
    "    axes[2].set_ylabel('Genes Detected')\n",
    "    axes[2].set_title('Genes vs Counts')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä QC Summary:\")\n",
    "    print(f\"   Median genes per cell: {cell_metadata['n_genes'].median():.0f}\")\n",
    "    print(f\"   Median UMI counts per cell: {cell_metadata['n_counts'].median():.0f}\")\n",
    "\n",
    "visualize_qc_metrics(cell_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Dimensionality Reduction\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Apply PCA for dimensionality reduction\n",
    "- Understand variance explained\n",
    "- Visualize cells in low-dimensional space\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**PCA:** Principal Component Analysis - linear projection  \n",
    "**PC1, PC2:** First and second principal components  \n",
    "**Variance Explained:** How much information each PC captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Perform PCA\n",
    "def perform_pca(sc_counts, cell_metadata):\n",
    "    \"\"\"Apply PCA to single-cell data\"\"\"\n",
    "    \n",
    "    # Normalize: log(CPM + 1)\n",
    "    library_sizes = sc_counts.sum(axis=0)\n",
    "    cpm = sc_counts / library_sizes * 1e6\n",
    "    log_cpm = np.log2(cpm + 1)\n",
    "    \n",
    "    # Transpose: cells as rows, genes as columns\n",
    "    data_for_pca = log_cpm.T\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data_for_pca)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=50)\n",
    "    pca_result = pca.fit_transform(data_scaled)\n",
    "    \n",
    "    # Add PCA coordinates to metadata\n",
    "    cell_metadata['PC1'] = pca_result[:, 0]\n",
    "    cell_metadata['PC2'] = pca_result[:, 1]\n",
    "    \n",
    "    print(\"üîç PCA Analysis\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Variance explained by PC1: {pca.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "    print(f\"Variance explained by PC2: {pca.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "    print(f\"Cumulative variance (PC1-PC10): {pca.explained_variance_ratio_[:10].sum()*100:.2f}%\")\n",
    "    \n",
    "    return pca, pca_result, cell_metadata\n",
    "\n",
    "pca, pca_result, cell_metadata = perform_pca(sc_counts, cell_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Visualize PCA\n",
    "def visualize_pca(cell_metadata):\n",
    "    \"\"\"Plot cells in PCA space\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot by cell type\n",
    "    for cell_type in cell_metadata['true_type'].unique():\n",
    "        subset = cell_metadata[cell_metadata['true_type'] == cell_type]\n",
    "        axes[0].scatter(subset['PC1'], subset['PC2'], \n",
    "                       label=cell_type, alpha=0.6, s=30)\n",
    "    \n",
    "    axes[0].set_xlabel('PC1')\n",
    "    axes[0].set_ylabel('PC2')\n",
    "    axes[0].set_title('PCA: Colored by Cell Type')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot by UMI counts\n",
    "    scatter = axes[1].scatter(cell_metadata['PC1'], cell_metadata['PC2'],\n",
    "                             c=cell_metadata['n_counts'], \n",
    "                             cmap='viridis', alpha=0.6, s=30)\n",
    "    axes[1].set_xlabel('PC1')\n",
    "    axes[1].set_ylabel('PC2')\n",
    "    axes[1].set_title('PCA: Colored by UMI Counts')\n",
    "    plt.colorbar(scatter, ax=axes[1], label='Total Counts')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ PCA successfully separates cell types!\")\n",
    "\n",
    "visualize_pca(cell_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: Clustering and Cell Type Identification\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Apply K-means clustering\n",
    "- Compare clustering results with known cell types\n",
    "- Understand clustering metrics\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**K-means:** Partitioning cells into K clusters  \n",
    "**Leiden/Louvain:** Graph-based clustering (used in real scRNA-seq)  \n",
    "**Silhouette Score:** Quality metric for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Perform clustering\n",
    "def perform_clustering(pca_result, cell_metadata, n_clusters=3):\n",
    "    \"\"\"Apply K-means clustering on PCA results\"\"\"\n",
    "    \n",
    "    # K-means on first 10 PCs\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(pca_result[:, :10])\n",
    "    \n",
    "    # Add to metadata\n",
    "    cell_metadata['cluster'] = [f\"Cluster_{i}\" for i in clusters]\n",
    "    \n",
    "    # Calculate silhouette score\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    silhouette = silhouette_score(pca_result[:, :10], clusters)\n",
    "    \n",
    "    print(\"üéØ Clustering Results\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Number of clusters: {n_clusters}\")\n",
    "    print(f\"Silhouette score: {silhouette:.3f} (higher is better)\")\n",
    "    print(f\"\\nCluster sizes:\")\n",
    "    print(cell_metadata['cluster'].value_counts())\n",
    "    \n",
    "    return cell_metadata\n",
    "\n",
    "cell_metadata = perform_clustering(pca_result, cell_metadata, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Visualize clustering results\n",
    "def visualize_clustering(cell_metadata):\n",
    "    \"\"\"Compare clustering with known cell types\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot by predicted clusters\n",
    "    for cluster in cell_metadata['cluster'].unique():\n",
    "        subset = cell_metadata[cell_metadata['cluster'] == cluster]\n",
    "        axes[0].scatter(subset['PC1'], subset['PC2'],\n",
    "                       label=cluster, alpha=0.6, s=30)\n",
    "    \n",
    "    axes[0].set_xlabel('PC1')\n",
    "    axes[0].set_ylabel('PC2')\n",
    "    axes[0].set_title('Predicted Clusters (K-means)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot by true cell types\n",
    "    for cell_type in cell_metadata['true_type'].unique():\n",
    "        subset = cell_metadata[cell_metadata['true_type'] == cell_type]\n",
    "        axes[1].scatter(subset['PC1'], subset['PC2'],\n",
    "                       label=cell_type, alpha=0.6, s=30)\n",
    "    \n",
    "    axes[1].set_xlabel('PC1')\n",
    "    axes[1].set_ylabel('PC2')\n",
    "    axes[1].set_title('True Cell Types')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create confusion-like comparison\n",
    "    comparison = pd.crosstab(cell_metadata['cluster'], \n",
    "                             cell_metadata['true_type'])\n",
    "    \n",
    "    print(\"\\nüìä Cluster vs True Cell Type:\")\n",
    "    print(comparison)\n",
    "    print(\"\\n‚úÖ Clustering successfully identifies distinct cell populations!\")\n",
    "\n",
    "visualize_clustering(cell_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 7: Visualization and Interpretation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Create heatmaps of gene expression\n",
    "- Identify marker genes for each cluster\n",
    "- Generate publication-quality visualizations\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Heatmap:** Visualizing expression patterns across cells/genes  \n",
    "**Marker Genes:** Genes specifically expressed in one cell type  \n",
    "**Violin Plots:** Distribution of expression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Find marker genes\n",
    "def find_marker_genes(sc_counts, cell_metadata, top_n=5):\n",
    "    \"\"\"Identify top marker genes for each cluster\"\"\"\n",
    "    \n",
    "    # Normalize\n",
    "    library_sizes = sc_counts.sum(axis=0)\n",
    "    cpm = sc_counts / library_sizes * 1e6\n",
    "    log_cpm = np.log2(cpm + 1)\n",
    "    \n",
    "    markers = {}\n",
    "    \n",
    "    for cluster in cell_metadata['cluster'].unique():\n",
    "        # Get cells in this cluster\n",
    "        cluster_cells = cell_metadata[cell_metadata['cluster'] == cluster]['cell']\n",
    "        other_cells = cell_metadata[cell_metadata['cluster'] != cluster]['cell']\n",
    "        \n",
    "        # Calculate mean expression\n",
    "        cluster_mean = log_cpm[cluster_cells].mean(axis=1)\n",
    "        other_mean = log_cpm[other_cells].mean(axis=1)\n",
    "        \n",
    "        # Fold change\n",
    "        fc = cluster_mean - other_mean\n",
    "        \n",
    "        # Get top genes\n",
    "        top_genes = fc.nlargest(top_n).index.tolist()\n",
    "        markers[cluster] = top_genes\n",
    "    \n",
    "    print(\"üî¨ Top Marker Genes per Cluster\")\n",
    "    print(\"=\" * 50)\n",
    "    for cluster, genes in markers.items():\n",
    "        print(f\"\\n{cluster}:\")\n",
    "        for gene in genes:\n",
    "            print(f\"  - {gene}\")\n",
    "    \n",
    "    return markers, log_cpm\n",
    "\n",
    "markers, log_cpm_sc = find_marker_genes(sc_counts, cell_metadata, top_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Create expression heatmap\n",
    "def create_expression_heatmap(log_cpm_sc, cell_metadata, markers):\n",
    "    \"\"\"Visualize marker gene expression across clusters\"\"\"\n",
    "    \n",
    "    # Get all marker genes\n",
    "    all_markers = []\n",
    "    for genes in markers.values():\n",
    "        all_markers.extend(genes)\n",
    "    all_markers = list(set(all_markers))[:15]  # Top 15 unique markers\n",
    "    \n",
    "    # Sort cells by cluster\n",
    "    cell_metadata_sorted = cell_metadata.sort_values('cluster')\n",
    "    sorted_cells = cell_metadata_sorted['cell']\n",
    "    \n",
    "    # Get expression matrix\n",
    "    expr_matrix = log_cpm_sc.loc[all_markers, sorted_cells]\n",
    "    \n",
    "    # Create heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(expr_matrix, \n",
    "                cmap='RdYlBu_r',\n",
    "                cbar_kws={'label': 'Log2(CPM + 1)'},\n",
    "                xticklabels=False,\n",
    "                yticklabels=True,\n",
    "                linewidths=0)\n",
    "    \n",
    "    plt.xlabel('Cells (sorted by cluster)')\n",
    "    plt.ylabel('Marker Genes')\n",
    "    plt.title('Expression Heatmap: Top Marker Genes', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add cluster boundaries\n",
    "    cluster_boundaries = cell_metadata_sorted.groupby('cluster').size().cumsum()[:-1].values\n",
    "    for boundary in cluster_boundaries:\n",
    "        plt.axvline(x=boundary, color='black', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüé® Heatmap shows distinct expression patterns for each cluster!\")\n",
    "\n",
    "create_expression_heatmap(log_cpm_sc, cell_metadata, markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **RNA-seq Data Structure**: Understanding count matrices and metadata\n",
    "2. **Normalization**: CPM, log transformation, and their importance\n",
    "3. **Differential Expression**: Statistical testing and volcano plots\n",
    "4. **Single-Cell Analysis**: QC, filtering, and handling sparsity\n",
    "5. **Dimensionality Reduction**: PCA for visualization\n",
    "6. **Clustering**: Identifying cell populations\n",
    "7. **Marker Genes**: Finding genes that define cell types\n",
    "\n",
    "### Key Takeaways:\n",
    "- RNA-seq data requires careful normalization and QC\n",
    "- Single-cell data is sparse and high-dimensional\n",
    "- PCA and clustering reveal cell populations\n",
    "- Marker genes help interpret biological meaning\n",
    "\n",
    "### Next Steps:\n",
    "- Try with real datasets (10X Genomics, GEO)\n",
    "- Learn Seurat (R) or Scanpy (Python) for advanced analysis\n",
    "- Explore trajectory analysis and RNA velocity\n",
    "- Apply to your own research questions!\n",
    "\n",
    "### üìö Recommended Resources:\n",
    "- **Scanpy**: https://scanpy.readthedocs.io/\n",
    "- **Seurat**: https://satijalab.org/seurat/\n",
    "- **Single Cell Course**: https://www.singlecellcourse.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
