{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè• Biomedical ML: Essential Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [Handling High-Dimensional Data](#practice-1-handling-high-dimensional-data)\n",
    "2. [Dealing with Class Imbalance](#practice-2-dealing-with-class-imbalance)\n",
    "3. [Missing Data Imputation](#practice-3-missing-data-imputation)\n",
    "4. [Cross-Validation Strategies](#practice-4-cross-validation-strategies)\n",
    "5. [Performance Metrics for Biomedical Data](#practice-5-performance-metrics-for-biomedical-data)\n",
    "6. [ROC and PR Curves](#practice-6-roc-and-pr-curves)\n",
    "7. [Survival Analysis with Kaplan-Meier](#practice-7-survival-analysis-with-kaplan-meier)\n",
    "8. [Cox Proportional Hazards Model](#practice-8-cox-proportional-hazards-model)\n",
    "9. [Model Interpretability with SHAP](#practice-9-model-interpretability-with-shap)\n",
    "10. [Complete Biomedical ML Pipeline](#practice-10-complete-biomedical-ml-pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             roc_curve, auc, precision_recall_curve,\n",
    "                             balanced_accuracy_score, matthews_corrcoef)\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Handling High-Dimensional Data\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the curse of dimensionality (P >> N problem)\n",
    "- Apply feature selection methods\n",
    "- Visualize data sparsity in high dimensions\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Curse of Dimensionality:** When features (P) greatly exceed samples (N), models tend to overfit and distances become meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Simulate high-dimensional biomedical data\n",
    "def create_highdim_biomedical_data():\n",
    "    \"\"\"Simulate gene expression data with P >> N\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simulate: 50 patients, 1000 genes\n",
    "    n_samples = 50\n",
    "    n_features = 1000\n",
    "    \n",
    "    # Generate expression data\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    \n",
    "    # Create disease labels (0: healthy, 1: disease)\n",
    "    # Make 10 genes truly predictive\n",
    "    true_genes = [0, 50, 100, 200, 300, 400, 500, 600, 700, 800]\n",
    "    y = np.zeros(n_samples)\n",
    "    \n",
    "    for i, gene in enumerate(true_genes):\n",
    "        X[:, gene] += np.random.randn(n_samples) * 0.5\n",
    "    \n",
    "    # Assign labels based on sum of true genes\n",
    "    gene_sum = X[:, true_genes].sum(axis=1)\n",
    "    y[gene_sum > np.median(gene_sum)] = 1\n",
    "    \n",
    "    print(f\"üìä Dataset Shape: {X.shape}\")\n",
    "    print(f\"   Samples (N): {n_samples}\")\n",
    "    print(f\"   Features (P): {n_features}\")\n",
    "    print(f\"   Ratio P/N: {n_features/n_samples:.1f}\")\n",
    "    print(f\"\\nüéØ Class Distribution:\")\n",
    "    print(f\"   Healthy: {np.sum(y==0)} patients\")\n",
    "    print(f\"   Disease: {np.sum(y==1)} patients\")\n",
    "    \n",
    "    return X, y, true_genes\n",
    "\n",
    "X_highdim, y_highdim, important_genes = create_highdim_biomedical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Feature selection using univariate statistics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def apply_feature_selection(X, y, k=50):\n",
    "    \"\"\"Select top K features using F-statistic\"\"\"\n",
    "    \n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    \n",
    "    # Get selected feature indices\n",
    "    selected_features = selector.get_support(indices=True)\n",
    "    \n",
    "    print(f\"\\nüîç Feature Selection Results:\")\n",
    "    print(f\"   Original features: {X.shape[1]}\")\n",
    "    print(f\"   Selected features: {X_selected.shape[1]}\")\n",
    "    print(f\"   Reduction: {(1 - X_selected.shape[1]/X.shape[1])*100:.1f}%\")\n",
    "    \n",
    "    # Check how many true genes were selected\n",
    "    true_selected = np.intersect1d(selected_features, important_genes)\n",
    "    print(f\"\\n‚úÖ True predictive genes found: {len(true_selected)}/{len(important_genes)}\")\n",
    "    \n",
    "    return X_selected, selected_features\n",
    "\n",
    "X_selected, selected_idx = apply_feature_selection(X_highdim, y_highdim, k=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Dealing with Class Imbalance\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the accuracy paradox\n",
    "- Apply SMOTE for oversampling\n",
    "- Use appropriate metrics for imbalanced data\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Accuracy Paradox:** 99% accuracy is useless if 99% of samples are negative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Create imbalanced dataset (rare disease scenario)\n",
    "def create_imbalanced_clinical_data():\n",
    "    \"\"\"Simulate imbalanced clinical data: 95% healthy, 5% disease\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_samples = 1000\n",
    "    n_features = 20\n",
    "    \n",
    "    # Generate features\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    \n",
    "    # Create highly imbalanced labels\n",
    "    y = np.zeros(n_samples)\n",
    "    disease_indices = np.random.choice(n_samples, size=50, replace=False)  # 5% disease\n",
    "    y[disease_indices] = 1\n",
    "    \n",
    "    # Make disease samples distinguishable\n",
    "    X[disease_indices, :5] += 2.0  # Increase first 5 features for disease\n",
    "    \n",
    "    print(f\"üìä Imbalanced Dataset:\")\n",
    "    print(f\"   Total samples: {n_samples}\")\n",
    "    print(f\"   Healthy: {np.sum(y==0)} ({np.sum(y==0)/len(y)*100:.1f}%)\")\n",
    "    print(f\"   Disease: {np.sum(y==1)} ({np.sum(y==1)/len(y)*100:.1f}%)\")\n",
    "    print(f\"\\n‚ö†Ô∏è Imbalance ratio: {np.sum(y==0)/np.sum(y==1):.1f}:1\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X_imb, y_imb = create_imbalanced_clinical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Apply SMOTE and compare results\n",
    "def compare_with_without_smote(X, y):\n",
    "    \"\"\"Compare model performance with and without SMOTE\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Model 1: Without SMOTE\n",
    "    clf1 = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    y_pred1 = clf1.predict(X_test)\n",
    "    \n",
    "    # Model 2: With SMOTE\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    clf2 = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    clf2.fit(X_train_smote, y_train_smote)\n",
    "    y_pred2 = clf2.predict(X_test)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WITHOUT SMOTE:\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_test, y_pred1, target_names=['Healthy', 'Disease']))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"WITH SMOTE:\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_test, y_pred2, target_names=['Healthy', 'Disease']))\n",
    "    \n",
    "    # Compare specific metrics\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPARISON:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Balanced Accuracy - Without SMOTE: {balanced_accuracy_score(y_test, y_pred1):.3f}\")\n",
    "    print(f\"Balanced Accuracy - With SMOTE: {balanced_accuracy_score(y_test, y_pred2):.3f}\")\n",
    "    print(f\"\\nMatthews CC - Without SMOTE: {matthews_corrcoef(y_test, y_pred1):.3f}\")\n",
    "    print(f\"Matthews CC - With SMOTE: {matthews_corrcoef(y_test, y_pred2):.3f}\")\n",
    "    \n",
    "    return clf1, clf2\n",
    "\n",
    "model_no_smote, model_with_smote = compare_with_without_smote(X_imb, y_imb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Missing Data Imputation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand missing data mechanisms (MCAR, MAR, MNAR)\n",
    "- Apply different imputation strategies\n",
    "- Compare imputation methods\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**MCAR:** Missing Completely At Random  \n",
    "**MAR:** Missing At Random (depends on observed data)  \n",
    "**MNAR:** Missing Not At Random (depends on unobserved values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Simulate missing data\n",
    "def create_data_with_missing_values():\n",
    "    \"\"\"Create clinical dataset with missing values\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate complete data\n",
    "    n_samples = 200\n",
    "    n_features = 10\n",
    "    \n",
    "    X_complete = np.random.randn(n_samples, n_features) * 10 + 50\n",
    "    X_missing = X_complete.copy()\n",
    "    \n",
    "    # Introduce MCAR: randomly missing 20% of values\n",
    "    missing_mask = np.random.rand(n_samples, n_features) < 0.2\n",
    "    X_missing[missing_mask] = np.nan\n",
    "    \n",
    "    missing_count = np.isnan(X_missing).sum()\n",
    "    total_values = n_samples * n_features\n",
    "    \n",
    "    print(f\"üìä Missing Data Statistics:\")\n",
    "    print(f\"   Total values: {total_values}\")\n",
    "    print(f\"   Missing values: {missing_count} ({missing_count/total_values*100:.1f}%)\")\n",
    "    print(f\"\\n   Missing per feature:\")\n",
    "    for i in range(n_features):\n",
    "        missing_in_feature = np.isnan(X_missing[:, i]).sum()\n",
    "        print(f\"      Feature {i+1}: {missing_in_feature} ({missing_in_feature/n_samples*100:.1f}%)\")\n",
    "    \n",
    "    return X_complete, X_missing\n",
    "\n",
    "X_complete, X_with_missing = create_data_with_missing_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Compare imputation methods\n",
    "def compare_imputation_methods(X_complete, X_missing):\n",
    "    \"\"\"Compare mean, median, and KNN imputation\"\"\"\n",
    "    \n",
    "    # Method 1: Mean imputation\n",
    "    imputer_mean = SimpleImputer(strategy='mean')\n",
    "    X_mean = imputer_mean.fit_transform(X_missing)\n",
    "    \n",
    "    # Method 2: Median imputation\n",
    "    imputer_median = SimpleImputer(strategy='median')\n",
    "    X_median = imputer_median.fit_transform(X_missing)\n",
    "    \n",
    "    # Method 3: KNN imputation\n",
    "    imputer_knn = KNNImputer(n_neighbors=5)\n",
    "    X_knn = imputer_knn.fit_transform(X_missing)\n",
    "    \n",
    "    # Calculate reconstruction error (only for missing values)\n",
    "    missing_mask = np.isnan(X_missing)\n",
    "    \n",
    "    error_mean = np.abs(X_complete[missing_mask] - X_mean[missing_mask]).mean()\n",
    "    error_median = np.abs(X_complete[missing_mask] - X_median[missing_mask]).mean()\n",
    "    error_knn = np.abs(X_complete[missing_mask] - X_knn[missing_mask]).mean()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"IMPUTATION METHOD COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nMean Absolute Error (MAE) on missing values:\")\n",
    "    print(f\"  Mean Imputation:   {error_mean:.4f}\")\n",
    "    print(f\"  Median Imputation: {error_median:.4f}\")\n",
    "    print(f\"  KNN Imputation:    {error_knn:.4f}\")\n",
    "    \n",
    "    # Determine best method\n",
    "    errors = {'Mean': error_mean, 'Median': error_median, 'KNN': error_knn}\n",
    "    best_method = min(errors, key=errors.get)\n",
    "    print(f\"\\n‚úÖ Best method: {best_method} imputation\")\n",
    "    \n",
    "    return X_mean, X_median, X_knn\n",
    "\n",
    "X_imp_mean, X_imp_median, X_imp_knn = compare_imputation_methods(X_complete, X_with_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Cross-Validation Strategies\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Implement different CV strategies\n",
    "- Understand when to use each strategy\n",
    "- Apply stratified CV for imbalanced data\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**K-Fold CV:** Split data into K folds, train on K-1, test on 1  \n",
    "**Stratified CV:** Preserve class distribution in each fold  \n",
    "**Group CV:** Keep samples from same patient together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Compare different CV strategies\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut\n",
    "\n",
    "def compare_cv_strategies():\n",
    "    \"\"\"Compare K-Fold, Stratified K-Fold, and LOOCV\"\"\"\n",
    "    \n",
    "    # Generate imbalanced data\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(100, 20)\n",
    "    y = np.zeros(100)\n",
    "    y[:10] = 1  # 10% positive class\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = np.random.permutation(100)\n",
    "    X, y = X[indices], y[indices]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CROSS-VALIDATION STRATEGY COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Strategy 1: K-Fold CV\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores_kfold = cross_val_score(model, X, y, cv=kfold, scoring='balanced_accuracy')\n",
    "    print(f\"\\n1. K-Fold CV (K=5):\")\n",
    "    print(f\"   Scores: {scores_kfold}\")\n",
    "    print(f\"   Mean: {scores_kfold.mean():.3f} (+/- {scores_kfold.std():.3f})\")\n",
    "    \n",
    "    # Strategy 2: Stratified K-Fold CV\n",
    "    skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores_skfold = cross_val_score(model, X, y, cv=skfold, scoring='balanced_accuracy')\n",
    "    print(f\"\\n2. Stratified K-Fold CV (K=5):\")\n",
    "    print(f\"   Scores: {scores_skfold}\")\n",
    "    print(f\"   Mean: {scores_skfold.mean():.3f} (+/- {scores_skfold.std():.3f})\")\n",
    "    \n",
    "    # Visualize class distribution in folds\n",
    "    print(f\"\\nüìä Class Distribution per Fold:\")\n",
    "    print(f\"\\n   Regular K-Fold:\")\n",
    "    for i, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "        test_pos = y[test_idx].sum()\n",
    "        test_total = len(test_idx)\n",
    "        print(f\"      Fold {i+1}: {test_pos:.0f}/{test_total} positive ({test_pos/test_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n   Stratified K-Fold:\")\n",
    "    for i, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "        test_pos = y[test_idx].sum()\n",
    "        test_total = len(test_idx)\n",
    "        print(f\"      Fold {i+1}: {test_pos:.0f}/{test_total} positive ({test_pos/test_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Stratified CV maintains class balance across folds!\")\n",
    "    \n",
    "    return scores_kfold, scores_skfold\n",
    "\n",
    "scores_k, scores_sk = compare_cv_strategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Performance Metrics for Biomedical Data\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand confusion matrix components\n",
    "- Calculate sensitivity, specificity, PPV, NPV\n",
    "- Use appropriate metrics for clinical scenarios\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Sensitivity (Recall):** TP / (TP + FN) - How many actual positives detected  \n",
    "**Specificity:** TN / (TN + FP) - How many actual negatives identified  \n",
    "**PPV (Precision):** TP / (TP + FP) - Positive predictive value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Calculate and visualize confusion matrix\n",
    "def detailed_performance_metrics():\n",
    "    \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
    "    \n",
    "    # Train a model on imbalanced data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_imb, y_imb, test_size=0.3, random_state=42, stratify=y_imb\n",
    "    )\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CONFUSION MATRIX\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n                Predicted\")\n",
    "    print(f\"              Negative  Positive\")\n",
    "    print(f\"Actual Negative    {tn:4d}      {fp:4d}    (Specificity)\")\n",
    "    print(f\"       Positive    {fn:4d}      {tp:4d}    (Sensitivity)\")\n",
    "    print(f\"              (NPV)      (PPV)\")\n",
    "    \n",
    "    # Calculate metrics manually\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    balanced_acc = (sensitivity + specificity) / 2\n",
    "    f1 = 2 * (ppv * sensitivity) / (ppv + sensitivity)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PERFORMANCE METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nBasic Metrics:\")\n",
    "    print(f\"  Accuracy:           {accuracy:.3f}\")\n",
    "    print(f\"  Balanced Accuracy:  {balanced_acc:.3f}\")\n",
    "    \n",
    "    print(f\"\\nClinical Metrics:\")\n",
    "    print(f\"  Sensitivity (Recall): {sensitivity:.3f}  [TP/(TP+FN)]\")\n",
    "    print(f\"  Specificity:          {specificity:.3f}  [TN/(TN+FP)]\")\n",
    "    print(f\"  PPV (Precision):      {ppv:.3f}  [TP/(TP+FP)]\")\n",
    "    print(f\"  NPV:                  {npv:.3f}  [TN/(TN+FN)]\")\n",
    "    \n",
    "    print(f\"\\nCombined Metrics:\")\n",
    "    print(f\"  F1-Score:           {f1:.3f}\")\n",
    "    print(f\"  Matthews CC:        {mcc:.3f}\")\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Healthy', 'Disease'],\n",
    "                yticklabels=['Healthy', 'Disease'])\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return clf, cm\n",
    "\n",
    "trained_clf, conf_matrix = detailed_performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: ROC and PR Curves\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Plot and interpret ROC curves\n",
    "- Plot and interpret PR curves\n",
    "- Understand when to use each curve\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**ROC Curve:** TPR vs FPR - good for balanced datasets  \n",
    "**PR Curve:** Precision vs Recall - better for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Plot ROC and PR curves\n",
    "def plot_roc_and_pr_curves():\n",
    "    \"\"\"Generate and compare ROC and PR curves\"\"\"\n",
    "    \n",
    "    # Get probability predictions\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_imb, y_imb, test_size=0.3, random_state=42, stratify=y_imb\n",
    "    )\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, thresholds_roc = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # PR Curve\n",
    "    precision, recall, thresholds_pr = precision_recall_curve(y_test, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Create side-by-side plots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # ROC Curve\n",
    "    axes[0].plot(fpr, tpr, color='#1E64C8', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    axes[0].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random')\n",
    "    axes[0].set_xlim([0.0, 1.0])\n",
    "    axes[0].set_ylim([0.0, 1.05])\n",
    "    axes[0].set_xlabel('False Positive Rate (1-Specificity)', fontsize=11)\n",
    "    axes[0].set_ylabel('True Positive Rate (Sensitivity)', fontsize=11)\n",
    "    axes[0].set_title('ROC Curve', fontsize=13, fontweight='bold')\n",
    "    axes[0].legend(loc='lower right')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # PR Curve\n",
    "    axes[1].plot(recall, precision, color='#e74c3c', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')\n",
    "    baseline = np.sum(y_test) / len(y_test)\n",
    "    axes[1].axhline(y=baseline, color='gray', lw=1, linestyle='--', label=f'Baseline ({baseline:.3f})')\n",
    "    axes[1].set_xlim([0.0, 1.0])\n",
    "    axes[1].set_ylim([0.0, 1.05])\n",
    "    axes[1].set_xlabel('Recall (Sensitivity)', fontsize=11)\n",
    "    axes[1].set_ylabel('Precision (PPV)', fontsize=11)\n",
    "    axes[1].set_title('Precision-Recall Curve', fontsize=13, fontweight='bold')\n",
    "    axes[1].legend(loc='lower left')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CURVE INTERPRETATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nROC-AUC: {roc_auc:.3f}\")\n",
    "    print(f\"  - 0.5 = random classifier\")\n",
    "    print(f\"  - 1.0 = perfect classifier\")\n",
    "    print(f\"  - Good for balanced datasets\")\n",
    "    \n",
    "    print(f\"\\nPR-AUC: {pr_auc:.3f}\")\n",
    "    print(f\"  - Better for imbalanced data\")\n",
    "    print(f\"  - Baseline = {baseline:.3f} (class prevalence)\")\n",
    "    print(f\"  - More informative for rare diseases\")\n",
    "    \n",
    "    return roc_auc, pr_auc\n",
    "\n",
    "roc_score, pr_score = plot_roc_and_pr_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 7: Survival Analysis with Kaplan-Meier\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand survival analysis basics\n",
    "- Plot Kaplan-Meier curves\n",
    "- Compare survival between groups\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Survival Analysis:** Time-to-event analysis (death, recurrence, etc.)  \n",
    "**Censoring:** Patient lost to follow-up or study ends before event  \n",
    "**Kaplan-Meier:** Non-parametric estimator of survival function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lifelines if not already installed\n",
    "!pip install lifelines -q\n",
    "\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "# 7.1 Simulate clinical trial survival data\n",
    "def create_survival_data():\n",
    "    \"\"\"Simulate survival data for two treatment groups\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_patients = 100\n",
    "    \n",
    "    # Treatment A: better survival\n",
    "    time_A = np.random.exponential(scale=30, size=n_patients//2)\n",
    "    event_A = np.random.rand(n_patients//2) < 0.6  # 60% experienced event\n",
    "    group_A = np.array(['Treatment A'] * (n_patients//2))\n",
    "    \n",
    "    # Treatment B: worse survival\n",
    "    time_B = np.random.exponential(scale=18, size=n_patients//2)\n",
    "    event_B = np.random.rand(n_patients//2) < 0.75  # 75% experienced event\n",
    "    group_B = np.array(['Treatment B'] * (n_patients//2))\n",
    "    \n",
    "    # Combine data\n",
    "    df_survival = pd.DataFrame({\n",
    "        'time': np.concatenate([time_A, time_B]),\n",
    "        'event': np.concatenate([event_A, event_B]).astype(int),\n",
    "        'group': np.concatenate([group_A, group_B])\n",
    "    })\n",
    "    \n",
    "    print(\"üìä Survival Data Summary:\")\n",
    "    print(f\"\\nTotal patients: {len(df_survival)}\")\n",
    "    print(f\"\\nTreatment A:\")\n",
    "    print(f\"  Events: {event_A.sum()}/{len(event_A)} ({event_A.sum()/len(event_A)*100:.1f}%)\")\n",
    "    print(f\"  Censored: {(~event_A).sum()}/{len(event_A)}\")\n",
    "    print(f\"  Median time: {np.median(time_A):.1f} months\")\n",
    "    \n",
    "    print(f\"\\nTreatment B:\")\n",
    "    print(f\"  Events: {event_B.sum()}/{len(event_B)} ({event_B.sum()/len(event_B)*100:.1f}%)\")\n",
    "    print(f\"  Censored: {(~event_B).sum()}/{len(event_B)}\")\n",
    "    print(f\"  Median time: {np.median(time_B):.1f} months\")\n",
    "    \n",
    "    return df_survival\n",
    "\n",
    "df_surv = create_survival_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Plot Kaplan-Meier curves\n",
    "def plot_kaplan_meier(df):\n",
    "    \"\"\"Plot KM curves for both treatment groups\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    kmf = KaplanMeierFitter()\n",
    "    \n",
    "    # Plot for each group\n",
    "    for group in df['group'].unique():\n",
    "        mask = df['group'] == group\n",
    "        kmf.fit(\n",
    "            durations=df.loc[mask, 'time'],\n",
    "            event_observed=df.loc[mask, 'event'],\n",
    "            label=group\n",
    "        )\n",
    "        kmf.plot_survival_function(ax=ax, ci_show=True)\n",
    "    \n",
    "    ax.set_xlabel('Time (months)', fontsize=12)\n",
    "    ax.set_ylabel('Survival Probability', fontsize=12)\n",
    "    ax.set_title('Kaplan-Meier Survival Curves by Treatment Group', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Log-rank test\n",
    "    results = logrank_test(\n",
    "        durations_A=df[df['group']=='Treatment A']['time'],\n",
    "        durations_B=df[df['group']=='Treatment B']['time'],\n",
    "        event_observed_A=df[df['group']=='Treatment A']['event'],\n",
    "        event_observed_B=df[df['group']=='Treatment B']['event']\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LOG-RANK TEST RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nTest statistic: {results.test_statistic:.4f}\")\n",
    "    print(f\"p-value: {results.p_value:.4f}\")\n",
    "    \n",
    "    if results.p_value < 0.05:\n",
    "        print(f\"\\n‚úÖ Significant difference in survival between groups (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå No significant difference in survival between groups (p >= 0.05)\")\n",
    "    \n",
    "    return kmf, results\n",
    "\n",
    "kmf_model, logrank_results = plot_kaplan_meier(df_surv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 8: Cox Proportional Hazards Model\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Fit Cox regression model\n",
    "- Interpret hazard ratios\n",
    "- Test proportional hazards assumption\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Cox Model:** h(t|X) = h‚ÇÄ(t) ¬∑ exp(Œ≤‚ÇÅX‚ÇÅ + ... + Œ≤‚ÇöX‚Çö)  \n",
    "**Hazard Ratio:** exp(Œ≤) - risk multiplier  \n",
    "**PH Assumption:** Hazard ratio constant over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Fit Cox regression model\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "def fit_cox_regression():\n",
    "    \"\"\"Fit Cox model with multiple covariates\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create dataset with covariates\n",
    "    n = 200\n",
    "    df_cox = pd.DataFrame({\n",
    "        'time': np.random.exponential(scale=20, size=n),\n",
    "        'event': np.random.rand(n) < 0.7,\n",
    "        'age': np.random.normal(65, 10, n),\n",
    "        'treatment': np.random.choice([0, 1], n),  # 0=control, 1=treatment\n",
    "        'stage': np.random.choice([1, 2, 3, 4], n),  # Cancer stage\n",
    "        'biomarker': np.random.normal(100, 20, n)\n",
    "    })\n",
    "    \n",
    "    # Fit Cox model\n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(df_cox, duration_col='time', event_col='event')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COX PROPORTIONAL HAZARDS MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    cph.print_summary()\n",
    "    \n",
    "    # Interpret hazard ratios\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HAZARD RATIO INTERPRETATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for covariate in cph.params_.index:\n",
    "        hr = np.exp(cph.params_[covariate])\n",
    "        ci_lower = np.exp(cph.confidence_intervals_.loc[covariate, '95% lower-bound'])\n",
    "        ci_upper = np.exp(cph.confidence_intervals_.loc[covariate, '95% upper-bound'])\n",
    "        \n",
    "        print(f\"\\n{covariate}:\")\n",
    "        print(f\"  Hazard Ratio: {hr:.3f}\")\n",
    "        print(f\"  95% CI: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "        \n",
    "        if hr > 1:\n",
    "            print(f\"  ‚Üí Increases risk by {(hr-1)*100:.1f}%\")\n",
    "        else:\n",
    "            print(f\"  ‚Üí Decreases risk by {(1-hr)*100:.1f}%\")\n",
    "    \n",
    "    return cph, df_cox\n",
    "\n",
    "cox_model, df_cox_data = fit_cox_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 9: Model Interpretability with SHAP\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Use SHAP values for model interpretation\n",
    "- Visualize feature importance\n",
    "- Explain individual predictions\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**SHAP:** SHapley Additive exPlanations - unified framework  \n",
    "**Shapley Values:** From game theory - fair contribution of each feature  \n",
    "**TreeSHAP:** Fast algorithm for tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install shap if needed\n",
    "!pip install shap -q\n",
    "\n",
    "import shap\n",
    "\n",
    "# 9.1 Apply SHAP to Random Forest model\n",
    "def apply_shap_interpretation():\n",
    "    \"\"\"Use SHAP to interpret Random Forest predictions\"\"\"\n",
    "    \n",
    "    # Create interpretable dataset\n",
    "    np.random.seed(42)\n",
    "    n_samples = 500\n",
    "    \n",
    "    # Create features with meaningful names\n",
    "    feature_names = ['Age', 'BMI', 'Blood_Pressure', 'Glucose', 'Cholesterol']\n",
    "    \n",
    "    X_interp = pd.DataFrame({\n",
    "        'Age': np.random.normal(60, 15, n_samples),\n",
    "        'BMI': np.random.normal(27, 5, n_samples),\n",
    "        'Blood_Pressure': np.random.normal(130, 20, n_samples),\n",
    "        'Glucose': np.random.normal(100, 25, n_samples),\n",
    "        'Cholesterol': np.random.normal(200, 40, n_samples)\n",
    "    })\n",
    "    \n",
    "    # Generate target based on features\n",
    "    risk_score = (0.02 * X_interp['Age'] + \n",
    "                  0.1 * X_interp['BMI'] + \n",
    "                  0.01 * X_interp['Glucose'] +\n",
    "                  np.random.randn(n_samples) * 2)\n",
    "    y_interp = (risk_score > np.median(risk_score)).astype(int)\n",
    "    \n",
    "    # Train model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_interp, y_interp, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"\\nüìä Model Performance:\")\n",
    "    print(f\"   Accuracy: {rf_model.score(X_test, y_test):.3f}\")\n",
    "    \n",
    "    # SHAP analysis\n",
    "    explainer = shap.TreeExplainer(rf_model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "    \n",
    "    print(\"\\n‚úÖ SHAP values calculated successfully!\")\n",
    "    \n",
    "    # Summary plot\n",
    "    print(\"\\nüìà Generating SHAP summary plot...\")\n",
    "    shap.summary_plot(shap_values[1], X_test, show=False)\n",
    "    plt.title('SHAP Feature Importance', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Feature importance comparison\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FEATURE IMPORTANCE COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Random Forest native importance\n",
    "    rf_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'RF Importance': rf_model.feature_importances_\n",
    "    }).sort_values('RF Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nRandom Forest Feature Importance:\")\n",
    "    print(rf_importance.to_string(index=False))\n",
    "    \n",
    "    # SHAP importance (mean absolute SHAP value)\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'SHAP Importance': np.abs(shap_values[1]).mean(axis=0)\n",
    "    }).sort_values('SHAP Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nSHAP Feature Importance:\")\n",
    "    print(shap_importance.to_string(index=False))\n",
    "    \n",
    "    return rf_model, explainer, shap_values, X_test\n",
    "\n",
    "rf_shap, shap_explainer, shap_vals, X_test_shap = apply_shap_interpretation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2 Explain individual prediction\n",
    "def explain_single_prediction(model, explainer, shap_values, X_test, sample_idx=0):\n",
    "    \"\"\"Explain prediction for a single patient\"\"\"\n",
    "    \n",
    "    # Get prediction\n",
    "    sample = X_test.iloc[sample_idx:sample_idx+1]\n",
    "    prediction = model.predict(sample)[0]\n",
    "    probability = model.predict_proba(sample)[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"PATIENT #{sample_idx} PREDICTION EXPLANATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nPatient Features:\")\n",
    "    for feature, value in sample.iloc[0].items():\n",
    "        print(f\"  {feature}: {value:.2f}\")\n",
    "    \n",
    "    print(f\"\\nPrediction:\")\n",
    "    print(f\"  Class: {prediction} ({'Disease' if prediction == 1 else 'Healthy'})\")\n",
    "    print(f\"  Probability: {probability[1]:.3f}\")\n",
    "    \n",
    "    # SHAP waterfall plot\n",
    "    print(\"\\nüìä Generating SHAP waterfall plot...\")\n",
    "    shap.waterfall_plot(\n",
    "        shap.Explanation(\n",
    "            values=shap_values[1][sample_idx],\n",
    "            base_values=explainer.expected_value[1],\n",
    "            data=sample.iloc[0].values,\n",
    "            feature_names=sample.columns.tolist()\n",
    "        ),\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(f'SHAP Explanation for Patient #{sample_idx}', \n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Individual prediction explained!\")\n",
    "\n",
    "explain_single_prediction(rf_shap, shap_explainer, shap_vals, X_test_shap, sample_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 10: Complete Biomedical ML Pipeline\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Build end-to-end ML pipeline\n",
    "- Integrate preprocessing, modeling, and evaluation\n",
    "- Apply best practices for biomedical data\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Pipeline:** Automated workflow from raw data to predictions  \n",
    "**Best Practices:** Feature selection, CV, proper metrics, interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10.1 Complete pipeline implementation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "def build_complete_pipeline():\n",
    "    \"\"\"Build complete ML pipeline for biomedical data\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUILDING COMPLETE BIOMEDICAL ML PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Load data\n",
    "    print(\"\\n[Step 1/6] Loading and preparing data...\")\n",
    "    X, y = create_imbalanced_clinical_data()\n",
    "    print(f\"   ‚úì Data loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    \n",
    "    # Step 2: Handle missing data\n",
    "    print(\"\\n[Step 2/6] Handling missing values...\")\n",
    "    # Introduce some missing values\n",
    "    X_with_nan = X.copy()\n",
    "    missing_mask = np.random.rand(*X.shape) < 0.1\n",
    "    X_with_nan[missing_mask] = np.nan\n",
    "    print(f\"   ‚úì Missing values: {np.isnan(X_with_nan).sum()} ({np.isnan(X_with_nan).sum()/X_with_nan.size*100:.1f}%)\")\n",
    "    \n",
    "    # Step 3: Split data\n",
    "    print(\"\\n[Step 3/6] Splitting data...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_with_nan, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"   ‚úì Train: {len(X_train)} samples\")\n",
    "    print(f\"   ‚úì Test: {len(X_test)} samples\")\n",
    "    \n",
    "    # Step 4: Build pipeline\n",
    "    print(\"\\n[Step 4/6] Building ML pipeline...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', SelectKBest(f_classif, k=10)),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "    print(\"   ‚úì Pipeline created with 4 steps:\")\n",
    "    print(\"     1. KNN Imputation\")\n",
    "    print(\"     2. Standard Scaling\")\n",
    "    print(\"     3. Feature Selection (K-Best)\")\n",
    "    print(\"     4. Random Forest (balanced)\")\n",
    "    \n",
    "    # Step 5: Train with cross-validation\n",
    "    print(\"\\n[Step 5/6] Training with cross-validation...\")\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train, y_train, \n",
    "        cv=StratifiedKFold(5, shuffle=True, random_state=42),\n",
    "        scoring='balanced_accuracy'\n",
    "    )\n",
    "    print(f\"   ‚úì CV Balanced Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n",
    "    \n",
    "    # Fit final model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(\"   ‚úì Final model trained on all training data\")\n",
    "    \n",
    "    # Step 6: Evaluate on test set\n",
    "    print(\"\\n[Step 6/6] Evaluating on test set...\")\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL TEST SET RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_test, y_pred, target_names=['Healthy', 'Disease']))\n",
    "    \n",
    "    # Additional metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"\\nClinical Metrics:\")\n",
    "    print(f\"  Sensitivity: {sensitivity:.3f}\")\n",
    "    print(f\"  Specificity: {specificity:.3f}\")\n",
    "    print(f\"  PPV:         {ppv:.3f}\")\n",
    "    print(f\"  NPV:         {npv:.3f}\")\n",
    "    print(f\"  Balanced Acc: {balanced_accuracy_score(y_test, y_pred):.3f}\")\n",
    "    print(f\"  Matthews CC:  {matthews_corrcoef(y_test, y_pred):.3f}\")\n",
    "    \n",
    "    # ROC-AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"  ROC-AUC:     {roc_auc:.3f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Complete pipeline executed successfully!\")\n",
    "    \n",
    "    return pipeline, X_test, y_test, y_pred, y_prob\n",
    "\n",
    "final_pipeline, X_final_test, y_final_test, y_final_pred, y_final_prob = build_complete_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **High-Dimensional Data**: Feature selection to combat curse of dimensionality\n",
    "2. **Class Imbalance**: SMOTE and proper metrics (balanced accuracy, Matthews CC)\n",
    "3. **Missing Data**: KNN imputation and comparison with simpler methods\n",
    "4. **Cross-Validation**: Stratified K-Fold for imbalanced biomedical data\n",
    "5. **Performance Metrics**: Confusion matrix, sensitivity, specificity, PPV, NPV\n",
    "6. **ROC and PR Curves**: Choosing appropriate evaluation for imbalanced data\n",
    "7. **Survival Analysis**: Kaplan-Meier curves and log-rank test\n",
    "8. **Cox Regression**: Hazard ratios and proportional hazards model\n",
    "9. **Interpretability**: SHAP values for clinical acceptance\n",
    "10. **Complete Pipeline**: End-to-end ML workflow for biomedical applications\n",
    "\n",
    "### Key Insights:\n",
    "- Biomedical data requires specialized techniques (not just standard ML)\n",
    "- Always use stratified CV and appropriate metrics for imbalanced data\n",
    "- Model interpretability is crucial for clinical adoption\n",
    "- Survival analysis is essential for time-to-event outcomes\n",
    "\n",
    "### Next Steps:\n",
    "- Apply to real clinical datasets\n",
    "- External validation on independent cohorts\n",
    "- Clinical deployment considerations\n",
    "- Regulatory requirements (FDA approval)\n",
    "\n",
    "### üìö Additional Resources:\n",
    "- **scikit-learn**: https://scikit-learn.org/\n",
    "- **lifelines**: https://lifelines.readthedocs.io/\n",
    "- **SHAP**: https://shap.readthedocs.io/\n",
    "- **imbalanced-learn**: https://imbalanced-learn.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
