{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Precision Medicine & Biomarkers: Hands-on Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [ROC Curve Analysis for Biomarker Evaluation](#practice-1-roc-curve-analysis)\n",
    "2. [Patient Stratification with Clustering](#practice-2-patient-stratification)\n",
    "3. [Survival Analysis and Risk Prediction](#practice-3-survival-analysis)\n",
    "4. [Multi-omics Data Integration](#practice-4-multi-omics-integration)\n",
    "5. [Biomarker Performance Metrics](#practice-5-performance-metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: ROC Curve Analysis for Biomarker Evaluation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand ROC curves for biomarker performance\n",
    "- Calculate sensitivity, specificity, and AUC\n",
    "- Determine optimal cutoff thresholds\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**ROC Curve:** Receiver Operating Characteristic curve plots True Positive Rate vs False Positive Rate\n",
    "**AUC:** Area Under the Curve - measures discrimination ability (0.5 = random, 1.0 = perfect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Generate synthetic biomarker data\n",
    "def generate_biomarker_data(n_samples=200):\n",
    "    \"\"\"Generate synthetic biomarker data for disease vs healthy patients\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Healthy patients (class 0)\n",
    "    healthy_biomarker = np.random.normal(loc=5.0, scale=1.5, size=n_samples//2)\n",
    "    \n",
    "    # Disease patients (class 1)\n",
    "    disease_biomarker = np.random.normal(loc=8.0, scale=1.8, size=n_samples//2)\n",
    "    \n",
    "    # Combine data\n",
    "    biomarker_values = np.concatenate([healthy_biomarker, disease_biomarker])\n",
    "    true_labels = np.concatenate([np.zeros(n_samples//2), np.ones(n_samples//2)])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Biomarker': biomarker_values,\n",
    "        'Disease_Status': true_labels.astype(int)\n",
    "    })\n",
    "    \n",
    "    print(\"üìä Biomarker Data Summary\")\n",
    "    print(\"=\"*50)\n",
    "    print(df.groupby('Disease_Status')['Biomarker'].describe())\n",
    "    \n",
    "    return df\n",
    "\n",
    "biomarker_df = generate_biomarker_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Visualize biomarker distribution\n",
    "def plot_biomarker_distribution(df):\n",
    "    \"\"\"Visualize biomarker distributions for healthy vs disease\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0].hist(df[df['Disease_Status']==0]['Biomarker'], \n",
    "                 bins=20, alpha=0.6, label='Healthy', color='skyblue')\n",
    "    axes[0].hist(df[df['Disease_Status']==1]['Biomarker'], \n",
    "                 bins=20, alpha=0.6, label='Disease', color='salmon')\n",
    "    axes[0].set_xlabel('Biomarker Value')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "    axes[0].set_title('Biomarker Distribution')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    sns.boxplot(data=df, x='Disease_Status', y='Biomarker', \n",
    "                palette=['skyblue', 'salmon'], ax=axes[1])\n",
    "    axes[1].set_xticklabels(['Healthy', 'Disease'])\n",
    "    axes[1].set_title('Biomarker Values by Disease Status')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_biomarker_distribution(biomarker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Calculate and plot ROC curve\n",
    "def calculate_roc_curve(df):\n",
    "    \"\"\"Calculate ROC curve and find optimal cutoff\"\"\"\n",
    "    \n",
    "    # Calculate ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(df['Disease_Status'], df['Biomarker'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Find optimal cutoff (Youden's index)\n",
    "    youden_index = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_index)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    print(\"\\nüìà ROC Analysis Results\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    print(f\"Optimal Cutoff: {optimal_threshold:.4f}\")\n",
    "    print(f\"Sensitivity at cutoff: {tpr[optimal_idx]:.4f}\")\n",
    "    print(f\"Specificity at cutoff: {1-fpr[optimal_idx]:.4f}\")\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "             label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "    plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100, \n",
    "                label=f'Optimal Cutoff ({optimal_threshold:.2f})', zorder=5)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "    plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return optimal_threshold, roc_auc\n",
    "\n",
    "optimal_cutoff, auc_score = calculate_roc_curve(biomarker_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Patient Stratification with Clustering\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Perform patient stratification using clustering\n",
    "- Identify risk groups based on molecular profiles\n",
    "- Visualize patient subgroups\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Patient Stratification:** Grouping patients by molecular or clinical characteristics\n",
    "**K-means Clustering:** Unsupervised learning to identify natural patient subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Generate multi-omics patient data\n",
    "def generate_patient_data(n_patients=150):\n",
    "    \"\"\"Generate synthetic multi-omics patient data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create three risk groups\n",
    "    # Low risk (n=50)\n",
    "    low_risk = np.random.multivariate_normal(\n",
    "        mean=[3, 2, 1, 2], \n",
    "        cov=np.eye(4)*0.5, \n",
    "        size=n_patients//3\n",
    "    )\n",
    "    \n",
    "    # Medium risk (n=50)\n",
    "    medium_risk = np.random.multivariate_normal(\n",
    "        mean=[5, 5, 5, 5], \n",
    "        cov=np.eye(4)*0.7, \n",
    "        size=n_patients//3\n",
    "    )\n",
    "    \n",
    "    # High risk (n=50)\n",
    "    high_risk = np.random.multivariate_normal(\n",
    "        mean=[8, 8, 9, 8], \n",
    "        cov=np.eye(4)*0.6, \n",
    "        size=n_patients//3\n",
    "    )\n",
    "    \n",
    "    # Combine data\n",
    "    X = np.vstack([low_risk, medium_risk, high_risk])\n",
    "    true_labels = np.concatenate([\n",
    "        np.zeros(n_patients//3),\n",
    "        np.ones(n_patients//3),\n",
    "        np.ones(n_patients//3)*2\n",
    "    ])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(X, columns=['Gene_Expression', 'Protein_Level', \n",
    "                                   'Mutation_Count', 'Pathway_Activity'])\n",
    "    df['True_Risk_Group'] = true_labels.astype(int)\n",
    "    \n",
    "    print(\"üß¨ Patient Data Generated\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total patients: {len(df)}\")\n",
    "    print(f\"Features: {df.columns[:-1].tolist()}\")\n",
    "    print(f\"\\nSummary by true risk group:\")\n",
    "    print(df.groupby('True_Risk_Group').mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "patient_df = generate_patient_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Perform K-means clustering for patient stratification\n",
    "def stratify_patients(df, n_clusters=3):\n",
    "    \"\"\"Stratify patients using K-means clustering\"\"\"\n",
    "    \n",
    "    # Extract features\n",
    "    X = df[['Gene_Expression', 'Protein_Level', 'Mutation_Count', 'Pathway_Activity']].values\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Add cluster assignments\n",
    "    df['Risk_Group'] = clusters\n",
    "    \n",
    "    # Map clusters to risk levels (based on cluster centers)\n",
    "    cluster_means = df.groupby('Risk_Group').mean()\n",
    "    risk_mapping = cluster_means['Gene_Expression'].argsort().argsort()\n",
    "    df['Risk_Level'] = df['Risk_Group'].map(risk_mapping)\n",
    "    \n",
    "    print(\"\\nüë• Patient Stratification Results\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nPatients per risk group:\")\n",
    "    print(df['Risk_Level'].value_counts().sort_index())\n",
    "    print(f\"\\nAverage characteristics by risk level:\")\n",
    "    print(df.groupby('Risk_Level')[['Gene_Expression', 'Protein_Level', \n",
    "                                      'Mutation_Count', 'Pathway_Activity']].mean())\n",
    "    \n",
    "    return df, X_scaled, kmeans\n",
    "\n",
    "patient_df, X_scaled, kmeans_model = stratify_patients(patient_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Visualize patient stratification with PCA\n",
    "def visualize_stratification(df, X_scaled):\n",
    "    \"\"\"Visualize patient stratification using PCA\"\"\"\n",
    "    \n",
    "    # Perform PCA for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Clustering results\n",
    "    risk_labels = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "    colors = ['green', 'orange', 'red']\n",
    "    \n",
    "    for i in range(3):\n",
    "        mask = df['Risk_Level'] == i\n",
    "        axes[0].scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                       c=colors[i], label=risk_labels[i], \n",
    "                       alpha=0.6, s=100, edgecolors='black')\n",
    "    \n",
    "    axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    axes[0].set_title('Patient Stratification (K-means Clustering)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: True risk groups (for comparison)\n",
    "    for i in range(3):\n",
    "        mask = df['True_Risk_Group'] == i\n",
    "        axes[1].scatter(X_pca[mask, 0], X_pca[mask, 1], \n",
    "                       c=colors[i], label=risk_labels[i], \n",
    "                       alpha=0.6, s=100, edgecolors='black')\n",
    "    \n",
    "    axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    axes[1].set_title('True Risk Groups (Reference)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ PCA explained variance: {pca.explained_variance_ratio_.sum():.1%}\")\n",
    "\n",
    "visualize_stratification(patient_df, X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Survival Analysis and Risk Prediction\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Perform Kaplan-Meier survival analysis\n",
    "- Compare survival curves between risk groups\n",
    "- Conduct log-rank test for statistical significance\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Survival Analysis:** Time-to-event analysis for patient outcomes\n",
    "**Kaplan-Meier Curve:** Non-parametric survival probability estimation\n",
    "**Log-rank Test:** Statistical test to compare survival distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Generate survival data for each risk group\n",
    "def generate_survival_data(df):\n",
    "    \"\"\"Generate survival time and event data based on risk groups\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    n_patients = len(df)\n",
    "    \n",
    "    # Generate survival times based on risk level\n",
    "    survival_times = []\n",
    "    events = []\n",
    "    \n",
    "    for risk_level in df['Risk_Level']:\n",
    "        if risk_level == 0:  # Low risk\n",
    "            time = np.random.exponential(scale=50, size=1)[0]\n",
    "            event = np.random.choice([0, 1], p=[0.3, 0.7])\n",
    "        elif risk_level == 1:  # Medium risk\n",
    "            time = np.random.exponential(scale=30, size=1)[0]\n",
    "            event = np.random.choice([0, 1], p=[0.5, 0.5])\n",
    "        else:  # High risk\n",
    "            time = np.random.exponential(scale=15, size=1)[0]\n",
    "            event = np.random.choice([0, 1], p=[0.7, 0.3])\n",
    "        \n",
    "        survival_times.append(min(time, 60))  # Censoring at 60 months\n",
    "        if time > 60:\n",
    "            event = 0  # Censored\n",
    "        events.append(event)\n",
    "    \n",
    "    df['Survival_Time'] = survival_times\n",
    "    df['Event'] = events  # 1 = event occurred, 0 = censored\n",
    "    \n",
    "    print(\"‚è±Ô∏è  Survival Data Summary\")\n",
    "    print(\"=\"*50)\n",
    "    for risk_level in [0, 1, 2]:\n",
    "        mask = df['Risk_Level'] == risk_level\n",
    "        risk_name = ['Low', 'Medium', 'High'][risk_level]\n",
    "        print(f\"\\n{risk_name} Risk Group:\")\n",
    "        print(f\"  Median survival: {df[mask]['Survival_Time'].median():.1f} months\")\n",
    "        print(f\"  Events: {df[mask]['Event'].sum()}/{len(df[mask])} ({df[mask]['Event'].mean():.1%})\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "patient_df = generate_survival_data(patient_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Kaplan-Meier survival analysis\n",
    "def kaplan_meier_analysis(df):\n",
    "    \"\"\"Perform Kaplan-Meier survival analysis by risk group\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    risk_labels = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "    colors = ['green', 'orange', 'red']\n",
    "    \n",
    "    kmf = KaplanMeierFitter()\n",
    "    \n",
    "    for i, (risk_level, color) in enumerate(zip([0, 1, 2], colors)):\n",
    "        mask = df['Risk_Level'] == risk_level\n",
    "        kmf.fit(df[mask]['Survival_Time'], \n",
    "                df[mask]['Event'], \n",
    "                label=risk_labels[i])\n",
    "        \n",
    "        kmf.plot_survival_function(color=color, linewidth=2.5)\n",
    "    \n",
    "    plt.xlabel('Time (months)', fontsize=12)\n",
    "    plt.ylabel('Survival Probability', fontsize=12)\n",
    "    plt.title('Kaplan-Meier Survival Curves by Risk Group', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best', fontsize=11)\n",
    "    plt.ylim([0, 1.05])\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Survival Analysis Complete\")\n",
    "\n",
    "kaplan_meier_analysis(patient_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Log-rank test for statistical comparison\n",
    "def perform_logrank_test(df):\n",
    "    \"\"\"Perform pairwise log-rank tests between risk groups\"\"\"\n",
    "    \n",
    "    print(\"\\nüìà Log-rank Test Results\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    comparisons = [(0, 1, 'Low vs Medium'),\n",
    "                   (0, 2, 'Low vs High'),\n",
    "                   (1, 2, 'Medium vs High')]\n",
    "    \n",
    "    for group1, group2, label in comparisons:\n",
    "        mask1 = df['Risk_Level'] == group1\n",
    "        mask2 = df['Risk_Level'] == group2\n",
    "        \n",
    "        result = logrank_test(\n",
    "            df[mask1]['Survival_Time'], \n",
    "            df[mask2]['Survival_Time'],\n",
    "            df[mask1]['Event'], \n",
    "            df[mask2]['Event']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{label}:\")\n",
    "        print(f\"  Test statistic: {result.test_statistic:.4f}\")\n",
    "        print(f\"  p-value: {result.p_value:.4f}\")\n",
    "        \n",
    "        if result.p_value < 0.001:\n",
    "            print(f\"  Result: *** Highly significant (p < 0.001)\")\n",
    "        elif result.p_value < 0.01:\n",
    "            print(f\"  Result: ** Very significant (p < 0.01)\")\n",
    "        elif result.p_value < 0.05:\n",
    "            print(f\"  Result: * Significant (p < 0.05)\")\n",
    "        else:\n",
    "            print(f\"  Result: Not significant (p >= 0.05)\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Statistical testing complete!\")\n",
    "\n",
    "perform_logrank_test(patient_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Multi-omics Data Integration\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Integrate multiple omics data types\n",
    "- Visualize multi-omics signatures\n",
    "- Identify coordinated biomarker patterns\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Multi-omics Integration:** Combining genomics, transcriptomics, proteomics, and metabolomics\n",
    "**Systems Biology Approach:** Holistic view of disease mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Generate comprehensive multi-omics dataset\n",
    "def generate_multiomics_data(n_patients=30):\n",
    "    \"\"\"Generate comprehensive multi-omics data\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create patient IDs\n",
    "    patient_ids = [f'P{i:03d}' for i in range(1, n_patients+1)]\n",
    "    \n",
    "    # Generate risk groups\n",
    "    risk_groups = np.repeat([0, 1, 2], n_patients//3)\n",
    "    \n",
    "    # Generate omics data\n",
    "    data = {\n",
    "        'Patient_ID': patient_ids,\n",
    "        'Risk_Group': risk_groups,\n",
    "        # Genomics\n",
    "        'TP53_Mutation': np.random.choice([0, 1], n_patients, p=[0.7, 0.3]),\n",
    "        'KRAS_Mutation': np.random.choice([0, 1], n_patients, p=[0.8, 0.2]),\n",
    "        'EGFR_Mutation': np.random.choice([0, 1], n_patients, p=[0.85, 0.15]),\n",
    "        # Transcriptomics (gene expression)\n",
    "        'Gene1_Expression': np.random.normal(5, 2, n_patients) + risk_groups * 2,\n",
    "        'Gene2_Expression': np.random.normal(6, 1.5, n_patients) + risk_groups * 1.5,\n",
    "        'Gene3_Expression': np.random.normal(4, 1.8, n_patients) + risk_groups * 2.5,\n",
    "        # Proteomics\n",
    "        'Protein1_Level': np.random.normal(100, 20, n_patients) + risk_groups * 30,\n",
    "        'Protein2_Level': np.random.normal(80, 15, n_patients) + risk_groups * 25,\n",
    "        # Metabolomics\n",
    "        'Metabolite1': np.random.normal(50, 10, n_patients) + risk_groups * 15,\n",
    "        'Metabolite2': np.random.normal(60, 12, n_patients) + risk_groups * 20,\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"üß¨ Multi-omics Dataset Generated\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total patients: {n_patients}\")\n",
    "    print(f\"\\nOmics layers:\")\n",
    "    print(\"  - Genomics: 3 mutation markers\")\n",
    "    print(\"  - Transcriptomics: 3 gene expression markers\")\n",
    "    print(\"  - Proteomics: 2 protein level markers\")\n",
    "    print(\"  - Metabolomics: 2 metabolite markers\")\n",
    "    print(f\"\\nRisk group distribution:\")\n",
    "    print(df['Risk_Group'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n",
    "\n",
    "multiomics_df = generate_multiomics_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Visualize multi-omics heatmap\n",
    "def plot_multiomics_heatmap(df):\n",
    "    \"\"\"Create comprehensive heatmap of multi-omics data\"\"\"\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    omics_features = ['TP53_Mutation', 'KRAS_Mutation', 'EGFR_Mutation',\n",
    "                      'Gene1_Expression', 'Gene2_Expression', 'Gene3_Expression',\n",
    "                      'Protein1_Level', 'Protein2_Level',\n",
    "                      'Metabolite1', 'Metabolite2']\n",
    "    \n",
    "    # Sort by risk group\n",
    "    df_sorted = df.sort_values('Risk_Group')\n",
    "    \n",
    "    # Standardize continuous features for visualization\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    heatmap_data = df_sorted[omics_features].copy()\n",
    "    continuous_features = ['Gene1_Expression', 'Gene2_Expression', 'Gene3_Expression',\n",
    "                          'Protein1_Level', 'Protein2_Level',\n",
    "                          'Metabolite1', 'Metabolite2']\n",
    "    heatmap_data[continuous_features] = scaler.fit_transform(heatmap_data[continuous_features])\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(heatmap_data.T, \n",
    "                cmap='RdYlBu_r', \n",
    "                center=0,\n",
    "                cbar_kws={'label': 'Standardized Value'},\n",
    "                yticklabels=omics_features,\n",
    "                xticklabels=False,\n",
    "                linewidths=0.5,\n",
    "                linecolor='gray',\n",
    "                ax=ax)\n",
    "    \n",
    "    # Add risk group annotations\n",
    "    risk_colors = df_sorted['Risk_Group'].map({0: 'green', 1: 'orange', 2: 'red'})\n",
    "    for i, color in enumerate(risk_colors):\n",
    "        ax.add_patch(plt.Rectangle((i, -0.5), 1, 0.3, color=color, clip_on=False))\n",
    "    \n",
    "    plt.title('Multi-omics Heatmap by Risk Group', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Patients (sorted by risk group)', fontsize=12)\n",
    "    plt.ylabel('Omics Features', fontsize=12)\n",
    "    \n",
    "    # Add legend for risk groups\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='green', label='Low Risk'),\n",
    "                      Patch(facecolor='orange', label='Medium Risk'),\n",
    "                      Patch(facecolor='red', label='High Risk')]\n",
    "    plt.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.15, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ Multi-omics heatmap generated!\")\n",
    "\n",
    "plot_multiomics_heatmap(multiomics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Biomarker Performance Metrics\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Calculate comprehensive biomarker performance metrics\n",
    "- Understand sensitivity, specificity, PPV, NPV\n",
    "- Evaluate clinical utility of biomarkers\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Sensitivity:** True Positive Rate (TPR)\n",
    "**Specificity:** True Negative Rate (TNR)\n",
    "**PPV:** Positive Predictive Value\n",
    "**NPV:** Negative Predictive Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Calculate comprehensive performance metrics\n",
    "def calculate_biomarker_metrics(df, cutoff):\n",
    "    \"\"\"Calculate all biomarker performance metrics\"\"\"\n",
    "    \n",
    "    # Make predictions based on cutoff\n",
    "    predictions = (df['Biomarker'] >= cutoff).astype(int)\n",
    "    true_labels = df['Disease_Status']\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, predictions).ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    sensitivity = tp / (tp + fn)  # True Positive Rate\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "    ppv = tp / (tp + fp)  # Positive Predictive Value\n",
    "    npv = tn / (tn + fn)  # Negative Predictive Value\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    print(\"\\nüìä Biomarker Performance Metrics\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Cutoff threshold: {cutoff:.2f}\\n\")\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"  True Negatives (TN):  {tn:3d}  |  False Positives (FP): {fp:3d}\")\n",
    "    print(f\"  False Negatives (FN): {fn:3d}  |  True Positives (TP):  {tp:3d}\")\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"  Sensitivity (Recall):    {sensitivity:.4f}  ({sensitivity*100:.2f}%)\")\n",
    "    print(f\"  Specificity:             {specificity:.4f}  ({specificity*100:.2f}%)\")\n",
    "    print(f\"  Positive Predictive Value: {ppv:.4f}  ({ppv*100:.2f}%)\")\n",
    "    print(f\"  Negative Predictive Value: {npv:.4f}  ({npv*100:.2f}%)\")\n",
    "    print(f\"  Accuracy:                {accuracy:.4f}  ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Visualize confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Predicted Healthy', 'Predicted Disease'],\n",
    "                yticklabels=['Actual Healthy', 'Actual Disease'],\n",
    "                cbar_kws={'label': 'Count'},\n",
    "                ax=ax)\n",
    "    plt.title(f'Confusion Matrix (Cutoff = {cutoff:.2f})', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'ppv': ppv,\n",
    "        'npv': npv,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "metrics = calculate_biomarker_metrics(biomarker_df, optimal_cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **ROC Curve Analysis**: Evaluated biomarker performance using ROC curves and calculated AUC\n",
    "2. **Patient Stratification**: Used K-means clustering to identify risk groups from multi-omics data\n",
    "3. **Survival Analysis**: Performed Kaplan-Meier analysis and log-rank tests for outcome prediction\n",
    "4. **Multi-omics Integration**: Combined genomics, transcriptomics, proteomics, and metabolomics data\n",
    "5. **Performance Metrics**: Calculated sensitivity, specificity, PPV, NPV for biomarker evaluation\n",
    "\n",
    "### Key Insights:\n",
    "- Biomarker validation requires multiple performance metrics, not just accuracy\n",
    "- Patient stratification enables personalized treatment approaches\n",
    "- Multi-omics integration provides comprehensive molecular profiles\n",
    "- Survival analysis is crucial for assessing clinical outcomes\n",
    "\n",
    "### Real-world Applications:\n",
    "- **HER2 Testing**: Selecting breast cancer patients for trastuzumab therapy\n",
    "- **MSI Status**: Identifying patients who respond to immunotherapy\n",
    "- **Liquid Biopsy**: Monitoring treatment response via ctDNA\n",
    "- **PD-L1 Expression**: Guiding checkpoint inhibitor therapy\n",
    "\n",
    "### Next Steps:\n",
    "- Implement machine learning models for biomarker discovery\n",
    "- Explore network biomarkers and pathway analysis\n",
    "- Study real clinical datasets (TCGA, GEO)\n",
    "- Learn about regulatory requirements for biomarker validation\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "**Key References:**\n",
    "- FDA-NIH Biomarker Working Group (2016). BEST (Biomarkers, EndpointS, and other Tools) Resource\n",
    "- Poste, G. (2011). Bring on the biomarkers. *Nature*, 469, 156-157\n",
    "- Simon, R. (2013). Clinical trials for predictive medicine. *Statistics in Medicine*, 32(25), 4361-4364\n",
    "\n",
    "**Useful Tools:**\n",
    "- `scikit-learn`: Machine learning for biomarker discovery\n",
    "- `lifelines`: Survival analysis in Python\n",
    "- `scikit-survival`: Survival analysis with ML\n",
    "- `scanpy`: Single-cell analysis\n",
    "\n",
    "**Databases:**\n",
    "- TCGA: The Cancer Genome Atlas\n",
    "- GEO: Gene Expression Omnibus\n",
    "- cBioPortal: Cancer genomics portal\n",
    "- ClinicalTrials.gov: Clinical trial information\n",
    "\n",
    "---\n",
    "\n",
    "### üéì Congratulations!\n",
    "\n",
    "You've completed the Precision Medicine & Biomarkers hands-on practice! You now have practical experience with:\n",
    "- Biomarker validation and performance evaluation\n",
    "- Patient stratification techniques\n",
    "- Survival analysis for clinical outcomes\n",
    "- Multi-omics data integration\n",
    "\n",
    "**Keep practicing and exploring real-world datasets to deepen your understanding!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
