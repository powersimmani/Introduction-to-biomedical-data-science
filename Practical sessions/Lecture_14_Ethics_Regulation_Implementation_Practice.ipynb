{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Ethics, Regulation, and Implementation: Practical Exercise\n",
    "\n",
    "## Table of Contents\n",
    "1. [Ethics Assessment Framework](#practice-1-ethics-assessment-framework)\n",
    "2. [Algorithmic Bias Detection](#practice-2-algorithmic-bias-detection)\n",
    "3. [Privacy and De-identification](#practice-3-privacy-and-de-identification)\n",
    "4. [Regulatory Compliance Checklist](#practice-4-regulatory-compliance-checklist)\n",
    "5. [Model Transparency and Explainability](#practice-5-model-transparency-and-explainability)\n",
    "6. [Risk Assessment Matrix](#practice-6-risk-assessment-matrix)\n",
    "7. [Clinical Integration Simulation](#practice-7-clinical-integration-simulation)\n",
    "8. [Cost-Benefit Analysis](#practice-8-cost-benefit-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Ethics Assessment Framework\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand key ethical principles in biomedical AI\n",
    "- Create a systematic ethics assessment framework\n",
    "- Evaluate AI systems against beneficence principles\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Beneficence Principles:** Do no harm, patient benefit, risk-benefit analysis, unintended consequences, precautionary principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Ethics Assessment Scorecard\n",
    "def create_ethics_scorecard():\n",
    "    \"\"\"\n",
    "    Create an ethics assessment scorecard for AI systems\n",
    "    \"\"\"\n",
    "    ethics_criteria = {\n",
    "        'Principle': [\n",
    "            'Do No Harm',\n",
    "            'Patient Benefit',\n",
    "            'Privacy Protection',\n",
    "            'Informed Consent',\n",
    "            'Fairness & Equity',\n",
    "            'Transparency',\n",
    "            'Accountability'\n",
    "        ],\n",
    "        'Weight': [0.20, 0.20, 0.15, 0.10, 0.15, 0.10, 0.10],\n",
    "        'Score': [0, 0, 0, 0, 0, 0, 0],  # To be filled\n",
    "        'Evidence': [''] * 7  # Supporting documentation\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(ethics_criteria)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"BIOMEDICAL AI ETHICS ASSESSMENT SCORECARD\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nScoring Guide: 1=Poor, 2=Fair, 3=Good, 4=Very Good, 5=Excellent\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Total Weight: {df['Weight'].sum():.2f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "ethics_df = create_ethics_scorecard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Example: Evaluate a hypothetical AI diagnostic system\n",
    "def evaluate_ai_system():\n",
    "    \"\"\"\n",
    "    Example evaluation of an AI diagnostic system\n",
    "    \"\"\"\n",
    "    # Example scores (in practice, these would come from thorough assessment)\n",
    "    example_scores = [4, 5, 3, 4, 3, 4, 5]\n",
    "    \n",
    "    ethics_df['Score'] = example_scores\n",
    "    ethics_df['Weighted_Score'] = ethics_df['Weight'] * ethics_df['Score']\n",
    "    \n",
    "    total_score = ethics_df['Weighted_Score'].sum()\n",
    "    max_possible = ethics_df['Weight'].sum() * 5\n",
    "    percentage = (total_score / max_possible) * 100\n",
    "    \n",
    "    print(\"\\nüìä EVALUATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(ethics_df[['Principle', 'Weight', 'Score', 'Weighted_Score']].to_string(index=False))\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTotal Weighted Score: {total_score:.2f} / {max_possible:.2f}\")\n",
    "    print(f\"Ethics Compliance: {percentage:.1f}%\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if percentage >= 80:\n",
    "        assessment = \"‚úÖ APPROVED - High ethical standards\"\n",
    "    elif percentage >= 60:\n",
    "        assessment = \"‚ö†Ô∏è CONDITIONAL - Improvements needed\"\n",
    "    else:\n",
    "        assessment = \"‚ùå NOT APPROVED - Significant ethical concerns\"\n",
    "    \n",
    "    print(f\"\\nAssessment: {assessment}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#28a745' if s >= 4 else '#ffc107' if s >= 3 else '#ff6b6b' for s in example_scores]\n",
    "    plt.barh(ethics_df['Principle'], ethics_df['Score'], color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Score (1-5)', fontsize=12, fontweight='bold')\n",
    "    plt.title('Ethics Assessment by Principle', fontsize=14, fontweight='bold')\n",
    "    plt.xlim(0, 5.5)\n",
    "    plt.axvline(x=3, color='orange', linestyle='--', alpha=0.5, label='Minimum Acceptable')\n",
    "    plt.axvline(x=4, color='green', linestyle='--', alpha=0.5, label='Target')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return ethics_df\n",
    "\n",
    "evaluated_df = evaluate_ai_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Algorithmic Bias Detection\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand sources of algorithmic bias\n",
    "- Measure fairness metrics across demographic groups\n",
    "- Implement bias mitigation strategies\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Fairness Metrics:** Demographic parity, equal opportunity, equalized odds, predictive parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Generate synthetic medical data with potential bias\n",
    "def generate_biased_medical_data(n_samples=1000):\n",
    "    \"\"\"\n",
    "    Generate synthetic patient data that may exhibit bias\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Demographics\n",
    "    age = np.random.normal(55, 15, n_samples).clip(18, 90)\n",
    "    gender = np.random.choice(['Male', 'Female'], n_samples)\n",
    "    ethnicity = np.random.choice(['Group_A', 'Group_B', 'Group_C'], n_samples, p=[0.6, 0.3, 0.1])\n",
    "    \n",
    "    # Clinical features\n",
    "    blood_pressure = np.random.normal(130, 20, n_samples).clip(90, 200)\n",
    "    cholesterol = np.random.normal(200, 40, n_samples).clip(100, 350)\n",
    "    bmi = np.random.normal(27, 5, n_samples).clip(18, 45)\n",
    "    \n",
    "    # Introduce bias: different baseline risks for different groups\n",
    "    risk_score = (\n",
    "        0.3 * (age - 18) / 72 + \n",
    "        0.2 * (blood_pressure - 90) / 110 +\n",
    "        0.2 * (cholesterol - 100) / 250 +\n",
    "        0.2 * (bmi - 18) / 27 +\n",
    "        (0.1 if gender == 'Male' else 0) +  # Gender bias\n",
    "        (0.15 if ethnicity == 'Group_C' else 0)  # Ethnicity bias (underrepresented)\n",
    "    )\n",
    "    \n",
    "    # Add noise\n",
    "    risk_score += np.random.normal(0, 0.1, n_samples)\n",
    "    \n",
    "    # Outcome: 1 = disease, 0 = no disease\n",
    "    disease = (risk_score > 0.6).astype(int)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'age': age.astype(int),\n",
    "        'gender': gender,\n",
    "        'ethnicity': ethnicity,\n",
    "        'blood_pressure': blood_pressure.round(1),\n",
    "        'cholesterol': cholesterol.round(1),\n",
    "        'bmi': bmi.round(1),\n",
    "        'risk_score': risk_score.round(3),\n",
    "        'disease': disease\n",
    "    })\n",
    "    \n",
    "    print(\"üìã Synthetic Medical Dataset Generated\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total Samples: {len(df)}\")\n",
    "    print(f\"\\nDisease Prevalence: {df['disease'].mean()*100:.1f}%\")\n",
    "    print(f\"\\nDemographic Distribution:\")\n",
    "    print(f\"  Gender: {df['gender'].value_counts().to_dict()}\")\n",
    "    print(f\"  Ethnicity: {df['ethnicity'].value_counts().to_dict()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "medical_data = generate_biased_medical_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Train model and detect bias\n",
    "def detect_algorithmic_bias(df):\n",
    "    \"\"\"\n",
    "    Train a model and assess bias across demographic groups\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    features = ['age', 'blood_pressure', 'cholesterol', 'bmi']\n",
    "    X = df[features]\n",
    "    y = df['disease']\n",
    "    \n",
    "    # Train model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get test set predictions\n",
    "    test_indices = X_test.index\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = df.loc[test_indices].copy()\n",
    "    results_df['predicted'] = predictions\n",
    "    results_df['actual'] = y_test.values\n",
    "    \n",
    "    print(\"\\nü§ñ MODEL PERFORMANCE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Overall Accuracy: {(predictions == y_test).mean()*100:.1f}%\")\n",
    "    \n",
    "    # Analyze bias by demographic groups\n",
    "    print(\"\\nüìä FAIRNESS ANALYSIS BY DEMOGRAPHIC GROUPS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for column in ['gender', 'ethnicity']:\n",
    "        print(f\"\\n{column.upper()} Analysis:\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        bias_metrics = []\n",
    "        \n",
    "        for group in results_df[column].unique():\n",
    "            group_data = results_df[results_df[column] == group]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = (group_data['predicted'] == group_data['actual']).mean()\n",
    "            \n",
    "            # True Positive Rate (Sensitivity)\n",
    "            positive_cases = group_data[group_data['actual'] == 1]\n",
    "            tpr = (positive_cases['predicted'] == 1).mean() if len(positive_cases) > 0 else 0\n",
    "            \n",
    "            # False Positive Rate\n",
    "            negative_cases = group_data[group_data['actual'] == 0]\n",
    "            fpr = (negative_cases['predicted'] == 1).mean() if len(negative_cases) > 0 else 0\n",
    "            \n",
    "            # Positive Prediction Rate\n",
    "            ppr = (group_data['predicted'] == 1).mean()\n",
    "            \n",
    "            bias_metrics.append({\n",
    "                'Group': group,\n",
    "                'Sample_Size': len(group_data),\n",
    "                'Accuracy': f\"{accuracy*100:.1f}%\",\n",
    "                'TPR': f\"{tpr*100:.1f}%\",\n",
    "                'FPR': f\"{fpr*100:.1f}%\",\n",
    "                'PPR': f\"{ppr*100:.1f}%\"\n",
    "            })\n",
    "        \n",
    "        bias_df = pd.DataFrame(bias_metrics)\n",
    "        print(bias_df.to_string(index=False))\n",
    "    \n",
    "    return model, results_df\n",
    "\n",
    "model, results_df = detect_algorithmic_bias(medical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Visualize bias across groups\n",
    "def visualize_bias(results_df):\n",
    "    \"\"\"\n",
    "    Create visualizations to illustrate potential bias\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Accuracy by Gender\n",
    "    gender_accuracy = results_df.groupby('gender').apply(\n",
    "        lambda x: (x['predicted'] == x['actual']).mean() * 100\n",
    "    )\n",
    "    axes[0].bar(gender_accuracy.index, gender_accuracy.values, \n",
    "                color=['#1E64C8', '#ff6b6b'], alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    axes[0].set_title('Model Accuracy by Gender', fontweight='bold', fontsize=13)\n",
    "    axes[0].set_ylim(0, 100)\n",
    "    axes[0].axhline(y=gender_accuracy.mean(), color='green', linestyle='--', \n",
    "                    alpha=0.5, label='Overall Mean')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Plot 2: Accuracy by Ethnicity\n",
    "    ethnicity_accuracy = results_df.groupby('ethnicity').apply(\n",
    "        lambda x: (x['predicted'] == x['actual']).mean() * 100\n",
    "    )\n",
    "    axes[1].bar(ethnicity_accuracy.index, ethnicity_accuracy.values,\n",
    "                color=['#28a745', '#ffc107', '#ff6b6b'], alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_ylabel('Accuracy (%)', fontweight='bold')\n",
    "    axes[1].set_title('Model Accuracy by Ethnicity', fontweight='bold', fontsize=13)\n",
    "    axes[1].set_ylim(0, 100)\n",
    "    axes[1].axhline(y=ethnicity_accuracy.mean(), color='green', linestyle='--',\n",
    "                    alpha=0.5, label='Overall Mean')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for significant disparities\n",
    "    print(\"\\n‚ö†Ô∏è BIAS ALERT SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    max_diff_gender = gender_accuracy.max() - gender_accuracy.min()\n",
    "    max_diff_ethnicity = ethnicity_accuracy.max() - ethnicity_accuracy.min()\n",
    "    \n",
    "    if max_diff_gender > 5:\n",
    "        print(f\"‚ùå Gender Bias Detected: {max_diff_gender:.1f}% difference in accuracy\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Gender Fairness: Only {max_diff_gender:.1f}% difference in accuracy\")\n",
    "    \n",
    "    if max_diff_ethnicity > 5:\n",
    "        print(f\"‚ùå Ethnicity Bias Detected: {max_diff_ethnicity:.1f}% difference in accuracy\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Ethnicity Fairness: Only {max_diff_ethnicity:.1f}% difference in accuracy\")\n",
    "\n",
    "visualize_bias(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Privacy and De-identification\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand privacy concerns in biomedical data\n",
    "- Implement basic de-identification techniques\n",
    "- Assess re-identification risks\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Privacy Protection:** Data sensitivity, re-identification risks, anonymization techniques, k-anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Create sample patient data with identifiers\n",
    "def create_identifiable_data():\n",
    "    \"\"\"\n",
    "    Create sample patient data with personal identifiers\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n = 10\n",
    "    \n",
    "    data = {\n",
    "        'patient_id': [f'PT{i:04d}' for i in range(1, n+1)],\n",
    "        'name': ['John Doe', 'Jane Smith', 'Bob Johnson', 'Alice Williams', 'Charlie Brown',\n",
    "                 'Diana Prince', 'Eve Davis', 'Frank Miller', 'Grace Lee', 'Henry Wilson'],\n",
    "        'ssn': [f'{np.random.randint(100,999)}-{np.random.randint(10,99)}-{np.random.randint(1000,9999)}' \n",
    "                for _ in range(n)],\n",
    "        'dob': pd.date_range('1950-01-01', '1990-12-31', periods=n),\n",
    "        'zip_code': [np.random.randint(10000, 99999) for _ in range(n)],\n",
    "        'diagnosis': np.random.choice(['Diabetes', 'Hypertension', 'Heart Disease'], n),\n",
    "        'treatment_cost': np.random.randint(5000, 50000, n)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"üîì ORIGINAL DATA (Identifiable)\")\n",
    "    print(\"=\"*90)\n",
    "    print(\"‚ö†Ô∏è WARNING: This data contains Personal Health Information (PHI)\")\n",
    "    print(\"=\"*90)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "identifiable_df = create_identifiable_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 De-identification techniques\n",
    "def deidentify_data(df):\n",
    "    \"\"\"\n",
    "    Apply de-identification techniques to protect patient privacy\n",
    "    \"\"\"\n",
    "    deidentified = df.copy()\n",
    "    \n",
    "    print(\"\\nüîí APPLYING DE-IDENTIFICATION TECHNIQUES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 1. Remove direct identifiers\n",
    "    print(\"\\n1Ô∏è‚É£ Removing Direct Identifiers:\")\n",
    "    direct_identifiers = ['patient_id', 'name', 'ssn']\n",
    "    deidentified = deidentified.drop(columns=direct_identifiers)\n",
    "    print(f\"   Removed: {', '.join(direct_identifiers)}\")\n",
    "    \n",
    "    # 2. Generalize dates (only keep year)\n",
    "    print(\"\\n2Ô∏è‚É£ Generalizing Dates:\")\n",
    "    deidentified['birth_year'] = pd.to_datetime(df['dob']).dt.year\n",
    "    deidentified = deidentified.drop(columns=['dob'])\n",
    "    print(\"   Date of Birth ‚Üí Birth Year only\")\n",
    "    \n",
    "    # 3. Generalize ZIP codes (first 3 digits only)\n",
    "    print(\"\\n3Ô∏è‚É£ Generalizing Geographic Data:\")\n",
    "    deidentified['zip_prefix'] = (df['zip_code'] // 100).astype(str) + 'XX'\n",
    "    deidentified = deidentified.drop(columns=['zip_code'])\n",
    "    print(\"   5-digit ZIP ‚Üí 3-digit prefix (e.g., 123XX)\")\n",
    "    \n",
    "    # 4. Add noise to numerical data\n",
    "    print(\"\\n4Ô∏è‚É£ Adding Statistical Noise:\")\n",
    "    noise = np.random.normal(0, 500, len(deidentified))\n",
    "    deidentified['treatment_cost'] = (df['treatment_cost'] + noise).round(-2).astype(int)\n",
    "    print(\"   Treatment Cost: Added random noise (¬±$500)\")\n",
    "    \n",
    "    # 5. Assign anonymous IDs\n",
    "    print(\"\\n5Ô∏è‚É£ Creating Anonymous Identifiers:\")\n",
    "    deidentified.insert(0, 'anonymous_id', [f'ANON{i:04d}' for i in range(1, len(deidentified)+1)])\n",
    "    print(\"   Generated anonymous IDs\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ DE-IDENTIFICATION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nüîí DE-IDENTIFIED DATA:\")\n",
    "    print(deidentified.to_string(index=False))\n",
    "    \n",
    "    return deidentified\n",
    "\n",
    "deidentified_df = deidentify_data(identifiable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Privacy risk assessment\n",
    "def assess_privacy_risk(original_df, deidentified_df):\n",
    "    \"\"\"\n",
    "    Assess the privacy protection level of de-identified data\n",
    "    \"\"\"\n",
    "    print(\"\\nüõ°Ô∏è PRIVACY PROTECTION ASSESSMENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Count remaining identifiers\n",
    "    phi_removed = ['patient_id', 'name', 'ssn', 'dob', 'zip_code']\n",
    "    quasi_identifiers = ['birth_year', 'zip_prefix', 'diagnosis']\n",
    "    \n",
    "    print(\"\\n‚úÖ Direct Identifiers Removed:\")\n",
    "    for identifier in phi_removed:\n",
    "        print(f\"   ‚Ä¢ {identifier}\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è Quasi-Identifiers Remaining:\")\n",
    "    for identifier in quasi_identifiers:\n",
    "        if identifier in deidentified_df.columns:\n",
    "            print(f\"   ‚Ä¢ {identifier}\")\n",
    "    \n",
    "    # Calculate k-anonymity\n",
    "    # Group by quasi-identifiers\n",
    "    grouped = deidentified_df.groupby(quasi_identifiers).size()\n",
    "    k_value = grouped.min()\n",
    "    \n",
    "    print(f\"\\nüìä K-Anonymity Level: {k_value}\")\n",
    "    print(f\"   (Each record is indistinguishable from at least {k_value-1} other records)\")\n",
    "    \n",
    "    # Risk assessment\n",
    "    if k_value >= 5:\n",
    "        risk = \"LOW\"\n",
    "        color = \"‚úÖ\"\n",
    "    elif k_value >= 3:\n",
    "        risk = \"MODERATE\"\n",
    "        color = \"‚ö†Ô∏è\"\n",
    "    else:\n",
    "        risk = \"HIGH\"\n",
    "        color = \"‚ùå\"\n",
    "    \n",
    "    print(f\"\\n{color} Re-identification Risk: {risk}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RECOMMENDATIONS:\")\n",
    "    print(\"=\"*70)\n",
    "    if k_value < 5:\n",
    "        print(\"‚ö†Ô∏è Consider further generalization of quasi-identifiers\")\n",
    "        print(\"‚ö†Ô∏è Implement additional privacy-preserving techniques (e.g., l-diversity)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Current de-identification level is acceptable for research use\")\n",
    "    print(\"‚úÖ Implement data use agreements and access controls\")\n",
    "    print(\"‚úÖ Regular privacy impact assessments recommended\")\n",
    "\n",
    "assess_privacy_risk(identifiable_df, deidentified_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Regulatory Compliance Checklist\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand FDA and CE marking requirements\n",
    "- Create a compliance assessment framework\n",
    "- Identify regulatory pathway for AI medical devices\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Regulatory Pathways:** FDA (510(k), De Novo, PMA), CE Marking (MDR), Software as Medical Device (SaMD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Regulatory pathway decision tool\n",
    "def determine_regulatory_pathway():\n",
    "    \"\"\"\n",
    "    Interactive tool to determine appropriate regulatory pathway\n",
    "    \"\"\"\n",
    "    print(\"üèõÔ∏è REGULATORY PATHWAY DECISION TOOL\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nAnswer the following questions to determine the appropriate pathway:\\n\")\n",
    "    \n",
    "    # Simulated answers (in real use, these would be interactive inputs)\n",
    "    device_questions = {\n",
    "        'Is this a medical device?': 'Yes',\n",
    "        'Does it use AI/ML?': 'Yes',\n",
    "        'Risk level (Low/Moderate/High)?': 'Moderate',\n",
    "        'Is there a predicate device?': 'Yes',\n",
    "        'Intended use': 'Diagnostic support',\n",
    "        'Target market': 'US and EU'\n",
    "    }\n",
    "    \n",
    "    for question, answer in device_questions.items():\n",
    "        print(f\"Q: {question}\")\n",
    "        print(f\"A: {answer}\")\n",
    "        print()\n",
    "    \n",
    "    # Decision logic\n",
    "    print(\"=\"*70)\n",
    "    print(\"üìã RECOMMENDED REGULATORY PATHWAYS:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # US FDA\n",
    "    print(\"\\nüá∫üá∏ United States (FDA):\")\n",
    "    if device_questions['Is there a predicate device?'] == 'Yes':\n",
    "        print(\"   ‚úÖ 510(k) Premarket Notification\")\n",
    "        print(\"      - Demonstrate substantial equivalence to predicate\")\n",
    "        print(\"      - Typical timeline: 3-6 months\")\n",
    "        print(\"      - Cost: $50,000-$150,000\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ De Novo Classification\")\n",
    "        print(\"      - For novel, low-moderate risk devices\")\n",
    "        print(\"      - Typical timeline: 6-12 months\")\n",
    "    \n",
    "    # EU CE Marking\n",
    "    print(\"\\nüá™üá∫ European Union (CE Marking):\")\n",
    "    if device_questions['Risk level (Low/Moderate/High)?'] == 'Moderate':\n",
    "        print(\"   ‚úÖ Class IIa or IIb Medical Device\")\n",
    "        print(\"      - Notified Body involvement required\")\n",
    "        print(\"      - Clinical evaluation report needed\")\n",
    "        print(\"      - Technical documentation per MDR 2017/745\")\n",
    "    \n",
    "    return device_questions\n",
    "\n",
    "pathway_info = determine_regulatory_pathway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Compliance checklist generator\n",
    "def generate_compliance_checklist():\n",
    "    \"\"\"\n",
    "    Generate a comprehensive compliance checklist\n",
    "    \"\"\"\n",
    "    checklist_items = {\n",
    "        'Category': [],\n",
    "        'Requirement': [],\n",
    "        'Status': [],\n",
    "        'Priority': [],\n",
    "        'Notes': []\n",
    "    }\n",
    "    \n",
    "    # FDA Requirements\n",
    "    fda_items = [\n",
    "        ('Software as Medical Device (SaMD) Classification', 'Not Started', 'High', ''),\n",
    "        ('Design Controls (21 CFR 820.30)', 'In Progress', 'High', 'DHF in development'),\n",
    "        ('Risk Management File (ISO 14971)', 'Not Started', 'High', ''),\n",
    "        ('Clinical Validation Studies', 'In Progress', 'High', 'Protocol approved'),\n",
    "        ('Cybersecurity Documentation', 'Not Started', 'Medium', ''),\n",
    "        ('510(k) Submission Preparation', 'Not Started', 'High', '')\n",
    "    ]\n",
    "    \n",
    "    for item, status, priority, notes in fda_items:\n",
    "        checklist_items['Category'].append('FDA')\n",
    "        checklist_items['Requirement'].append(item)\n",
    "        checklist_items['Status'].append(status)\n",
    "        checklist_items['Priority'].append(priority)\n",
    "        checklist_items['Notes'].append(notes)\n",
    "    \n",
    "    # EU MDR Requirements\n",
    "    mdr_items = [\n",
    "        ('Technical Documentation', 'In Progress', 'High', 'Annex II & III'),\n",
    "        ('Clinical Evaluation Report', 'Not Started', 'High', ''),\n",
    "        ('Post-Market Surveillance Plan', 'Not Started', 'High', ''),\n",
    "        ('Quality Management System (ISO 13485)', 'In Progress', 'High', 'Certification pending'),\n",
    "        ('Notified Body Selection', 'Not Started', 'Medium', '')\n",
    "    ]\n",
    "    \n",
    "    for item, status, priority, notes in mdr_items:\n",
    "        checklist_items['Category'].append('EU MDR')\n",
    "        checklist_items['Requirement'].append(item)\n",
    "        checklist_items['Status'].append(status)\n",
    "        checklist_items['Priority'].append(priority)\n",
    "        checklist_items['Notes'].append(notes)\n",
    "    \n",
    "    # Ethics & Privacy\n",
    "    ethics_items = [\n",
    "        ('Ethics Committee Approval', 'Complete', 'High', 'IRB approved'),\n",
    "        ('Data Privacy Impact Assessment', 'In Progress', 'High', 'GDPR compliance'),\n",
    "        ('Informed Consent Process', 'Complete', 'High', ''),\n",
    "        ('Algorithmic Bias Assessment', 'In Progress', 'Medium', 'Ongoing monitoring')\n",
    "    ]\n",
    "    \n",
    "    for item, status, priority, notes in ethics_items:\n",
    "        checklist_items['Category'].append('Ethics')\n",
    "        checklist_items['Requirement'].append(item)\n",
    "        checklist_items['Status'].append(status)\n",
    "        checklist_items['Priority'].append(priority)\n",
    "        checklist_items['Notes'].append(notes)\n",
    "    \n",
    "    df = pd.DataFrame(checklist_items)\n",
    "    \n",
    "    print(\"\\nüìã REGULATORY COMPLIANCE CHECKLIST\")\n",
    "    print(\"=\"*100)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"PROGRESS SUMMARY:\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    status_counts = df['Status'].value_counts()\n",
    "    total = len(df)\n",
    "    \n",
    "    for status in ['Complete', 'In Progress', 'Not Started']:\n",
    "        count = status_counts.get(status, 0)\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"{status:15s}: {count:2d} items ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Priority breakdown\n",
    "    print(\"\\nPRIORITY BREAKDOWN:\")\n",
    "    priority_counts = df['Priority'].value_counts()\n",
    "    for priority in ['High', 'Medium', 'Low']:\n",
    "        count = priority_counts.get(priority, 0)\n",
    "        print(f\"{priority:10s}: {count:2d} items\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "compliance_df = generate_compliance_checklist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Model Transparency and Explainability\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand the importance of AI transparency\n",
    "- Implement basic explainability techniques\n",
    "- Create audit trails for clinical decisions\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Transparency:** Model explainability, decision rationale, uncertainty communication, audit trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Feature importance analysis\n",
    "def analyze_feature_importance(model, feature_names):\n",
    "    \"\"\"\n",
    "    Analyze and visualize feature importance for transparency\n",
    "    \"\"\"\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    print(\"\\nüîç MODEL TRANSPARENCY REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nFeature Importance Analysis:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': [feature_names[i] for i in indices],\n",
    "        'Importance': [importances[i] for i in indices],\n",
    "        'Percentage': [f\"{importances[i]*100:.1f}%\" for i in indices]\n",
    "    })\n",
    "    \n",
    "    print(importance_df.to_string(index=False))\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_names)))\n",
    "    plt.barh(range(len(indices)), importances[indices], color=colors, alpha=0.8, edgecolor='black')\n",
    "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance', fontweight='bold', fontsize=12)\n",
    "    plt.title('Feature Importance for Clinical Decision Support', fontweight='bold', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "feature_names = ['age', 'blood_pressure', 'cholesterol', 'bmi']\n",
    "importance_df = analyze_feature_importance(model, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Generate clinical decision explanation\n",
    "def generate_decision_explanation(patient_data, prediction, feature_importance):\n",
    "    \"\"\"\n",
    "    Generate human-readable explanation for a clinical decision\n",
    "    \"\"\"\n",
    "    print(\"\\nüìÑ CLINICAL DECISION EXPLANATION REPORT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Example patient\n",
    "    example_patient = {\n",
    "        'age': 65,\n",
    "        'blood_pressure': 145,\n",
    "        'cholesterol': 240,\n",
    "        'bmi': 29.5\n",
    "    }\n",
    "    \n",
    "    print(\"\\nPATIENT PROFILE:\")\n",
    "    print(\"-\" * 70)\n",
    "    for feature, value in example_patient.items():\n",
    "        print(f\"  {feature.replace('_', ' ').title():20s}: {value}\")\n",
    "    \n",
    "    # Simulate prediction\n",
    "    risk_probability = 0.72  # Simulated\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PREDICTION:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n  Disease Risk: {'HIGH' if risk_probability > 0.6 else 'LOW'}\")\n",
    "    print(f\"  Probability: {risk_probability*100:.1f}%\")\n",
    "    print(f\"  Confidence: {'High' if risk_probability > 0.7 or risk_probability < 0.3 else 'Moderate'}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CONTRIBUTING FACTORS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nThe model's decision was primarily influenced by:\")\n",
    "    print(\"\\n  1Ô∏è‚É£ Age (65 years) - Higher risk factor\")\n",
    "    print(\"      ‚Üí Above 60 years significantly increases disease risk\")\n",
    "    print(\"\\n  2Ô∏è‚É£ Blood Pressure (145 mmHg) - Elevated\")\n",
    "    print(\"      ‚Üí Above normal range (120-130 mmHg)\")\n",
    "    print(\"\\n  3Ô∏è‚É£ Cholesterol (240 mg/dL) - High\")\n",
    "    print(\"      ‚Üí Exceeds recommended level (<200 mg/dL)\")\n",
    "    print(\"\\n  4Ô∏è‚É£ BMI (29.5) - Overweight\")\n",
    "    print(\"      ‚Üí Above normal range (18.5-24.9)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CLINICAL RECOMMENDATIONS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n  ‚úÖ Schedule comprehensive cardiovascular evaluation\")\n",
    "    print(\"  ‚úÖ Consider lifestyle modifications (diet, exercise)\")\n",
    "    print(\"  ‚úÖ Monitor blood pressure and cholesterol levels\")\n",
    "    print(\"  ‚úÖ Discuss potential medication options with physician\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"IMPORTANT DISCLAIMERS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n  ‚ö†Ô∏è This AI system is a clinical decision support tool\")\n",
    "    print(\"  ‚ö†Ô∏è Not a substitute for professional medical judgment\")\n",
    "    print(\"  ‚ö†Ô∏è Final decisions must be made by qualified healthcare providers\")\n",
    "    print(\"  ‚ö†Ô∏è Consider patient's complete medical history and context\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"AUDIT INFORMATION:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n  Model Version: v2.1.0\")\n",
    "    print(f\"  Date: 2024-01-15 14:30:22\")\n",
    "    print(f\"  Operator ID: DR_SMITH_001\")\n",
    "    print(f\"  Session ID: 7a3f9c2e-8b1d-4e5f-9c3a-1b2e4d5c6f7a\")\n",
    "\n",
    "generate_decision_explanation(None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: Risk Assessment Matrix\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand risk management frameworks (ISO 14971)\n",
    "- Create and populate a risk assessment matrix\n",
    "- Identify mitigation strategies for high-risk scenarios\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Risk Management:** Hazard identification, severity assessment, probability estimation, risk control measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Create risk assessment matrix\n",
    "def create_risk_matrix():\n",
    "    \"\"\"\n",
    "    Create a comprehensive risk assessment matrix for AI medical device\n",
    "    \"\"\"\n",
    "    risks = {\n",
    "        'Risk_ID': ['R001', 'R002', 'R003', 'R004', 'R005', 'R006', 'R007'],\n",
    "        'Hazard': [\n",
    "            'False Negative Prediction',\n",
    "            'False Positive Prediction',\n",
    "            'Data Privacy Breach',\n",
    "            'Algorithm Bias',\n",
    "            'Software Malfunction',\n",
    "            'Incorrect Data Input',\n",
    "            'Cybersecurity Attack'\n",
    "        ],\n",
    "        'Potential_Harm': [\n",
    "            'Missed diagnosis, delayed treatment',\n",
    "            'Unnecessary treatment, patient anxiety',\n",
    "            'Privacy violation, legal liability',\n",
    "            'Inequitable healthcare outcomes',\n",
    "            'Incorrect clinical decisions',\n",
    "            'Misdiagnosis, wrong treatment',\n",
    "            'System unavailability, data theft'\n",
    "        ],\n",
    "        'Severity': [5, 3, 4, 4, 5, 5, 4],  # 1=Negligible, 5=Catastrophic\n",
    "        'Probability': [3, 4, 2, 3, 2, 3, 2],  # 1=Remote, 5=Frequent\n",
    "        'Detectability': [4, 3, 5, 4, 3, 3, 4]  # 1=High, 5=Low\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(risks)\n",
    "    \n",
    "    # Calculate Risk Priority Number (RPN)\n",
    "    df['RPN'] = df['Severity'] * df['Probability'] * df['Detectability']\n",
    "    \n",
    "    # Determine risk level\n",
    "    def risk_level(rpn):\n",
    "        if rpn >= 80:\n",
    "            return 'CRITICAL'\n",
    "        elif rpn >= 40:\n",
    "            return 'HIGH'\n",
    "        elif rpn >= 20:\n",
    "            return 'MEDIUM'\n",
    "        else:\n",
    "            return 'LOW'\n",
    "    \n",
    "    df['Risk_Level'] = df['RPN'].apply(risk_level)\n",
    "    \n",
    "    # Sort by RPN (highest risk first)\n",
    "    df = df.sort_values('RPN', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è RISK ASSESSMENT MATRIX (ISO 14971)\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"\\nRisk Priority Number (RPN) = Severity √ó Probability √ó Detectability\")\n",
    "    print(\"Scale: 1 (Lowest) to 5 (Highest)\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"RISK SUMMARY:\")\n",
    "    print(\"=\"*100)\n",
    "    risk_counts = df['Risk_Level'].value_counts()\n",
    "    for level in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:\n",
    "        count = risk_counts.get(level, 0)\n",
    "        emoji = 'üî¥' if level == 'CRITICAL' else 'üü†' if level == 'HIGH' else 'üü°' if level == 'MEDIUM' else 'üü¢'\n",
    "        print(f\"{emoji} {level:10s}: {count} risk(s)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "risk_df = create_risk_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Visualize risk matrix\n",
    "def visualize_risk_matrix(risk_df):\n",
    "    \"\"\"\n",
    "    Create visual representation of risk matrix\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Risk Priority Numbers\n",
    "    colors = ['#ff3333' if x >= 80 else '#ff9933' if x >= 40 else '#ffcc33' if x >= 20 else '#99cc33' \n",
    "              for x in risk_df['RPN']]\n",
    "    \n",
    "    ax1.barh(risk_df['Risk_ID'], risk_df['RPN'], color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Risk Priority Number (RPN)', fontweight='bold', fontsize=12)\n",
    "    ax1.set_title('Risk Assessment: Priority Ranking', fontweight='bold', fontsize=14)\n",
    "    ax1.axvline(x=80, color='red', linestyle='--', alpha=0.5, label='Critical Threshold')\n",
    "    ax1.axvline(x=40, color='orange', linestyle='--', alpha=0.5, label='High Threshold')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: Severity vs Probability Matrix\n",
    "    scatter_colors = {'CRITICAL': '#ff3333', 'HIGH': '#ff9933', 'MEDIUM': '#ffcc33', 'LOW': '#99cc33'}\n",
    "    for level in risk_df['Risk_Level'].unique():\n",
    "        mask = risk_df['Risk_Level'] == level\n",
    "        ax2.scatter(risk_df[mask]['Probability'], \n",
    "                   risk_df[mask]['Severity'],\n",
    "                   c=scatter_colors[level],\n",
    "                   s=200,\n",
    "                   alpha=0.6,\n",
    "                   edgecolors='black',\n",
    "                   linewidth=1.5,\n",
    "                   label=level)\n",
    "    \n",
    "    # Add risk zones\n",
    "    ax2.axhline(y=4, color='red', linestyle='--', alpha=0.3)\n",
    "    ax2.axvline(x=3, color='red', linestyle='--', alpha=0.3)\n",
    "    ax2.fill_between([3, 5], 4, 5, alpha=0.1, color='red')\n",
    "    ax2.text(4, 4.5, 'High Risk Zone', fontsize=10, ha='center', alpha=0.5)\n",
    "    \n",
    "    ax2.set_xlabel('Probability', fontweight='bold', fontsize=12)\n",
    "    ax2.set_ylabel('Severity', fontweight='bold', fontsize=12)\n",
    "    ax2.set_title('Risk Matrix: Severity vs Probability', fontweight='bold', fontsize=14)\n",
    "    ax2.set_xlim(0.5, 5.5)\n",
    "    ax2.set_ylim(0.5, 5.5)\n",
    "    ax2.set_xticks(range(1, 6))\n",
    "    ax2.set_yticks(range(1, 6))\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_risk_matrix(risk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Risk mitigation strategies\n",
    "def generate_mitigation_plan(risk_df):\n",
    "    \"\"\"\n",
    "    Generate risk mitigation strategies for high-priority risks\n",
    "    \"\"\"\n",
    "    print(\"\\nüõ°Ô∏è RISK MITIGATION PLAN\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    # Focus on HIGH and CRITICAL risks\n",
    "    high_risks = risk_df[risk_df['Risk_Level'].isin(['HIGH', 'CRITICAL'])]\n",
    "    \n",
    "    mitigation_strategies = {\n",
    "        'R001': [\n",
    "            'Implement confidence thresholds for predictions',\n",
    "            'Require human oversight for borderline cases',\n",
    "            'Regular validation against gold standard datasets',\n",
    "            'Alert system for low-confidence predictions'\n",
    "        ],\n",
    "        'R005': [\n",
    "            'Comprehensive software testing (unit, integration, system)',\n",
    "            'Redundancy and failsafe mechanisms',\n",
    "            'Real-time monitoring and error logging',\n",
    "            'Regular software updates and patches'\n",
    "        ],\n",
    "        'R006': [\n",
    "            'Input validation and range checking',\n",
    "            'User training on data entry procedures',\n",
    "            'Double-check system for critical values',\n",
    "            'Automated data quality checks'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for _, risk in high_risks.iterrows():\n",
    "        risk_id = risk['Risk_ID']\n",
    "        print(f\"\\n{risk['Risk_Level']} RISK: {risk_id}\")\n",
    "        print(\"-\" * 90)\n",
    "        print(f\"Hazard: {risk['Hazard']}\")\n",
    "        print(f\"RPN: {risk['RPN']} (Severity={risk['Severity']}, Probability={risk['Probability']}, \"\n",
    "              f\"Detectability={risk['Detectability']})\")\n",
    "        \n",
    "        if risk_id in mitigation_strategies:\n",
    "            print(\"\\nMitigation Strategies:\")\n",
    "            for i, strategy in enumerate(mitigation_strategies[risk_id], 1):\n",
    "                print(f\"  {i}. {strategy}\")\n",
    "        \n",
    "        print(f\"\\nTarget RPN: <40 (Reduce to LOW-MEDIUM risk)\")\n",
    "        print(f\"Review Date: Quarterly\")\n",
    "        print(f\"Responsible: Quality Assurance Team\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"‚úÖ All high-priority risks must be mitigated before market release\")\n",
    "    print(\"‚úÖ Regular risk reviews required throughout product lifecycle\")\n",
    "\n",
    "generate_mitigation_plan(risk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 7: Clinical Integration Simulation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand clinical workflow integration challenges\n",
    "- Simulate change management process\n",
    "- Assess training and adoption readiness\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Implementation:** Workflow analysis, system interfaces, pilot testing, stakeholder engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Clinical workflow integration assessment\n",
    "def assess_workflow_integration():\n",
    "    \"\"\"\n",
    "    Assess readiness for clinical workflow integration\n",
    "    \"\"\"\n",
    "    print(\"\\nüè• CLINICAL INTEGRATION READINESS ASSESSMENT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    integration_phases = {\n",
    "        'Phase': ['Planning', 'Development', 'Training', 'Testing', 'Deployment'],\n",
    "        'Status': ['Complete', 'Complete', 'In Progress', 'Not Started', 'Not Started'],\n",
    "        'Completion': [100, 100, 60, 0, 0],\n",
    "        'Duration_Weeks': [4, 12, 6, 4, 8],\n",
    "        'Key_Activities': [\n",
    "            'Workflow analysis, stakeholder mapping',\n",
    "            'System integration, interface development',\n",
    "            'User training, competency assessment',\n",
    "            'Pilot testing, performance validation',\n",
    "            'Full-scale rollout, monitoring'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(integration_phases)\n",
    "    \n",
    "    print(\"\\nIntegration Timeline:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Calculate overall progress\n",
    "    total_completion = (df['Completion'] * df['Duration_Weeks']).sum() / df['Duration_Weeks'].sum()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Overall Progress: {total_completion:.1f}%\")\n",
    "    print(f\"Estimated Time to Completion: {df[df['Status'] != 'Complete']['Duration_Weeks'].sum()} weeks\")\n",
    "    \n",
    "    # Visualize progress\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Progress bar chart\n",
    "    colors = ['#28a745' if s == 'Complete' else '#ffc107' if s == 'In Progress' else '#cccccc' \n",
    "              for s in df['Status']]\n",
    "    ax1.barh(df['Phase'], df['Completion'], color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('Completion (%)', fontweight='bold')\n",
    "    ax1.set_title('Integration Phase Progress', fontweight='bold', fontsize=13)\n",
    "    ax1.set_xlim(0, 100)\n",
    "    \n",
    "    # Timeline Gantt-style\n",
    "    y_pos = np.arange(len(df))\n",
    "    start_weeks = [0, 4, 16, 22, 26]\n",
    "    for i, (phase, duration, status) in enumerate(zip(df['Phase'], df['Duration_Weeks'], df['Status'])):\n",
    "        color = '#28a745' if status == 'Complete' else '#ffc107' if status == 'In Progress' else '#cccccc'\n",
    "        ax2.barh(i, duration, left=start_weeks[i], color=color, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    ax2.set_yticks(y_pos)\n",
    "    ax2.set_yticklabels(df['Phase'])\n",
    "    ax2.set_xlabel('Timeline (Weeks)', fontweight='bold')\n",
    "    ax2.set_title('Integration Timeline', fontweight='bold', fontsize=13)\n",
    "    ax2.axvline(x=22, color='red', linestyle='--', alpha=0.5, label='Current Week')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "integration_df = assess_workflow_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Stakeholder engagement and training assessment\n",
    "def assess_stakeholder_readiness():\n",
    "    \"\"\"\n",
    "    Assess stakeholder engagement and training readiness\n",
    "    \"\"\"\n",
    "    print(\"\\nüë• STAKEHOLDER READINESS ASSESSMENT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    stakeholders = {\n",
    "        'Stakeholder_Group': [\n",
    "            'Physicians',\n",
    "            'Nurses',\n",
    "            'IT Support Staff',\n",
    "            'Hospital Administrators',\n",
    "            'Quality Assurance'\n",
    "        ],\n",
    "        'Training_Completed': [15, 42, 8, 5, 6],\n",
    "        'Training_Required': [20, 50, 10, 8, 8],\n",
    "        'Competency_Pass_Rate': [93, 88, 100, 80, 100],\n",
    "        'Engagement_Level': ['High', 'High', 'Medium', 'Medium', 'High']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(stakeholders)\n",
    "    df['Training_Progress_%'] = (df['Training_Completed'] / df['Training_Required'] * 100).round(1)\n",
    "    df['Status'] = df['Training_Progress_%'].apply(\n",
    "        lambda x: 'Complete' if x == 100 else 'On Track' if x >= 70 else 'Behind'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining Progress by Stakeholder Group:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Overall metrics\n",
    "    total_completed = df['Training_Completed'].sum()\n",
    "    total_required = df['Training_Required'].sum()\n",
    "    overall_progress = (total_completed / total_required) * 100\n",
    "    avg_pass_rate = df['Competency_Pass_Rate'].mean()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"OVERALL TRAINING METRICS:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total Training Progress: {overall_progress:.1f}%\")\n",
    "    print(f\"Average Competency Pass Rate: {avg_pass_rate:.1f}%\")\n",
    "    print(f\"Remaining to Train: {total_required - total_completed} personnel\")\n",
    "    \n",
    "    # Readiness assessment\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"READINESS ASSESSMENT:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if overall_progress >= 90 and avg_pass_rate >= 85:\n",
    "        print(\"\\n‚úÖ READY FOR DEPLOYMENT\")\n",
    "        print(\"   All stakeholder groups show adequate training and competency\")\n",
    "    elif overall_progress >= 70:\n",
    "        print(\"\\n‚ö†Ô∏è DEPLOYMENT POSSIBLE WITH CONDITIONS\")\n",
    "        print(\"   Complete remaining training before full-scale rollout\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå NOT READY FOR DEPLOYMENT\")\n",
    "        print(\"   Significant training gaps remain - continue preparation\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x = np.arange(len(df))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax.bar(x - width/2, df['Training_Completed'], width, label='Completed', \n",
    "           color='#28a745', alpha=0.7, edgecolor='black')\n",
    "    ax.bar(x + width/2, df['Training_Required'] - df['Training_Completed'], width,\n",
    "           bottom=df['Training_Completed'], label='Remaining',\n",
    "           color='#cccccc', alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    ax.set_ylabel('Number of Personnel', fontweight='bold')\n",
    "    ax.set_title('Training Progress by Stakeholder Group', fontweight='bold', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df['Stakeholder_Group'], rotation=15, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "stakeholder_df = assess_stakeholder_readiness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 8: Cost-Benefit Analysis\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Understand financial considerations in AI implementation\n",
    "- Calculate ROI and break-even analysis\n",
    "- Assess direct and indirect benefits\n",
    "\n",
    "### üìñ Key Concepts\n",
    "**Economic Evaluation:** ROI calculation, productivity impacts, quality improvements, risk reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Cost analysis\n",
    "def calculate_implementation_costs():\n",
    "    \"\"\"\n",
    "    Calculate total costs for AI system implementation\n",
    "    \"\"\"\n",
    "    print(\"\\nüí∞ IMPLEMENTATION COST ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    costs = {\n",
    "        'Category': [\n",
    "            'Software Development',\n",
    "            'Clinical Validation Studies',\n",
    "            'Regulatory Submissions',\n",
    "            'IT Infrastructure',\n",
    "            'Training & Change Management',\n",
    "            'Quality Management System',\n",
    "            'Annual Maintenance',\n",
    "            'Post-Market Surveillance'\n",
    "        ],\n",
    "        'One_Time_Cost': [500000, 300000, 150000, 200000, 100000, 80000, 0, 0],\n",
    "        'Annual_Cost': [0, 0, 0, 0, 0, 0, 150000, 50000],\n",
    "        'Cost_Type': ['One-Time', 'One-Time', 'One-Time', 'One-Time', 'One-Time', 'One-Time', 'Recurring', 'Recurring']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(costs)\n",
    "    \n",
    "    print(\"\\nDetailed Cost Breakdown:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Calculate totals\n",
    "    total_one_time = df['One_Time_Cost'].sum()\n",
    "    total_annual = df['Annual_Cost'].sum()\n",
    "    five_year_total = total_one_time + (total_annual * 5)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COST SUMMARY:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total One-Time Costs:     ${total_one_time:>12,.0f}\")\n",
    "    print(f\"Total Annual Costs:       ${total_annual:>12,.0f}\")\n",
    "    print(f\"5-Year Total Cost:        ${five_year_total:>12,.0f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Pie chart for one-time costs\n",
    "    one_time_data = df[df['One_Time_Cost'] > 0]\n",
    "    ax1.pie(one_time_data['One_Time_Cost'], labels=one_time_data['Category'],\n",
    "            autopct='%1.1f%%', startangle=90, colors=plt.cm.Set3.colors)\n",
    "    ax1.set_title('One-Time Cost Distribution', fontweight='bold', fontsize=13)\n",
    "    \n",
    "    # 5-year projection\n",
    "    years = np.arange(0, 6)\n",
    "    cumulative_costs = [total_one_time + (total_annual * year) for year in years]\n",
    "    ax2.plot(years, cumulative_costs, marker='o', linewidth=2, markersize=8, color='#1E64C8')\n",
    "    ax2.fill_between(years, cumulative_costs, alpha=0.3, color='#1E64C8')\n",
    "    ax2.set_xlabel('Year', fontweight='bold')\n",
    "    ax2.set_ylabel('Cumulative Cost ($)', fontweight='bold')\n",
    "    ax2.set_title('5-Year Cost Projection', fontweight='bold', fontsize=13)\n",
    "    ax2.grid(alpha=0.3)\n",
    "    ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df, total_one_time, total_annual\n",
    "\n",
    "cost_df, one_time_costs, annual_costs = calculate_implementation_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2 Benefit analysis and ROI calculation\n",
    "def calculate_roi():\n",
    "    \"\"\"\n",
    "    Calculate return on investment from AI implementation\n",
    "    \"\"\"\n",
    "    print(\"\\nüìà BENEFIT ANALYSIS & ROI CALCULATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    benefits = {\n",
    "        'Benefit_Category': [\n",
    "            'Increased Diagnostic Accuracy',\n",
    "            'Reduced Time to Diagnosis',\n",
    "            'Prevented Medical Errors',\n",
    "            'Improved Patient Throughput',\n",
    "            'Reduced Unnecessary Tests',\n",
    "            'Better Resource Utilization'\n",
    "        ],\n",
    "        'Annual_Value': [300000, 200000, 400000, 250000, 150000, 200000],\n",
    "        'Confidence_Level': ['High', 'High', 'Medium', 'High', 'Medium', 'Medium']\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(benefits)\n",
    "    \n",
    "    print(\"\\nQuantified Annual Benefits:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Calculate total benefits\n",
    "    total_annual_benefit = df['Annual_Value'].sum()\n",
    "    \n",
    "    # ROI calculation\n",
    "    total_cost_5yr = one_time_costs + (annual_costs * 5)\n",
    "    total_benefit_5yr = total_annual_benefit * 5\n",
    "    net_benefit = total_benefit_5yr - total_cost_5yr\n",
    "    roi_percentage = (net_benefit / total_cost_5yr) * 100\n",
    "    \n",
    "    # Payback period\n",
    "    payback_years = one_time_costs / (total_annual_benefit - annual_costs)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ROI ANALYSIS (5-Year Projection):\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nTotal Investment (5 years):   ${total_cost_5yr:>12,.0f}\")\n",
    "    print(f\"Total Benefits (5 years):     ${total_benefit_5yr:>12,.0f}\")\n",
    "    print(f\"Net Benefit:                  ${net_benefit:>12,.0f}\")\n",
    "    print(f\"\\nROI:                          {roi_percentage:>11.1f}%\")\n",
    "    print(f\"Payback Period:               {payback_years:>11.1f} years\")\n",
    "    \n",
    "    # Interpretation\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FINANCIAL ASSESSMENT:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if roi_percentage > 50:\n",
    "        assessment = \"‚úÖ EXCELLENT - Strong financial case for implementation\"\n",
    "    elif roi_percentage > 20:\n",
    "        assessment = \"‚úÖ GOOD - Positive return justifies investment\"\n",
    "    elif roi_percentage > 0:\n",
    "        assessment = \"‚ö†Ô∏è MARGINAL - Consider strategic value beyond pure ROI\"\n",
    "    else:\n",
    "        assessment = \"‚ùå NEGATIVE - Financial case unclear, reassess assumptions\"\n",
    "    \n",
    "    print(f\"\\n{assessment}\")\n",
    "    \n",
    "    if payback_years <= 3:\n",
    "        print(f\"‚úÖ Payback period is acceptable ({payback_years:.1f} years)\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Payback period is longer than typical threshold ({payback_years:.1f} years)\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    years = np.arange(1, 6)\n",
    "    cumulative_benefits = [total_annual_benefit * year for year in years]\n",
    "    cumulative_costs = [one_time_costs + (annual_costs * year) for year in years]\n",
    "    cumulative_net = [b - c for b, c in zip(cumulative_benefits, cumulative_costs)]\n",
    "    \n",
    "    ax.plot(years, cumulative_benefits, marker='o', label='Cumulative Benefits', \n",
    "            linewidth=2, color='#28a745', markersize=8)\n",
    "    ax.plot(years, cumulative_costs, marker='s', label='Cumulative Costs',\n",
    "            linewidth=2, color='#ff6b6b', markersize=8)\n",
    "    ax.plot(years, cumulative_net, marker='^', label='Net Benefit',\n",
    "            linewidth=2, color='#1E64C8', markersize=8, linestyle='--')\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.fill_between(years, 0, cumulative_net, where=(np.array(cumulative_net) > 0),\n",
    "                     alpha=0.2, color='#28a745', label='Positive Net Benefit')\n",
    "    \n",
    "    ax.set_xlabel('Year', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Value ($)', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('5-Year Financial Projection: Costs vs Benefits', fontweight='bold', fontsize=14)\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x/1e6:.1f}M'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df, roi_percentage, payback_years\n",
    "\n",
    "benefit_df, roi, payback = calculate_roi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **Ethics Assessment** - Systematic evaluation of AI systems against key ethical principles\n",
    "2. **Algorithmic Bias** - Detection and quantification of bias across demographic groups\n",
    "3. **Privacy Protection** - De-identification techniques and re-identification risk assessment\n",
    "4. **Regulatory Compliance** - FDA and CE marking pathways, compliance checklists\n",
    "5. **Model Transparency** - Explainability techniques and clinical decision reporting\n",
    "6. **Risk Management** - ISO 14971 risk assessment and mitigation strategies\n",
    "7. **Clinical Integration** - Workflow analysis, training assessment, deployment readiness\n",
    "8. **Cost-Benefit Analysis** - ROI calculation and financial justification\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "‚úÖ **Ethics First** - Ethical considerations must guide all AI development decisions\n",
    "\n",
    "‚úÖ **Fairness Matters** - Regular bias audits are essential for equitable healthcare\n",
    "\n",
    "‚úÖ **Privacy is Paramount** - De-identification is necessary but not sufficient alone\n",
    "\n",
    "‚úÖ **Regulation Enables Innovation** - Compliance frameworks provide clear pathways to market\n",
    "\n",
    "‚úÖ **Transparency Builds Trust** - Explainable AI is critical for clinical adoption\n",
    "\n",
    "‚úÖ **Risk Management is Continuous** - Not a one-time activity but ongoing process\n",
    "\n",
    "‚úÖ **Implementation is Multidisciplinary** - Success requires collaboration across many domains\n",
    "\n",
    "‚úÖ **Value Demonstration** - Strong business case supports sustainable implementation\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Apply these frameworks to your own AI projects\n",
    "- Stay updated on evolving regulations (FDA AI/ML guidance, EU AI Act)\n",
    "- Build interdisciplinary teams (clinicians, ethicists, engineers, legal)\n",
    "- Engage with professional organizations (AMIA, HIMSS, etc.)\n",
    "- Contribute to responsible AI development in healthcare\n",
    "\n",
    "### Additional Resources:\n",
    "\n",
    "üìö FDA Digital Health Center of Excellence: https://www.fda.gov/medical-devices/digital-health-center-excellence\n",
    "\n",
    "üìö WHO Ethics and Governance of AI for Health: https://www.who.int/publications/i/item/9789240029200\n",
    "\n",
    "üìö IEEE Ethics in Action: https://ethicsinaction.ieee.org/\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** Responsible AI in healthcare is not just about technical excellence‚Äîit's about ensuring that AI systems are safe, effective, fair, transparent, and beneficial for all patients."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
