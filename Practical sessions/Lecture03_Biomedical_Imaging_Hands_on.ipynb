{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Biomedical Imaging Technologies: Hands-on Practice\n",
    "\n",
    "## Table of Contents\n",
    "1. [Image Loading and Basic Operations](#practice-1-image-loading-and-basic-operations)\n",
    "2. [Microscopy Image Analysis](#practice-2-microscopy-image-analysis)\n",
    "3. [Medical Image Processing (DICOM)](#practice-3-medical-image-processing-dicom)\n",
    "4. [Image Segmentation Techniques](#practice-4-image-segmentation-techniques)\n",
    "5. [Feature Extraction and Quantification](#practice-5-feature-extraction-and-quantification)\n",
    "6. [3D Visualization and Reconstruction](#practice-6-3d-visualization-and-reconstruction)\n",
    "\n",
    "---\n",
    "**Learning Objectives:**\n",
    "- Understand digital image fundamentals (pixels, bit depth, file formats)\n",
    "- Apply preprocessing techniques (filtering, contrast enhancement)\n",
    "- Implement segmentation methods (thresholding, region growing, watershed)\n",
    "- Extract quantitative features from biomedical images\n",
    "- Visualize 3D medical imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage import io, filters, exposure, morphology, segmentation, measure, color\n",
    "from skimage.util import img_as_ubyte, img_as_float\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"âœ… All libraries loaded successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"scikit-image available for image processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 1: Image Loading and Basic Operations\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives\n",
    "- Understand pixel and voxel concepts (2D vs 3D)\n",
    "- Learn about bit depth (8-bit: 256 levels, 16-bit: 65,536 levels)\n",
    "- Perform basic image operations\n",
    "\n",
    "### ðŸ“– Key Concepts\n",
    "- **Pixel**: Picture element (2D)\n",
    "- **Bit depth**: Number of gray levels\n",
    "- **Dynamic range**: Difference between brightest and darkest values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Create a synthetic microscopy image\n",
    "def create_synthetic_cells(size=256, n_cells=5):\n",
    "    \"\"\"Generate synthetic cell images for practice\"\"\"\n",
    "    image = np.zeros((size, size), dtype=np.float32)\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    for _ in range(n_cells):\n",
    "        # Random cell position\n",
    "        y, x = np.random.randint(30, size-30, 2)\n",
    "        radius = np.random.randint(15, 30)\n",
    "        \n",
    "        # Create cell\n",
    "        yy, xx = np.ogrid[:size, :size]\n",
    "        mask = (yy - y)**2 + (xx - x)**2 <= radius**2\n",
    "        image[mask] = np.random.uniform(0.6, 1.0)\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 0.05, image.shape)\n",
    "    image = np.clip(image + noise, 0, 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Create image\n",
    "image = create_synthetic_cells()\n",
    "\n",
    "# Display image properties\n",
    "print(\"ðŸ“Š Image Properties\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {image.shape}\")\n",
    "print(f\"Data type: {image.dtype}\")\n",
    "print(f\"Min value: {image.min():.4f}\")\n",
    "print(f\"Max value: {image.max():.4f}\")\n",
    "print(f\"Mean intensity: {image.mean():.4f}\")\n",
    "print(f\"Standard deviation: {image.std():.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original image\n",
    "im = axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Synthetic Cell Image', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "plt.colorbar(im, ax=axes[0], fraction=0.046)\n",
    "\n",
    "# Histogram\n",
    "axes[1].hist(image.ravel(), bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_title('Intensity Histogram', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Pixel Intensity')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Image created and analyzed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 2: Microscopy Image Analysis\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives\n",
    "- Apply noise reduction filters (Gaussian, median, bilateral)\n",
    "- Perform contrast enhancement\n",
    "- Understand histogram equalization\n",
    "\n",
    "### ðŸ“– Key Concepts from Lecture\n",
    "- **Gaussian filter**: Smoothing with weighted average\n",
    "- **Median filter**: Removes salt-and-pepper noise\n",
    "- **Histogram equalization**: Uniform intensity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Image preprocessing techniques\n",
    "def apply_preprocessing(image):\n",
    "    \"\"\"Apply various preprocessing techniques\"\"\"\n",
    "    \n",
    "    # 1. Gaussian filtering\n",
    "    gaussian = filters.gaussian(image, sigma=1.5)\n",
    "    \n",
    "    # 2. Median filtering\n",
    "    median = filters.median(image, morphology.disk(3))\n",
    "    \n",
    "    # 3. Histogram equalization\n",
    "    equalized = exposure.equalize_hist(image)\n",
    "    \n",
    "    # 4. Contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    stretched = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "    \n",
    "    return gaussian, median, equalized, stretched\n",
    "\n",
    "# Apply preprocessing\n",
    "gaussian_img, median_img, eq_img, stretched_img = apply_preprocessing(image)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "images = [image, gaussian_img, median_img, stretched_img, eq_img, image]\n",
    "titles = ['Original', 'Gaussian Filter\\n(Ïƒ=1.5)', 'Median Filter\\n(disk r=3)', \n",
    "          'Contrast Stretching\\n(2-98 percentile)', 'Histogram\\nEqualization', 'Reference']\n",
    "\n",
    "for ax, img, title in zip(axes.flat, images, titles):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "axes[1, 2].axis('on')\n",
    "axes[1, 2].hist(image.ravel(), bins=50, alpha=0.5, label='Original', color='blue')\n",
    "axes[1, 2].hist(eq_img.ravel(), bins=50, alpha=0.5, label='Equalized', color='red')\n",
    "axes[1, 2].set_title('Histogram Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].set_xlabel('Intensity')\n",
    "axes[1, 2].set_ylabel('Frequency')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Preprocessing techniques applied successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 3: Medical Image Processing (DICOM)\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives\n",
    "- Understand DICOM format basics\n",
    "- Apply morphological operations\n",
    "- Learn erosion, dilation, opening, closing\n",
    "\n",
    "### ðŸ“– Key Concepts\n",
    "- **Erosion**: Removes pixels at boundaries\n",
    "- **Dilation**: Adds pixels at boundaries\n",
    "- **Opening**: Erosion followed by dilation (removes small objects)\n",
    "- **Closing**: Dilation followed by erosion (fills small holes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Morphological operations\n",
    "def apply_morphology(image, threshold=0.3):\n",
    "    \"\"\"Apply morphological operations for image enhancement\"\"\"\n",
    "    \n",
    "    # Create binary image\n",
    "    binary = image > threshold\n",
    "    \n",
    "    # Define structuring element\n",
    "    selem = morphology.disk(3)\n",
    "    \n",
    "    # Apply operations\n",
    "    eroded = morphology.erosion(binary, selem)\n",
    "    dilated = morphology.dilation(binary, selem)\n",
    "    opened = morphology.opening(binary, selem)\n",
    "    closed = morphology.closing(binary, selem)\n",
    "    \n",
    "    return binary, eroded, dilated, opened, closed\n",
    "\n",
    "# Apply morphology\n",
    "binary, eroded, dilated, opened, closed = apply_morphology(image)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "morph_images = [image, binary, eroded, dilated, opened, closed]\n",
    "morph_titles = ['Original (Grayscale)', 'Binary\\n(threshold=0.3)', 'Erosion\\n(removes boundaries)', \n",
    "                'Dilation\\n(expands boundaries)', 'Opening\\n(erosionâ†’dilation)', 'Closing\\n(dilationâ†’erosion)']\n",
    "\n",
    "for ax, img, title in zip(axes.flat, morph_images, morph_titles):\n",
    "    if title.startswith('Original'):\n",
    "        ax.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Morphological Operations Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Binary image: {binary.sum()} white pixels\")\n",
    "print(f\"Eroded: {eroded.sum()} white pixels (smaller objects)\")\n",
    "print(f\"Dilated: {dilated.sum()} white pixels (larger objects)\")\n",
    "print(f\"Opened: {opened.sum()} white pixels (noise removed)\")\n",
    "print(f\"Closed: {closed.sum()} white pixels (holes filled)\")\n",
    "print(\"\\nâœ… Morphological operations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 4: Image Segmentation Techniques\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives\n",
    "- Implement multiple segmentation methods\n",
    "- Compare thresholding, watershed, and region growing\n",
    "- Understand when to use each method\n",
    "\n",
    "### ðŸ“– Key Concepts from Lecture\n",
    "- **Otsu's method**: Automatic threshold selection\n",
    "- **Watershed**: Treats image as topographic surface\n",
    "- **Region growing**: Groups similar pixels from seed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Multiple segmentation techniques\n",
    "def compare_segmentation_methods(image):\n",
    "    \"\"\"Compare different segmentation approaches\"\"\"\n",
    "    \n",
    "    print(\"ðŸ” Applying Segmentation Methods...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Otsu's thresholding\n",
    "    threshold_value = filters.threshold_otsu(image)\n",
    "    otsu_seg = image > threshold_value\n",
    "    print(f\"1. Otsu threshold value: {threshold_value:.4f}\")\n",
    "    \n",
    "    # 2. Adaptive thresholding\n",
    "    adaptive_seg = image > filters.threshold_local(image, block_size=35)\n",
    "    print(\"2. Adaptive thresholding applied (block_size=35)\")\n",
    "    \n",
    "    # 3. Watershed segmentation\n",
    "    # Compute elevation map\n",
    "    elevation_map = filters.sobel(image)\n",
    "    \n",
    "    # Find markers\n",
    "    markers = np.zeros_like(image, dtype=int)\n",
    "    markers[image < 0.2] = 1  # Background\n",
    "    markers[image > 0.6] = 2  # Foreground\n",
    "    \n",
    "    watershed_seg = segmentation.watershed(elevation_map, markers)\n",
    "    print(\"3. Watershed segmentation completed\")\n",
    "    \n",
    "    # 4. Connected component labeling\n",
    "    labeled_image = measure.label(otsu_seg)\n",
    "    n_objects = labeled_image.max()\n",
    "    print(f\"4. Found {n_objects} connected objects\")\n",
    "    \n",
    "    return otsu_seg, adaptive_seg, watershed_seg, labeled_image, n_objects\n",
    "\n",
    "# Apply segmentation\n",
    "otsu_result, adaptive_result, watershed_result, labeled, n_cells = compare_segmentation_methods(image)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original\n",
    "axes[0, 0].imshow(image, cmap='gray')\n",
    "axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "# Otsu\n",
    "axes[0, 1].imshow(otsu_result, cmap='gray')\n",
    "axes[0, 1].set_title('Otsu Thresholding\\n(Global)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "# Adaptive\n",
    "axes[0, 2].imshow(adaptive_result, cmap='gray')\n",
    "axes[0, 2].set_title('Adaptive Thresholding\\n(Local)', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "# Watershed\n",
    "axes[1, 0].imshow(watershed_result, cmap='nipy_spectral')\n",
    "axes[1, 0].set_title('Watershed Segmentation', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "# Labeled\n",
    "axes[1, 1].imshow(color.label2rgb(labeled, bg_label=0))\n",
    "axes[1, 1].set_title(f'Connected Components\\n({n_cells} objects)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "axes[1, 2].imshow(image, cmap='gray')\n",
    "axes[1, 2].contour(otsu_result, colors='red', linewidths=2)\n",
    "axes[1, 2].set_title('Original + Boundaries', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Segmentation comparison completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 5: Feature Extraction and Quantification\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives\n",
    "- Extract shape descriptors (area, perimeter, circularity)\n",
    "- Calculate intensity statistics\n",
    "- Generate quantitative reports\n",
    "\n",
    "### ðŸ“– Key Concepts\n",
    "- **Area**: Number of pixels in object\n",
    "- **Perimeter**: Boundary length\n",
    "- **Circularity**: $4\\pi \\times \\frac{Area}{Perimeter^2}$\n",
    "- **Intensity metrics**: Mean, std, min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Extract quantitative features\n",
    "def extract_features(image, labeled_image):\n",
    "    \"\"\"Extract shape and intensity features from labeled objects\"\"\"\n",
    "    \n",
    "    print(\"ðŸ“Š Extracting Features from Detected Objects...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get region properties\n",
    "    regions = measure.regionprops(labeled_image, intensity_image=image)\n",
    "    \n",
    "    features = []\n",
    "    for i, region in enumerate(regions, 1):\n",
    "        feature = {\n",
    "            'Object': i,\n",
    "            'Area (pixels)': region.area,\n",
    "            'Perimeter (pixels)': region.perimeter,\n",
    "            'Circularity': 4 * np.pi * region.area / (region.perimeter ** 2) if region.perimeter > 0 else 0,\n",
    "            'Mean Intensity': region.mean_intensity,\n",
    "            'Max Intensity': region.max_intensity,\n",
    "            'Centroid Y': region.centroid[0],\n",
    "            'Centroid X': region.centroid[1]\n",
    "        }\n",
    "        features.append(feature)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(features)\n",
    "    \n",
    "    print(f\"\\nTotal objects detected: {len(features)}\")\n",
    "    print(\"\\nFeature Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    return df, regions\n",
    "\n",
    "# Extract features\n",
    "import pandas as pd\n",
    "feature_df, detected_regions = extract_features(image, labeled)\n",
    "\n",
    "# Visualize features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Image with labels\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "for region in detected_regions:\n",
    "    y, x = region.centroid\n",
    "    axes[0].plot(x, y, 'r+', markersize=15, markeredgewidth=2)\n",
    "    axes[0].text(x, y-20, f'{region.label}', color='red', fontsize=10, \n",
    "                fontweight='bold', ha='center')\n",
    "axes[0].set_title('Detected Objects with Labels', fontsize=12, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Area distribution\n",
    "axes[1].bar(feature_df['Object'], feature_df['Area (pixels)'], color='steelblue', edgecolor='black')\n",
    "axes[1].set_xlabel('Object ID', fontsize=11)\n",
    "axes[1].set_ylabel('Area (pixels)', fontsize=11)\n",
    "axes[1].set_title('Object Area Distribution', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Circularity vs Area\n",
    "scatter = axes[2].scatter(feature_df['Area (pixels)'], feature_df['Circularity'], \n",
    "                         c=feature_df['Mean Intensity'], cmap='viridis', s=100, \n",
    "                         edgecolor='black', linewidth=1.5, alpha=0.7)\n",
    "axes[2].set_xlabel('Area (pixels)', fontsize=11)\n",
    "axes[2].set_ylabel('Circularity', fontsize=11)\n",
    "axes[2].set_title('Shape Analysis (color=intensity)', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[2], label='Mean Intensity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Feature extraction completed!\")\n",
    "print(\"\\nðŸ“‹ Sample Feature Table:\")\n",
    "print(feature_df.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Practice 6: 3D Visualization and Reconstruction\n",
    "\n",
    "### ðŸŽ¯ Learning Objectives\n",
    "- Create 3D image stacks\n",
    "- Apply maximum intensity projection (MIP)\n",
    "- Visualize multi-planar reformation (MPR)\n",
    "\n",
    "### ðŸ“– Key Concepts\n",
    "- **Z-stack**: Series of 2D images at different depths\n",
    "- **MIP**: Shows brightest voxels along viewing direction\n",
    "- **MPR**: Creates arbitrary slice planes from 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Create and visualize 3D image stack\n",
    "def create_3d_stack(n_slices=10):\n",
    "    \"\"\"Generate synthetic 3D image stack\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”¨ Creating 3D Image Stack...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stack = []\n",
    "    for z in range(n_slices):\n",
    "        # Create slice with varying intensity\n",
    "        slice_img = create_synthetic_cells(size=128, n_cells=3 + z % 3)\n",
    "        # Add depth-dependent intensity variation\n",
    "        depth_factor = 1.0 - abs(z - n_slices/2) / (n_slices/2) * 0.3\n",
    "        slice_img = slice_img * depth_factor\n",
    "        stack.append(slice_img)\n",
    "    \n",
    "    stack_3d = np.array(stack)\n",
    "    print(f\"Stack shape: {stack_3d.shape} (Z, Y, X)\")\n",
    "    print(f\"Total voxels: {stack_3d.size:,}\")\n",
    "    \n",
    "    return stack_3d\n",
    "\n",
    "# Create stack\n",
    "image_stack = create_3d_stack(n_slices=10)\n",
    "\n",
    "# Maximum Intensity Projection\n",
    "mip_z = np.max(image_stack, axis=0)  # Along Z\n",
    "mip_y = np.max(image_stack, axis=1)  # Along Y\n",
    "mip_x = np.max(image_stack, axis=2)  # Along X\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Individual slices\n",
    "for i in range(6):\n",
    "    ax = plt.subplot(3, 4, i+1)\n",
    "    slice_idx = i * 2\n",
    "    ax.imshow(image_stack[slice_idx], cmap='gray')\n",
    "    ax.set_title(f'Slice Z={slice_idx}', fontsize=11, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "# MIP projections\n",
    "ax = plt.subplot(3, 4, 7)\n",
    "ax.imshow(mip_z, cmap='hot')\n",
    "ax.set_title('MIP (Z-axis)\\nTop view', fontsize=11, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = plt.subplot(3, 4, 8)\n",
    "ax.imshow(mip_y, cmap='hot')\n",
    "ax.set_title('MIP (Y-axis)\\nFront view', fontsize=11, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "ax = plt.subplot(3, 4, 11)\n",
    "ax.imshow(mip_x, cmap='hot')\n",
    "ax.set_title('MIP (X-axis)\\nSide view', fontsize=11, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "# 3D visualization representation\n",
    "ax = plt.subplot(3, 4, 12)\n",
    "middle_slice = image_stack[image_stack.shape[0]//2]\n",
    "ax.imshow(middle_slice, cmap='gray')\n",
    "ax.contour(middle_slice, levels=3, colors='cyan', linewidths=2)\n",
    "ax.set_title('Middle Slice\\n+ Contours', fontsize=11, fontweight='bold')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š 3D Stack Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dimensions: {image_stack.shape[0]} slices Ã— {image_stack.shape[1]} Ã— {image_stack.shape[2]} pixels\")\n",
    "print(f\"Voxel intensities: min={image_stack.min():.4f}, max={image_stack.max():.4f}\")\n",
    "print(f\"Mean intensity per slice: {[f'{s.mean():.3f}' for s in image_stack[:5]]}...\")\n",
    "print(\"\\nâœ… 3D visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Practice Complete!\n",
    "\n",
    "### Summary of What We Learned:\n",
    "\n",
    "1. **Digital Image Basics**: Pixels, bit depth, intensity distributions\n",
    "2. **Preprocessing**: Filtering, contrast enhancement, morphological operations\n",
    "3. **Segmentation**: Otsu, adaptive thresholding, watershed algorithm\n",
    "4. **Feature Extraction**: Shape descriptors, intensity statistics, quantification\n",
    "5. **3D Imaging**: Stack creation, MIP, multi-planar views\n",
    "\n",
    "### Key Insights:\n",
    "- Image preprocessing is crucial for accurate analysis\n",
    "- Different segmentation methods work for different scenarios\n",
    "- Quantitative features enable objective image analysis\n",
    "- 3D visualization helps understand complex structures\n",
    "\n",
    "### Clinical Applications:\n",
    "- **Microscopy**: Cell counting, morphology analysis\n",
    "- **Radiology**: Tumor segmentation, volume measurement\n",
    "- **Pathology**: Tissue classification, cancer detection\n",
    "- **Surgery Planning**: 3D reconstruction, anatomical visualization\n",
    "\n",
    "### Next Steps:\n",
    "- Explore real DICOM medical images\n",
    "- Implement machine learning-based segmentation (U-Net)\n",
    "- Practice with ImageJ and 3D Slicer software\n",
    "- Learn about image registration for multi-modal fusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“š Additional Resources\n",
    "\n",
    "### Python Libraries:\n",
    "- **scikit-image**: Image processing in Python - https://scikit-image.org/\n",
    "- **SimpleITK**: Medical image analysis - https://simpleitk.org/\n",
    "- **pydicom**: DICOM file handling - https://pydicom.github.io/\n",
    "\n",
    "### Software Tools:\n",
    "- **ImageJ/Fiji**: Free image processing - https://fiji.sc/\n",
    "- **3D Slicer**: Medical image visualization - https://www.slicer.org/\n",
    "- **QuPath**: Digital pathology analysis - https://qupath.github.io/\n",
    "\n",
    "### Datasets for Practice:\n",
    "- **Cell Image Library**: http://www.cellimagelibrary.org/\n",
    "- **The Cancer Imaging Archive (TCIA)**: https://www.cancerimagingarchive.net/\n",
    "- **BioImage Archive**: https://www.ebi.ac.uk/bioimage-archive/\n",
    "\n",
    "### Further Reading:\n",
    "- Gonzalez & Woods - \"Digital Image Processing\"\n",
    "- Sonka et al. - \"Image Processing, Analysis, and Machine Vision\"\n",
    "- Bankman - \"Handbook of Medical Image Processing\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
