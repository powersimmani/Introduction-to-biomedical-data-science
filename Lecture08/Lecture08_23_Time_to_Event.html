<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Time-to-Event Prediction - Comprehensive Guide</title>
    <style>
        * {margin:0;padding:0;box-sizing:border-box;}
        body {font-family:Aptos,'Segoe UI',Tahoma,sans-serif;background:#f5f7fa;padding:20px;line-height:1.6;}
        .container {max-width:1400px;margin:0 auto;background:white;padding:50px;box-shadow:0 4px 20px rgba(0,0,0,0.1);border-radius:15px;}
        
        /* Title */
        .main-title {font-size:48px;font-weight:700;color:#1E64C8;margin-bottom:15px;text-align:center;}
        .subtitle {font-size:24px;font-weight:400;color:#666;text-align:center;margin-bottom:40px;border-bottom:4px solid #1E64C8;padding-bottom:25px;}
        
        /* Table of Contents */
        .toc {background:#e8f2ff;border:2px solid #1E64C8;border-radius:10px;padding:30px;margin-bottom:50px;}
        .toc-title {font-size:28px;font-weight:700;color:#1E64C8;margin-bottom:20px;}
        .toc-list {list-style:none;margin-left:0;}
        .toc-list li {margin-bottom:12px;font-size:18px;}
        .toc-list a {color:#1E64C8;text-decoration:none;transition:all 0.3s;}
        .toc-list a:hover {text-decoration:underline;color:#3a7bd5;}
        
        /* Methods Overview Section */
        .overview-section {margin-bottom:60px;}
        .section-intro {font-size:18px;color:#555;margin-bottom:30px;text-align:center;line-height:1.8;}
        .methods-grid {display:grid;grid-template-columns:repeat(3,1fr);gap:30px;margin-bottom:40px;}
        .method-card {background:linear-gradient(135deg,#f8fbff 0%,#e8f2ff 100%);border:3px solid #1E64C8;border-radius:15px;padding:30px;text-align:center;transition:all 0.3s;box-shadow:0 2px 10px rgba(0,0,0,0.05);}
        .method-card:hover {transform:translateY(-8px);box-shadow:0 12px 30px rgba(30,100,200,0.3);}
        .method-viz {height:180px;display:flex;justify-content:center;align-items:center;margin-bottom:20px;}
        .method-name {font-size:24px;font-weight:700;color:#1E64C8;margin-bottom:12px;}
        .method-desc {font-size:16px;color:#333;line-height:1.7;}
        
        /* Metrics */
        .metrics-box {background:#f8fbff;border:3px solid #1E64C8;border-radius:15px;padding:30px;margin-bottom:60px;}
        .metrics-title {font-size:28px;font-weight:700;color:#1E64C8;margin-bottom:25px;text-align:center;}
        .metrics-grid {display:flex;gap:20px;justify-content:center;flex-wrap:wrap;}
        .metric-item {background:white;border:2px solid #1E64C8;border-radius:10px;padding:15px 25px;font-size:17px;font-weight:600;position:relative;overflow:hidden;transition:all 0.3s;}
        .metric-item:hover {transform:scale(1.05);box-shadow:0 4px 15px rgba(30,100,200,0.2);}
        .metric-item::before {content:'';position:absolute;top:0;left:0;width:100%;height:4px;background:linear-gradient(90deg,#1E64C8,#5088d4);}
        
        /* Detailed Sections */
        .detailed-section {margin-bottom:80px;page-break-inside:avoid;}
        .section-header {background:linear-gradient(135deg,#1E64C8 0%,#3a7bd5 100%);color:white;padding:30px 40px;border-radius:15px 15px 0 0;margin-bottom:0;}
        .section-number {font-size:22px;opacity:0.9;margin-bottom:10px;font-weight:600;letter-spacing:1px;}
        .section-title {font-size:40px;font-weight:700;}
        .section-content {border:3px solid #1E64C8;border-top:none;border-radius:0 0 15px 15px;padding:40px;background:white;}
        
        /* Subsections */
        .subsection {margin-bottom:45px;}
        .subsection-title {font-size:28px;font-weight:700;color:#1E64C8;margin-bottom:20px;display:flex;align-items:center;}
        .subsection-title::before {content:'‚ñ∏';margin-right:15px;font-size:24px;}
        .subsection-content {font-size:17px;line-height:2;color:#333;margin-bottom:20px;}
        
        /* Diagrams */
        .diagram-container {background:#f8fbff;border:3px solid #1E64C8;border-radius:12px;padding:35px;margin:30px 0;text-align:center;box-shadow:0 2px 10px rgba(0,0,0,0.05);}
        .diagram-title {font-size:22px;font-weight:700;color:#1E64C8;margin-bottom:20px;}
        .diagram-caption {font-size:16px;color:#666;margin-top:20px;font-style:italic;line-height:1.6;max-width:900px;margin-left:auto;margin-right:auto;}
        
        /* Feature Boxes */
        .feature-grid {display:grid;grid-template-columns:repeat(2,1fr);gap:20px;margin:30px 0;}
        .feature-box {background:#f8fbff;border-left:5px solid #1E64C8;padding:20px;border-radius:8px;transition:all 0.3s;}
        .feature-box:hover {box-shadow:0 4px 15px rgba(30,100,200,0.15);transform:translateX(5px);}
        .feature-box-title {font-weight:700;color:#1E64C8;margin-bottom:12px;font-size:19px;}
        .feature-box-content {font-size:16px;color:#555;line-height:1.8;}
        
        /* Lists */
        ul {margin-left:35px;margin-bottom:20px;}
        li {margin-bottom:12px;line-height:1.9;color:#333;font-size:17px;}
        li strong {color:#1E64C8;font-weight:600;}
        
        /* Highlight Boxes */
        .highlight-box {background:#fff3cd;border-left:6px solid #ffc107;padding:22px;margin:30px 0;border-radius:8px;box-shadow:0 2px 8px rgba(0,0,0,0.05);}
        .highlight-box-title {font-weight:700;color:#856404;margin-bottom:12px;font-size:20px;}
        .highlight-box-content {color:#856404;line-height:1.8;font-size:16px;}
        
        /* Info Boxes */
        .info-box {background:#d1ecf1;border-left:6px solid:#17a2b8;padding:22px;margin:30px 0;border-radius:8px;}
        .info-box-title {font-weight:700;color:#0c5460;margin-bottom:12px;font-size:20px;}
        .info-box-content {color:#0c5460;line-height:1.8;font-size:16px;}
        
        /* Code/Math Boxes */
        .math-box {background:#f1f3f5;border:2px solid #dee2e6;border-radius:10px;padding:25px;margin:25px 0;font-family:'Courier New',monospace;font-size:15px;overflow-x:auto;white-space:pre-wrap;line-height:1.7;box-shadow:inset 0 2px 4px rgba(0,0,0,0.05);}
        
        /* Comparison Table */
        .comparison-table {width:100%;border-collapse:collapse;margin:30px 0;box-shadow:0 2px 10px rgba(0,0,0,0.1);}
        .comparison-table th {background:#1E64C8;color:white;padding:18px;text-align:left;font-weight:600;font-size:17px;}
        .comparison-table td {border:1px solid #ddd;padding:18px;font-size:16px;line-height:1.6;}
        .comparison-table tr:nth-child(even) {background:#f8fbff;}
        .comparison-table tr:hover {background:#e8f2ff;}
        
        /* Summary Section */
        .summary-section {background:linear-gradient(135deg,#f8fbff 0%,#e8f2ff 100%);border:3px solid #1E64C8;border-radius:15px;padding:40px;margin-top:60px;}
        .summary-title {font-size:32px;font-weight:700;color:#1E64C8;margin-bottom:25px;text-align:center;}
        
        /* Print Styles */
        @media print {
            body {background:white;padding:0;}
            .container {box-shadow:none;padding:20px;}
            .method-card, .detailed-section {page-break-inside:avoid;}
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Main Title -->
        <div class="main-title">Time-to-Event Prediction with Machine Learning</div>
        <div class="subtitle">Comprehensive Guide to Modern Survival Analysis Methods</div>
        
        <!-- Table of Contents -->
        <div class="toc">
            <div class="toc-title">üìë Table of Contents</div>
            <ul class="toc-list">
                <li><a href="#overview">1. Overview & Evaluation Metrics</a></li>
                <li><a href="#rsf">2. Random Survival Forests (RSF)</a></li>
                <li><a href="#deepsurv">3. DeepSurv: Deep Learning for Survival</a></li>
                <li><a href="#discrete">4. Discrete Time Survival Models</a></li>
                <li><a href="#comparison">5. Method Comparison & Selection Guide</a></li>
            </ul>
        </div>
        
        <!-- Overview Section -->
        <div id="overview" class="overview-section">
            <div class="section-intro">
                Survival analysis, also known as time-to-event analysis, focuses on predicting the time until an event of interest occurs. Machine learning has revolutionized this field by providing powerful methods that can handle complex, non-linear relationships and high-dimensional data.
            </div>
            
            <!-- Methods Grid -->
            <div class="methods-grid">
                <!-- Random Survival Forests -->
                <div class="method-card">
                    <div class="method-viz">
                        <svg width="300" height="180" viewBox="0 0 300 180">
                            <g transform="translate(15,20)">
                                <!-- Tree 1 -->
                                <g>
                                    <circle cx="30" cy="20" r="7" fill="#28a745"/>
                                    <line x1="30" y1="27" x2="18" y2="50" stroke="#333" stroke-width="2"/>
                                    <line x1="30" y1="27" x2="42" y2="50" stroke="#333" stroke-width="2"/>
                                    <circle cx="18" cy="53" r="5" fill="#ff8c00"/>
                                    <circle cx="42" cy="53" r="5" fill="#ff8c00"/>
                                    <line x1="18" y1="58" x2="12" y2="75" stroke="#333" stroke-width="1.5"/>
                                    <line x1="18" y1="58" x2="24" y2="75" stroke="#333" stroke-width="1.5"/>
                                    <rect x="9" y="75" width="6" height="6" fill="#1E64C8"/>
                                    <rect x="21" y="75" width="6" height="6" fill="#e74c3c"/>
                                    <text x="30" y="100" text-anchor="middle" font-size="11" fill="#666" font-weight="600">Tree 1</text>
                                </g>
                                
                                <!-- Tree 2 -->
                                <g transform="translate(80,0)">
                                    <circle cx="30" cy="20" r="7" fill="#28a745"/>
                                    <line x1="30" y1="27" x2="18" y2="50" stroke="#333" stroke-width="2"/>
                                    <line x1="30" y1="27" x2="42" y2="50" stroke="#333" stroke-width="2"/>
                                    <circle cx="18" cy="53" r="5" fill="#ff8c00"/>
                                    <circle cx="42" cy="53" r="5" fill="#ff8c00"/>
                                    <line x1="42" y1="58" x2="36" y2="75" stroke="#333" stroke-width="1.5"/>
                                    <line x1="42" y1="58" x2="48" y2="75" stroke="#333" stroke-width="1.5"/>
                                    <rect x="33" y="75" width="6" height="6" fill="#1E64C8"/>
                                    <rect x="45" y="75" width="6" height="6" fill="#e74c3c"/>
                                    <text x="30" y="100" text-anchor="middle" font-size="11" fill="#666" font-weight="600">Tree 2</text>
                                </g>
                                
                                <!-- Tree N -->
                                <g transform="translate(160,0)">
                                    <circle cx="30" cy="20" r="7" fill="#28a745"/>
                                    <line x1="30" y1="27" x2="18" y2="50" stroke="#333" stroke-width="2"/>
                                    <line x1="30" y1="27" x2="42" y2="50" stroke="#333" stroke-width="2"/>
                                    <circle cx="18" cy="53" r="5" fill="#ff8c00"/>
                                    <circle cx="42" cy="53" r="5" fill="#ff8c00"/>
                                    <line x1="18" y1="58" x2="12" y2="75" stroke="#333" stroke-width="1.5"/>
                                    <line x1="18" y1="58" x2="24" y2="75" stroke="#333" stroke-width="1.5"/>
                                    <rect x="9" y="75" width="6" height="6" fill="#e74c3c"/>
                                    <rect x="21" y="75" width="6" height="6" fill="#1E64C8"/>
                                    <text x="30" y="100" text-anchor="middle" font-size="11" fill="#666" font-weight="600">Tree N</text>
                                </g>
                                
                                <!-- Aggregation -->
                                <path d="M 230,60 L 260,60" stroke="#1E64C8" stroke-width="3" marker-end="url(#arrowRSF)"/>
                                <text x="245" y="50" text-anchor="middle" font-size="12" fill="#1E64C8" font-weight="600">Avg</text>
                                
                                <!-- Output -->
                                <rect x="265" y="40" width="35" height="40" fill="none" stroke="#1E64C8" stroke-width="2"/>
                                <path d="M 268,75 Q 275,65 282,50 T 295,30" stroke="#28a745" stroke-width="3" fill="none"/>
                                <text x="282" y="95" text-anchor="middle" font-size="11" fill="#666" font-weight="600">S(t)</text>
                            </g>
                            
                            <text x="150" y="140" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Ensemble of survival trees</text>
                            <text x="150" y="158" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Bootstrap aggregation for robust predictions</text>
                            
                            <defs>
                                <marker id="arrowRSF" markerWidth="10" markerHeight="10" refX="8" refY="3" orient="auto">
                                    <path d="M0,0 L0,6 L9,3 z" fill="#1E64C8"/>
                                </marker>
                            </defs>
                        </svg>
                    </div>
                    <div class="method-name">Random Survival Forests</div>
                    <div class="method-desc">Ensemble learning approach that combines multiple survival trees. Handles non-linear relationships and provides feature importance rankings.</div>
                </div>
                
                <!-- DeepSurv -->
                <div class="method-card">
                    <div class="method-viz">
                        <svg width="300" height="180" viewBox="0 0 300 180">
                            <g transform="translate(35,30)">
                                <!-- Input layer -->
                                <text x="0" y="-5" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Input</text>
                                <circle cx="0" cy="15" r="5" fill="#1E64C8" opacity="0.8"/>
                                <circle cx="0" cy="35" r="5" fill="#1E64C8" opacity="0.8"/>
                                <circle cx="0" cy="55" r="5" fill="#1E64C8" opacity="0.8"/>
                                <circle cx="0" cy="75" r="5" fill="#1E64C8" opacity="0.8"/>
                                <text x="0" y="100" text-anchor="middle" font-size="10" fill="#666">Features</text>
                                
                                <!-- Hidden layer 1 -->
                                <circle cx="60" cy="20" r="5" fill="#ff8c00" opacity="0.8"/>
                                <circle cx="60" cy="40" r="5" fill="#ff8c00" opacity="0.8"/>
                                <circle cx="60" cy="60" r="5" fill="#ff8c00" opacity="0.8"/>
                                <circle cx="60" cy="80" r="5" fill="#ff8c00" opacity="0.8"/>
                                
                                <!-- Hidden layer 2 -->
                                <circle cx="120" cy="25" r="5" fill="#ff8c00" opacity="0.8"/>
                                <circle cx="120" cy="45" r="5" fill="#ff8c00" opacity="0.8"/>
                                <circle cx="120" cy="65" r="5" fill="#ff8c00" opacity="0.8"/>
                                
                                <!-- Output layer -->
                                <circle cx="180" cy="45" r="7" fill="#28a745" opacity="0.9"/>
                                <text x="180" y="-5" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Output</text>
                                <text x="180" y="75" text-anchor="middle" font-size="11" fill="#28a745" font-weight="600">log h(t|X)</text>
                                
                                <!-- Connections (sample) -->
                                <line x1="5" y1="15" x2="55" y2="20" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="5" y1="35" x2="55" y2="40" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="5" y1="55" x2="55" y2="60" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="5" y1="75" x2="55" y2="80" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                
                                <line x1="65" y1="20" x2="115" y2="25" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="65" y1="40" x2="115" y2="45" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="65" y1="60" x2="115" y2="65" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                
                                <line x1="125" y1="25" x2="173" y2="45" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="125" y1="45" x2="173" y2="45" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                                <line x1="125" y1="65" x2="173" y2="45" stroke="#ddd" stroke-width="1" opacity="0.6"/>
                            </g>
                            
                            <text x="150" y="140" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Deep neural network architecture</text>
                            <text x="150" y="158" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Cox partial likelihood loss function</text>
                        </svg>
                    </div>
                    <div class="method-name">DeepSurv</div>
                    <div class="method-desc">Deep learning approach combining neural networks with Cox regression. Captures complex non-linear patterns in high-dimensional data.</div>
                </div>
                
                <!-- Discrete Time Models -->
                <div class="method-card">
                    <div class="method-viz">
                        <svg width="300" height="180" viewBox="0 0 300 180">
                            <g transform="translate(25,45)">
                                <!-- Timeline -->
                                <line x1="10" y1="60" x2="260" y2="60" stroke="#333" stroke-width="3"/>
                                
                                <!-- Intervals -->
                                <rect x="10" y="45" width="48" height="30" fill="#1E64C8" opacity="0.25" stroke="#1E64C8" stroke-width="2"/>
                                <text x="34" y="65" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="700">t‚ÇÅ</text>
                                
                                <rect x="58" y="45" width="48" height="30" fill="#1E64C8" opacity="0.25" stroke="#1E64C8" stroke-width="2"/>
                                <text x="82" y="65" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="700">t‚ÇÇ</text>
                                
                                <rect x="106" y="45" width="48" height="30" fill="#1E64C8" opacity="0.25" stroke="#1E64C8" stroke-width="2"/>
                                <text x="130" y="65" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="700">t‚ÇÉ</text>
                                
                                <rect x="154" y="45" width="48" height="30" fill="#1E64C8" opacity="0.25" stroke="#1E64C8" stroke-width="2"/>
                                <text x="178" y="65" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="700">t‚ÇÑ</text>
                                
                                <rect x="202" y="45" width="58" height="30" fill="#1E64C8" opacity="0.25" stroke="#1E64C8" stroke-width="2"/>
                                <text x="231" y="65" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="700">t‚ÇÖ+</text>
                                
                                <!-- Title -->
                                <text x="135" y="25" text-anchor="middle" font-size="13" fill="#666" font-weight="700">Binary Classification per Interval</text>
                                
                                <!-- Probabilities -->
                                <circle cx="34" cy="90" r="4" fill="#28a745"/>
                                <text x="34" y="108" text-anchor="middle" font-size="11" fill="#28a745" font-weight="600">0.95</text>
                                
                                <circle cx="82" cy="90" r="4" fill="#28a745"/>
                                <text x="82" y="108" text-anchor="middle" font-size="11" fill="#28a745" font-weight="600">0.88</text>
                                
                                <circle cx="130" cy="90" r="4" fill="#ffc107"/>
                                <text x="130" y="108" text-anchor="middle" font-size="11" fill="#ffc107" font-weight="600">0.72</text>
                                
                                <circle cx="178" cy="90" r="4" fill="#ff8c00"/>
                                <text x="178" y="108" text-anchor="middle" font-size="11" fill="#ff8c00" font-weight="600">0.45</text>
                                
                                <circle cx="231" cy="90" r="4" fill="#dc3545"/>
                                <text x="231" y="108" text-anchor="middle" font-size="11" fill="#dc3545" font-weight="600">0.20</text>
                                
                                <text x="135" y="5" text-anchor="middle" font-size="12" fill="#1E64C8" font-weight="700">P(T > t·µ¢ | T > t·µ¢‚Çã‚ÇÅ)</text>
                            </g>
                            
                            <text x="150" y="140" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Time discretized into intervals</text>
                            <text x="150" y="158" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Logistic regression for each interval</text>
                        </svg>
                    </div>
                    <div class="method-name">Discrete Time Models</div>
                    <div class="method-desc">Transforms survival analysis into sequence of binary classification problems. Flexible and easy to implement with standard ML tools.</div>
                </div>
            </div>
            
            <!-- Evaluation Metrics -->
            <div class="metrics-box">
                <div class="metrics-title">üìä Evaluation Metrics for Survival Analysis</div>
                <div class="metrics-grid">
                    <div class="metric-item">C-index (Concordance)</div>
                    <div class="metric-item">Time-dependent AUC</div>
                    <div class="metric-item">Calibration Plots</div>
                    <div class="metric-item">Brier Score</div>
                    <div class="metric-item">Integrated Brier Score</div>
                </div>
            </div>
        </div>
        
        <!-- SECTION 1: Random Survival Forests -->
        <div id="rsf" class="detailed-section">
            <div class="section-header">
                <div class="section-number">METHOD 1</div>
                <div class="section-title">Random Survival Forests (RSF)</div>
            </div>
            <div class="section-content">
                
                <div class="subsection">
                    <div class="subsection-title">Overview & Core Concept</div>
                    <div class="subsection-content">
                        Random Survival Forests extend the traditional Random Forest algorithm to handle censored survival data. Instead of predicting a class label or continuous value, RSF estimates the entire survival function S(t) for each individual, representing the probability of surviving beyond time t. The method builds an ensemble of survival trees, each trained on a bootstrap sample of the data, and aggregates their predictions to produce robust, non-parametric survival estimates that can capture complex patterns without assuming proportional hazards or specific distributional forms.
                    </div>
                </div>

                <div class="diagram-container">
                    <div class="diagram-title">üå≤ Complete RSF Architecture: From Data to Prediction</div>
                    <svg width="1100" height="450" viewBox="0 0 1100 450">
                        <!-- Input Data -->
                        <g transform="translate(20,30)">
                            <rect x="0" y="0" width="140" height="180" fill="#f8fbff" stroke="#1E64C8" stroke-width="3" rx="8"/>
                            <text x="70" y="28" text-anchor="middle" font-size="16" font-weight="700" fill="#1E64C8">Training Data</text>
                            
                            <!-- Table representation -->
                            <line x1="15" y1="45" x2="125" y2="45" stroke="#333" stroke-width="2"/>
                            <text x="25" y="65" font-size="13" fill="#333" font-weight="600">Covariates: X</text>
                            <text x="25" y="85" font-size="13" fill="#333">Time: T</text>
                            <text x="25" y="105" font-size="13" fill="#333">Event: Œ¥</text>
                            
                            <!-- Sample rows -->
                            <rect x="15" y="115" width="110" height="10" fill="#28a745" opacity="0.4"/>
                            <rect x="15" y="127" width="110" height="10" fill="#28a745" opacity="0.4"/>
                            <rect x="15" y="139" width="88" height="10" fill="#e74c3c" opacity="0.4"/>
                            <text x="108" y="147" font-size="10" fill="#e74c3c" font-weight="600">censored</text>
                            <rect x="15" y="151" width="110" height="10" fill="#28a745" opacity="0.4"/>
                            <text x="70" y="175" text-anchor="middle" font-size="11" fill="#666" font-style="italic">n observations</text>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 170,120 L 210,120" stroke="#1E64C8" stroke-width="3" marker-end="url(#arrow1)"/>
                        <text x="190" y="110" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="600">Bootstrap</text>
                        
                        <!-- Bootstrap Samples -->
                        <g transform="translate(220,25)">
                            <rect x="0" y="0" width="100" height="70" fill="#fff3cd" stroke="#ffc107" stroke-width="2" rx="6"/>
                            <text x="50" y="22" text-anchor="middle" font-size="13" font-weight="700" fill="#856404">Sample 1</text>
                            <rect x="12" y="32" width="76" height="6" fill="#28a745" opacity="0.5"/>
                            <rect x="12" y="40" width="76" height="6" fill="#28a745" opacity="0.5"/>
                            <rect x="12" y="48" width="60" height="6" fill="#e74c3c" opacity="0.5"/>
                            <text x="50" y="66" text-anchor="middle" font-size="10" fill="#666">~63% unique</text>
                            
                            <rect x="0" y="80" width="100" height="70" fill="#fff3cd" stroke="#ffc107" stroke-width="2" rx="6"/>
                            <text x="50" y="102" text-anchor="middle" font-size="13" font-weight="700" fill="#856404">Sample 2</text>
                            <rect x="12" y="112" width="76" height="6" fill="#28a745" opacity="0.5"/>
                            <rect x="12" y="120" width="65" height="6" fill="#e74c3c" opacity="0.5"/>
                            <rect x="12" y="128" width="76" height="6" fill="#28a745" opacity="0.5"/>
                            
                            <text x="50" y="170" text-anchor="middle" font-size="16" fill="#666">‚ãÆ</text>
                            
                            <rect x="0" y="185" width="100" height="70" fill="#fff3cd" stroke="#ffc107" stroke-width="2" rx="6"/>
                            <text x="50" y="207" text-anchor="middle" font-size="13" font-weight="700" fill="#856404">Sample B</text>
                            <rect x="12" y="217" width="76" height="6" fill="#28a745" opacity="0.5"/>
                            <rect x="12" y="225" width="76" height="6" fill="#28a745" opacity="0.5"/>
                            <rect x="12" y="233" width="55" height="6" fill="#e74c3c" opacity="0.5"/>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 330,120 L 370,120" stroke="#1E64C8" stroke-width="3" marker-end="url(#arrow1)"/>
                        <text x="350" y="110" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="600">Build</text>
                        
                        <!-- Survival Trees -->
                        <g transform="translate(380,15)">
                            <!-- Tree 1 -->
                            <g>
                                <rect x="-12" y="-8" width="110" height="95" fill="#e8f2ff" stroke="#1E64C8" stroke-width="2" rx="6" opacity="0.4"/>
                                <circle cx="40" cy="12" r="8" fill="#28a745"/>
                                <text x="40" y="17" text-anchor="middle" font-size="10" fill="white" font-weight="700">Root</text>
                                
                                <line x1="40" y1="20" x2="25" y2="45" stroke="#333" stroke-width="2"/>
                                <line x1="40" y1="20" x2="55" y2="45" stroke="#333" stroke-width="2"/>
                                
                                <circle cx="25" cy="48" r="6" fill="#ff8c00"/>
                                <circle cx="55" cy="48" r="6" fill="#ff8c00"/>
                                
                                <line x1="25" y1="54" x2="18" y2="70" stroke="#333" stroke-width="1.5"/>
                                <line x1="25" y1="54" x2="32" y2="70" stroke="#333" stroke-width="1.5"/>
                                <line x1="55" y1="54" x2="48" y2="70" stroke="#333" stroke-width="1.5"/>
                                <line x1="55" y1="54" x2="62" y2="70" stroke="#333" stroke-width="1.5"/>
                                
                                <rect x="15" y="70" width="6" height="6" fill="#1E64C8"/>
                                <rect x="29" y="70" width="6" height="6" fill="#e74c3c"/>
                                <rect x="45" y="70" width="6" height="6" fill="#28a745"/>
                                <rect x="59" y="70" width="6" height="6" fill="#1E64C8"/>
                                
                                <text x="40" y="95" text-anchor="middle" font-size="12" fill="#1E64C8" font-weight="700">Tree 1</text>
                            </g>
                            
                            <!-- Tree 2 -->
                            <g transform="translate(120,0)">
                                <rect x="-12" y="-8" width="110" height="95" fill="#e8f2ff" stroke="#1E64C8" stroke-width="2" rx="6" opacity="0.4"/>
                                <circle cx="40" cy="12" r="8" fill="#28a745"/>
                                <text x="40" y="17" text-anchor="middle" font-size="10" fill="white" font-weight="700">Root</text>
                                
                                <line x1="40" y1="20" x2="25" y2="45" stroke="#333" stroke-width="2"/>
                                <line x1="40" y1="20" x2="55" y2="45" stroke="#333" stroke-width="2"/>
                                
                                <circle cx="25" cy="48" r="6" fill="#ff8c00"/>
                                <circle cx="55" cy="48" r="6" fill="#ff8c00"/>
                                
                                <line x1="55" y1="54" x2="48" y2="70" stroke="#333" stroke-width="1.5"/>
                                <line x1="55" y1="54" x2="62" y2="70" stroke="#333" stroke-width="1.5"/>
                                
                                <rect x="22" y="70" width="6" height="6" fill="#28a745"/>
                                <rect x="45" y="70" width="6" height="6" fill="#1E64C8"/>
                                <rect x="59" y="70" width="6" height="6" fill="#e74c3c"/>
                                
                                <text x="40" y="95" text-anchor="middle" font-size="12" fill="#1E64C8" font-weight="700">Tree 2</text>
                            </g>
                            
                            <!-- Tree B -->
                            <g transform="translate(240,0)">
                                <rect x="-12" y="-8" width="110" height="95" fill="#e8f2ff" stroke="#1E64C8" stroke-width="2" rx="6" opacity="0.4"/>
                                <circle cx="40" cy="12" r="8" fill="#28a745"/>
                                <text x="40" y="17" text-anchor="middle" font-size="10" fill="white" font-weight="700">Root</text>
                                
                                <line x1="40" y1="20" x2="25" y2="45" stroke="#333" stroke-width="2"/>
                                <line x1="40" y1="20" x2="55" y2="45" stroke="#333" stroke-width="2"/>
                                
                                <circle cx="25" cy="48" r="6" fill="#ff8c00"/>
                                <circle cx="55" cy="48" r="6" fill="#ff8c00"/>
                                
                                <line x1="25" y1="54" x2="18" y2="70" stroke="#333" stroke-width="1.5"/>
                                <line x1="25" y1="54" x2="32" y2="70" stroke="#333" stroke-width="1.5"/>
                                
                                <rect x="15" y="70" width="6" height="6" fill="#e74c3c"/>
                                <rect x="29" y="70" width="6" height="6" fill="#1E64C8"/>
                                <rect x="52" y="70" width="6" height="6" fill="#28a745"/>
                                
                                <text x="40" y="95" text-anchor="middle" font-size="12" fill="#1E64C8" font-weight="700">Tree B</text>
                            </g>
                            
                            <text x="170" y="120" text-anchor="middle" font-size="12" fill="#666" font-style="italic">Each terminal node stores survival times</text>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 750,120 L 790,120" stroke="#1E64C8" stroke-width="3" marker-end="url(#arrow1)"/>
                        <text x="770" y="110" text-anchor="middle" font-size="13" fill="#1E64C8" font-weight="600">Average</text>
                        
                        <!-- Ensemble Output -->
                        <g transform="translate(800,30)">
                            <rect x="0" y="0" width="280" height="160" fill="#f8fbff" stroke="#1E64C8" stroke-width="3" rx="10"/>
                            <text x="140" y="28" text-anchor="middle" font-size="17" font-weight="700" fill="#1E64C8">Ensemble Survival Curve</text>
                            
                            <!-- Survival curve plot -->
                            <g transform="translate(30,50)">
                                <!-- Axes -->
                                <line x1="0" y1="90" x2="220" y2="90" stroke="#333" stroke-width="2"/>
                                <line x1="0" y1="0" x2="0" y2="90" stroke="#333" stroke-width="2"/>
                                
                                <!-- Axis labels -->
                                <text x="110" y="110" text-anchor="middle" font-size="13" fill="#333" font-weight="600">Time</text>
                                <text x="-10" y="45" text-anchor="middle" font-size="13" fill="#333" font-weight="600" transform="rotate(-90,-10,45)">Survival Prob.</text>
                                
                                <!-- Individual tree curves (light) -->
                                <path d="M 5,8 Q 50,12 100,20 T 180,50 L 215,75" stroke="#1E64C8" stroke-width="1.5" fill="none" opacity="0.3"/>
                                <path d="M 5,8 Q 60,14 110,28 T 190,62 L 215,78" stroke="#1E64C8" stroke-width="1.5" fill="none" opacity="0.3"/>
                                <path d="M 5,8 Q 45,10 90,18 T 170,45 L 215,72" stroke="#1E64C8" stroke-width="1.5" fill="none" opacity="0.3"/>
                                <path d="M 5,8 Q 55,13 105,25 T 185,55 L 215,76" stroke="#1E64C8" stroke-width="1.5" fill="none" opacity="0.3"/>
                                
                                <!-- Average curve (bold) -->
                                <path d="M 5,8 Q 52,12 102,23 T 185,53 L 215,75" stroke="#28a745" stroke-width="4" fill="none"/>
                                
                                <!-- Legend -->
                                <line x1="160" y1="12" x2="180" y2="12" stroke="#1E64C8" stroke-width="1.5" opacity="0.3"/>
                                <text x="185" y="16" font-size="11" fill="#666">Individual trees</text>
                                <line x1="160" y1="24" x2="180" y2="24" stroke="#28a745" stroke-width="4"/>
                                <text x="185" y="28" font-size="11" fill="#666" font-weight="600">Ensemble avg</text>
                            </g>
                        </g>
                        
                        <!-- Splitting Criterion Box -->
                        <g transform="translate(380,160)">
                            <rect x="0" y="0" width="340" height="120" fill="#fff3cd" stroke="#ffc107" stroke-width="3" rx="8"/>
                            <text x="170" y="25" text-anchor="middle" font-size="16" font-weight="700" fill="#856404">Log-Rank Split Criterion</text>
                            
                            <text x="170" y="52" text-anchor="middle" font-size="14" fill="#333">Maximize separation between child nodes:</text>
                            
                            <text x="170" y="75" text-anchor="middle" font-size="16" fill="#333" font-family="Courier New" font-weight="600">|O_L - E_L| / ‚àöVar(O_L)</text>
                            
                            <g transform="translate(25,90)">
                                <text x="0" y="0" font-size="12" fill="#555">O_L = observed events in left child</text>
                                <text x="0" y="18" font-size="12" fill="#555">E_L = expected events in left child under null</text>
                            </g>
                        </g>
                        
                        <!-- OOB Box -->
                        <g transform="translate(20,270)">
                            <rect x="0" y="0" width="300" height="110" fill="#d1ecf1" stroke="#17a2b8" stroke-width="3" rx="8"/>
                            <text x="150" y="25" text-anchor="middle" font-size="16" font-weight="700" fill="#0c5460">Out-of-Bag (OOB) Validation</text>
                            
                            <g transform="translate(20,40)">
                                <text x="0" y="0" font-size="13" fill="#0c5460">‚Ä¢ ~37% of samples not used in each tree</text>
                                <text x="0" y="20" font-size="13" fill="#0c5460">‚Ä¢ Use OOB samples for unbiased error estimate</text>
                                <text x="0" y="40" font-size="13" fill="#0c5460">‚Ä¢ No separate validation set needed</text>
                                <text x="0" y="60" font-size="13" fill="#0c5460">‚Ä¢ Compute OOB C-index for model selection</text>
                            </g>
                        </g>
                        
                        <!-- Feature Importance Box -->
                        <g transform="translate(370,290)">
                            <rect x="0" y="0" width="350" height="90" fill="#e8f2ff" stroke="#1E64C8" stroke-width="3" rx="8"/>
                            <text x="175" y="25" text-anchor="middle" font-size="16" font-weight="700" fill="#1E64C8">Variable Importance Measures</text>
                            
                            <g transform="translate(20,40)">
                                <text x="0" y="0" font-size="13" fill="#333">1. <tspan font-weight="600">VIMP</tspan>: Permutation importance (OOB prediction error)</text>
                                <text x="0" y="20" font-size="13" fill="#333">2. <tspan font-weight="600">Minimal Depth</tspan>: Average depth of first split</text>
                                <text x="0" y="40" font-size="13" fill="#333">3. <tspan font-weight="600">Split Frequency</tspan>: How often feature is used</text>
                            </g>
                        </g>
                        
                        <defs>
                            <marker id="arrow1" markerWidth="12" markerHeight="12" refX="10" refY="4" orient="auto">
                                <path d="M0,0 L0,8 L12,4 z" fill="#1E64C8"/>
                            </marker>
                        </defs>
                    </svg>
                    <div class="diagram-caption">
                        Complete workflow of Random Survival Forests: Data is bootstrap sampled, survival trees are grown using log-rank splitting, predictions from all trees are averaged to create ensemble survival function. OOB samples provide unbiased validation, and feature importance can be extracted.
                    </div>
                </div>


                <div class="subsection">
                    <div class="subsection-title">Key Features & Advantages</div>
                    <div class="feature-grid">
                        <div class="feature-box">
                            <div class="feature-box-title">üå≥ Non-parametric & Flexible</div>
                            <div class="feature-box-content">
                                Makes no assumptions about the baseline hazard or proportional hazards. Can model complex, non-linear relationships between covariates and survival times, including interactions that would be difficult to specify manually.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üîç Automatic Feature Selection</div>
                            <div class="feature-box-content">
                                Automatically identifies important predictors through variable importance measures (VIMP, minimal depth). Robust to irrelevant features and multicollinearity.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üõ°Ô∏è Handles Missing Data</div>
                            <div class="feature-box-content">
                                Can use surrogate splits when features have missing values, maintaining prediction accuracy even with incomplete data. No need for imputation in many cases.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üìä Built-in Cross-validation</div>
                            <div class="feature-box-content">
                                Out-of-bag (OOB) samples (~37% per tree) provide unbiased estimate of prediction error without requiring a separate validation set. Efficient use of data.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">‚ö° Parallelizable Training</div>
                            <div class="feature-box-content">
                                Trees are grown independently, allowing for parallel computation across multiple cores/machines. Scales well to large datasets.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üéØ Robust Predictions</div>
                            <div class="feature-box-content">
                                Ensemble averaging reduces variance and overfitting. More stable predictions compared to single trees, especially with complex or noisy data.
                            </div>
                        </div>
                    </div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Algorithm Details & Implementation Steps</div>
                    <div class="subsection-content">
                        The RSF algorithm follows these key steps for building each survival tree in the forest:
                    </div>
                    
                    <ul>
                        <li><strong>Bootstrap Sampling:</strong> Draw a random sample with replacement from the training data. Typically results in about 63% unique observations per tree, with remaining 37% as out-of-bag (OOB) samples for validation.</li>
                        
                        <li><strong>Random Feature Selection:</strong> At each node during tree growing, randomly select a subset of m features from all p available features. Common choices: m = ‚àöp for survival data or m = p/3 for regression-type problems.</li>
                        
                        <li><strong>Split Point Selection:</strong> For each selected feature, find the optimal split point that maximizes survival difference between daughter nodes using the log-rank test statistic. The split maximizes |O_L - E_L| / ‚àöVar(O_L), where O_L is observed events and E_L is expected events in the left child.</li>
                        
                        <li><strong>Recursive Partitioning:</strong> Recursively apply splitting until a stopping criterion is met: minimum node size reached (e.g., 3-15 observations), no significant splits available (p-value threshold), or maximum depth achieved.</li>
                        
                        <li><strong>Terminal Node Estimation:</strong> In each leaf node, estimate the survival function using the Kaplan-Meier estimator based on the training samples that fall into that node. This gives S_leaf(t) for all time points.</li>
                        
                        <li><strong>Ensemble Prediction:</strong> For a new observation x, drop it down each of the B trees to obtain B terminal nodes. Collect the B survival function estimates and average them: S_ensemble(t|x) = (1/B) Œ£ S_b(t|x).</li>
                        
                        <li><strong>Variable Importance:</strong> Calculate feature importance using permutation: for each feature, randomly permute its values in OOB samples and measure decrease in prediction accuracy (C-index). Larger decreases indicate more important features.</li>
                    </ul>
                </div>

                <div class="highlight-box">
                    <div class="highlight-box-title">‚ö° Hyperparameter Tuning Guide</div>
                    <div class="highlight-box-content">
                        <strong>Number of trees (ntree):</strong> 500-1000 typically sufficient. More trees = more stable predictions but longer training. Error plateaus after sufficient trees.<br><br>
                        
                        <strong>Features per split (mtry):</strong> ‚àöp is default and works well. Try p/3 or log‚ÇÇ(p) for alternatives. Smaller values = more diversity, larger values = stronger individual trees.<br><br>
                        
                        <strong>Minimum node size (nodesize):</strong> 3-15 typically. Larger values = simpler trees, less overfitting, faster training. Smaller values = more complex trees, potential overfitting.<br><br>
                        
                        <strong>Splitting rule:</strong> Log-rank (default), log-rank score, or conservation of events. Log-rank typically performs best for standard survival analysis.<br><br>
                        
                        <strong>Computational cost:</strong> Training time is O(ntree √ó n √ó p √ó log n). Use parallel processing with multiple cores. Prediction is fast: O(ntree √ó log n) per observation.
                    </div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Practical Example & Code Implementation</div>
                    <div class="subsection-content">
                        <strong>Clinical Application:</strong> Predicting cancer patient survival after diagnosis using clinical features (age, tumor stage, biomarkers), treatment information, and patient characteristics. RSF can identify complex interactions between age, tumor characteristics, and treatment response that proportional hazards models might miss.
                    </div>
                    
                    <div class="math-box"># Python Implementation using scikit-survival
from sksurv.ensemble import RandomSurvivalForest
from sksurv.metrics import concordance_index_censored
import numpy as np
import matplotlib.pyplot as plt

# Initialize Random Survival Forest
rsf = RandomSurvivalForest(
    n_estimators=1000,          # Number of trees
    min_samples_split=10,       # Min samples to split node
    min_samples_leaf=15,        # Min samples in leaf
    max_features="sqrt",        # Features to consider per split
    n_jobs=-1,                  # Use all CPU cores
    random_state=42
)

# Train model
# y_train is structured array with fields 'event' (bool) and 'time' (float)
rsf.fit(X_train, y_train)

# Get survival function for new patients
surv_funcs = rsf.predict_survival_function(X_test)

# Plot survival curves for first 5 patients
for i, surv_func in enumerate(surv_funcs[:5]):
    plt.step(surv_func.x, surv_func.y, where="post", 
             label=f"Patient {i+1}")
plt.xlabel("Time")
plt.ylabel("Survival Probability")
plt.title("Predicted Survival Curves")
plt.legend()
plt.show()

# Extract risk scores (higher = worse prognosis)
risk_scores = rsf.predict(X_test)

# Calculate C-index (concordance)
c_index = rsf.score(X_test, y_test)
print(f"C-index: {c_index:.3f}")

# Get feature importance
feature_importance = rsf.feature_importances_
important_features = np.argsort(feature_importance)[::-1][:10]
print("Top 10 important features:", important_features)</div>
                </div>

                <div class="info-box">
                    <div class="info-box-title">üìö When to Use Random Survival Forests</div>
                    <div class="info-box-content">
                        <strong>Ideal scenarios:</strong><br>
                        ‚Ä¢ Non-linear relationships between predictors and survival<br>
                        ‚Ä¢ Need for variable importance/feature selection<br>
                        ‚Ä¢ Moderate sample size (n > 100) with many features<br>
                        ‚Ä¢ Missing data in predictor variables<br>
                        ‚Ä¢ No strong prior belief in proportional hazards<br>
                        ‚Ä¢ Want interpretable feature rankings<br><br>
                        
                        <strong>Less ideal for:</strong><br>
                        ‚Ä¢ Very small samples (n < 50)<br>
                        ‚Ä¢ Need for explicit hazard ratios or covariate effects<br>
                        ‚Ä¢ Real-time predictions with limited compute resources<br>
                        ‚Ä¢ When linear Cox model performs adequately
                    </div>
                </div>

            </div>
        </div>


        <!-- SECTION 2: DeepSurv -->
        <div id="deepsurv" class="detailed-section">
            <div class="section-header">
                <div class="section-number">METHOD 2</div>
                <div class="section-title">DeepSurv: Deep Learning for Survival Analysis</div>
            </div>
            <div class="section-content">
                
                <div class="subsection">
                    <div class="subsection-title">Overview & Core Concept</div>
                    <div class="subsection-content">
                        DeepSurv is a deep neural network approach that extends the Cox proportional hazards model using deep learning architectures. Instead of assuming linear relationships between covariates and log-hazard like traditional Cox regression, DeepSurv uses a multi-layer feed-forward neural network to learn highly complex, non-linear representations of the input features. The network is trained using the Cox partial likelihood loss function, which maintains the semi-parametric nature and relative risk interpretation of Cox models while allowing the model to capture intricate patterns in high-dimensional data. This makes DeepSurv particularly powerful for genomic data, medical imaging features, or any scenario where relationships between predictors and survival are highly non-linear.
                    </div>
                </div>

                <div class="diagram-container">
                    <div class="diagram-title">üß† DeepSurv Architecture & Training Process</div>
                    <svg width="1100" height="550" viewBox="0 0 1100 550">
                        <!-- Input Layer -->
                        <g transform="translate(30,100)">
                            <rect x="0" y="0" width="150" height="240" fill="#f8fbff" stroke="#1E64C8" stroke-width="3" rx="8"/>
                            <text x="75" y="28" text-anchor="middle" font-size="16" font-weight="700" fill="#1E64C8">Input Features (X)</text>
                            
                            <!-- Feature list -->
                            <g transform="translate(18,50)">
                                <rect x="0" y="0" width="114" height="24" fill="#e8f2ff" stroke="#1E64C8" stroke-width="1.5" rx="4"/>
                                <text x="57" y="17" text-anchor="middle" font-size="12" fill="#333">Age: 65</text>
                                
                                <rect x="0" y="30" width="114" height="24" fill="#e8f2ff" stroke="#1E64C8" stroke-width="1.5" rx="4"/>
                                <text x="57" y="47" text-anchor="middle" font-size="12" fill="#333">Tumor: 3.2cm</text>
                                
                                <rect x="0" y="60" width="114" height="24" fill="#e8f2ff" stroke="#1E64C8" stroke-width="1.5" rx="4"/>
                                <text x="57" y="77" text-anchor="middle" font-size="12" fill="#333">Grade: III</text>
                                
                                <rect x="0" y="90" width="114" height="24" fill="#e8f2ff" stroke="#1E64C8" stroke-width="1.5" rx="4"/>
                                <text x="57" y="107" text-anchor="middle" font-size="12" fill="#333">Gene: [...]</text>
                                
                                <rect x="0" y="120" width="114" height="24" fill="#e8f2ff" stroke="#1E64C8" stroke-width="1.5" rx="4"/>
                                <text x="57" y="137" text-anchor="middle" font-size="12" fill="#333">Treatment</text>
                                
                                <text x="57" y="160" text-anchor="middle" font-size="14" fill="#666">‚ãÆ</text>
                                
                                <text x="57" y="180" text-anchor="middle" font-size="11" fill="#666" font-style="italic">p features</text>
                            </g>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 190,220 L 230,220" stroke="#1E64C8" stroke-width="3" marker-end="url(#arrow2)"/>
                        
                        <!-- Neural Network -->
                        <g transform="translate(240,80)">
                            <rect x="0" y="0" width="420" height="280" fill="#fff3cd" stroke="#ffc107" stroke-width="3" rx="10"/>
                            <text x="210" y="28" text-anchor="middle" font-size="17" font-weight="700" fill="#856404">Deep Neural Network</text>
                            
                            <!-- Network visualization -->
                            <g transform="translate(50,60)">
                                <!-- Input layer -->
                                <text x="0" y="-12" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Input</text>
                                <circle cx="0" cy="20" r="6" fill="#1E64C8"/>
                                <circle cx="0" cy="45" r="6" fill="#1E64C8"/>
                                <circle cx="0" cy="70" r="6" fill="#1E64C8"/>
                                <circle cx="0" cy="95" r="6" fill="#1E64C8"/>
                                <circle cx="0" cy="120" r="6" fill="#1E64C8"/>
                                <text x="0" y="155" text-anchor="middle" font-size="10" fill="#666">‚ãÆ</text>
                                <circle cx="0" cy="175" r="6" fill="#1E64C8"/>
                                <text x="0" y="200" text-anchor="middle" font-size="11" fill="#1E64C8" font-weight="600">n‚ÇÄ = p</text>
                                
                                <!-- Hidden layer 1 -->
                                <text x="85" y="-12" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Hidden 1</text>
                                <circle cx="85" cy="30" r="6" fill="#ff8c00"/>
                                <circle cx="85" cy="55" r="6" fill="#ff8c00"/>
                                <circle cx="85" cy="80" r="6" fill="#ff8c00"/>
                                <circle cx="85" cy="105" r="6" fill="#ff8c00"/>
                                <circle cx="85" cy="130" r="6" fill="#ff8c00"/>
                                <text x="85" y="160" text-anchor="middle" font-size="10" fill="#666">‚ãÆ</text>
                                <text x="85" y="200" text-anchor="middle" font-size="11" fill="#ff8c00" font-weight="600">n‚ÇÅ units</text>
                                
                                <!-- Hidden layer 2 -->
                                <text x="170" y="-12" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Hidden 2</text>
                                <circle cx="170" cy="40" r="6" fill="#ff8c00"/>
                                <circle cx="170" cy="70" r="6" fill="#ff8c00"/>
                                <circle cx="170" cy="100" r="6" fill="#ff8c00"/>
                                <circle cx="170" cy="130" r="6" fill="#ff8c00"/>
                                <text x="170" y="160" text-anchor="middle" font-size="10" fill="#666">‚ãÆ</text>
                                <text x="170" y="200" text-anchor="middle" font-size="11" fill="#ff8c00" font-weight="600">n‚ÇÇ units</text>
                                
                                <!-- Hidden layer L -->
                                <text x="255" y="-12" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Hidden L</text>
                                <circle cx="255" cy="50" r="6" fill="#ff8c00"/>
                                <circle cx="255" cy="80" r="6" fill="#ff8c00"/>
                                <circle cx="255" cy="110" r="6" fill="#ff8c00"/>
                                <text x="255" y="140" text-anchor="middle" font-size="10" fill="#666">‚ãÆ</text>
                                <text x="255" y="200" text-anchor="middle" font-size="11" fill="#ff8c00" font-weight="600">n‚Çó units</text>
                                
                                <!-- Output layer -->
                                <text x="320" y="-12" text-anchor="middle" font-size="12" fill="#666" font-weight="600">Output</text>
                                <circle cx="320" cy="95" r="8" fill="#28a745"/>
                                <text x="320" y="135" text-anchor="middle" font-size="13" fill="#28a745" font-weight="700">log h(t|X)</text>
                                <text x="320" y="200" text-anchor="middle" font-size="11" fill="#28a745" font-weight="600">1 unit</text>
                                
                                <!-- Sample connections -->
                                <line x1="6" y1="20" x2="79" y2="30" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="6" y1="45" x2="79" y2="55" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="6" y1="70" x2="79" y2="80" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="6" y1="95" x2="79" y2="105" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                
                                <line x1="91" y1="30" x2="164" y2="40" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="91" y1="55" x2="164" y2="70" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="91" y1="80" x2="164" y2="100" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                
                                <line x1="176" y1="40" x2="249" y2="50" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="176" y1="70" x2="249" y2="80" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="176" y1="100" x2="249" y2="110" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                
                                <line x1="261" y1="50" x2="312" y2="95" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="261" y1="80" x2="312" y2="95" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                                <line x1="261" y1="110" x2="312" y2="95" stroke="#ddd" stroke-width="1" opacity="0.5"/>
                            </g>
                            
                            <!-- Activation note -->
                            <text x="210" y="260" text-anchor="middle" font-size="13" fill="#856404" font-style="italic">Activation: ReLU, SELU, or Tanh + Dropout</text>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 670,220 L 710,220" stroke="#1E64C8" stroke-width="3" marker-end="url(#arrow2)"/>
                        
                        <!-- Cox Loss -->
                        <g transform="translate(720,110)">
                            <rect x="0" y="0" width="340" height="220" fill="#f8fbff" stroke="#1E64C8" stroke-width="3" rx="10"/>
                            <text x="170" y="28" text-anchor="middle" font-size="17" font-weight="700" fill="#1E64C8">Cox Partial Likelihood Loss</text>
                            
                            <!-- Loss formula -->
                            <g transform="translate(170,60)">
                                <text x="0" y="0" text-anchor="middle" font-size="15" fill="#333" font-weight="700">Objective Function:</text>
                                
                                <text x="0" y="30" text-anchor="middle" font-size="14" fill="#333" font-family="Courier New" font-weight="600">L(Œ∏) = -‚àë·µ¢ Œ¥·µ¢[log h(t·µ¢|X·µ¢) - log ‚àë‚±º‚ààR·µ¢ h(t·µ¢|X‚±º)]</text>
                                
                                <g transform="translate(-145,65)">
                                    <text x="0" y="0" font-size="13" fill="#555" font-weight="600">where:</text>
                                    <text x="0" y="20" font-size="12" fill="#555">‚Ä¢ Œ¥·µ¢ = event indicator (1 if event, 0 if censored)</text>
                                    <text x="0" y="38" font-size="12" fill="#555">‚Ä¢ h(t|X) = exp(NN(X;Œ∏)) = hazard function</text>
                                    <text x="0" y="56" font-size="12" fill="#555">‚Ä¢ R·µ¢ = risk set at time t·µ¢ (all j with t‚±º ‚â• t·µ¢)</text>
                                    <text x="0" y="74" font-size="12" fill="#555">‚Ä¢ Œ∏ = all network weights and biases</text>
                                    <text x="0" y="92" font-size="12" fill="#555">‚Ä¢ NN(X;Œ∏) = output of neural network</text>
                                </g>
                            </g>
                        </g>
                        
                        <!-- Backpropagation arrow -->
                        <path d="M 890,340 Q 890,410 450,410 T 250,410" stroke="#e74c3c" stroke-width="3" stroke-dasharray="6,6" marker-end="url(#arrow3)"/>
                        <text x="550" y="435" text-anchor="middle" font-size="15" fill="#e74c3c" font-weight="700">Backpropagation: ‚àáŒ∏L(Œ∏) ‚Üí Update weights</text>
                        
                        <!-- Training info -->
                        <g transform="translate(30,390)">
                            <rect x="0" y="0" width="220" height="130" fill="#e8f2ff" stroke="#1E64C8" stroke-width="3" rx="8"/>
                            <text x="110" y="25" text-anchor="middle" font-size="15" font-weight="700" fill="#1E64C8">Training Data</text>
                            
                            <g transform="translate(18,42)">
                                <text x="0" y="0" font-size="12" fill="#333">‚Ä¢ Features: X ‚àà ‚Ñù‚ÅøÀ£·µñ</text>
                                <text x="0" y="20" font-size="12" fill="#333">‚Ä¢ Event times: T ‚àà ‚Ñù‚Åø</text>
                                <text x="0" y="40" font-size="12" fill="#333">‚Ä¢ Event indicators: Œ¥ ‚àà {0,1}‚Åø</text>
                                <text x="0" y="60" font-size="12" fill="#333">‚Ä¢ Continuous & categorical</text>
                                <text x="5" y="78" font-size="12" fill="#333">covariates supported</text>
                            </g>
                        </g>
                        
                        <!-- Optimizer info -->
                        <g transform="translate(720,360)">
                            <rect x="0" y="0" width="340" height="160" fill="#fff3cd" stroke="#ffc107" stroke-width="3" rx="8"/>
                            <text x="170" y="25" text-anchor="middle" font-size="15" font-weight="700" fill="#856404">Optimization Details</text>
                            
                            <g transform="translate(20,45)">
                                <text x="0" y="0" font-size="13" fill="#333" font-weight="600">Optimizer: Adam, SGD, or RMSprop</text>
                                <text x="0" y="22" font-size="12" fill="#555">‚Ä¢ Learning rate: 0.001 - 0.01 (with decay)</text>
                                <text x="0" y="40" font-size="12" fill="#555">‚Ä¢ Batch size: 32 - 256</text>
                                <text x="0" y="58" font-size="12" fill="#555">‚Ä¢ Epochs: 50 - 500 (early stopping)</text>
                                <text x="0" y="76" font-size="12" fill="#555">‚Ä¢ L1/L2 regularization: Œª = 0.001 - 0.01</text>
                                <text x="0" y="94" font-size="12" fill="#555">‚Ä¢ Dropout: 0.2 - 0.5</text>
                                <text x="0" y="112" font-size="12" fill="#555">‚Ä¢ Weight initialization: He or Xavier</text>
                            </g>
                        </g>
                        
                        <defs>
                            <marker id="arrow2" markerWidth="12" markerHeight="12" refX="10" refY="4" orient="auto">
                                <path d="M0,0 L0,8 L12,4 z" fill="#1E64C8"/>
                            </marker>
                            <marker id="arrow3" markerWidth="12" markerHeight="12" refX="10" refY="4" orient="auto">
                                <path d="M0,0 L0,8 L12,4 z" fill="#e74c3c"/>
                            </marker>
                        </defs>
                    </svg>
                    <div class="diagram-caption">
                        DeepSurv architecture showing input features processed through multiple hidden layers with non-linear activations, producing log-hazard predictions. The Cox partial likelihood loss enables end-to-end training via backpropagation while maintaining the interpretable hazard ratio framework.
                    </div>
                </div>


                <div class="subsection">
                    <div class="subsection-title">Key Features & Advantages</div>
                    <div class="feature-grid">
                        <div class="feature-box">
                            <div class="feature-box-title">üß† Deep Non-linear Representations</div>
                            <div class="feature-box-content">
                                Multiple hidden layers can learn hierarchical, highly complex non-linear relationships between covariates and survival that shallow models cannot capture. Particularly powerful for discovering subtle patterns in high-dimensional data.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üìà High-dimensional Data Excellence</div>
                            <div class="feature-box-content">
                                Excels with genomic data, medical imaging features, or other settings where p >> n (features greatly exceed samples). Deep architectures can perform implicit dimensionality reduction and feature learning.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üîó Automatic Interaction Learning</div>
                            <div class="feature-box-content">
                                Automatically discovers complex interactions between features without manual specification. Hidden layers naturally combine features in non-linear ways that would be intractable to enumerate manually.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">‚öñÔ∏è Maintains Cox Interpretability</div>
                            <div class="feature-box-content">
                                Uses Cox partial likelihood, so hazard ratios between patients can still be computed for risk stratification. Predictions have clear clinical interpretation as relative risks.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üéØ Transfer Learning Potential</div>
                            <div class="feature-box-content">
                                Pre-trained networks from related tasks can be fine-tuned, leveraging knowledge from larger datasets. Particularly useful when labeled survival data is limited.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üîß Flexible Architecture</div>
                            <div class="feature-box-content">
                                Can incorporate various input types (continuous, categorical, images, text) with appropriate preprocessing layers. Architecture can be customized for domain-specific requirements.
                            </div>
                        </div>
                    </div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Network Architecture Design</div>
                    <div class="subsection-content">
                        <strong>Typical architecture components for DeepSurv:</strong>
                    </div>
                    
                    <ul>
                        <li><strong>Input Layer:</strong> Dimensionality equals number of features (p). Common preprocessing: standardization (zero mean, unit variance) or normalization (min-max scaling to [0,1]). One-hot encoding for categorical variables.</li>
                        
                        <li><strong>Hidden Layers:</strong> Usually 1-4 hidden layers with decreasing width pattern (e.g., 128 ‚Üí 64 ‚Üí 32 or 256 ‚Üí 128 ‚Üí 64). Deeper networks for very complex patterns, shallower for moderate complexity. Each layer has fewer neurons than previous to create information bottleneck.</li>
                        
                        <li><strong>Activation Functions:</strong> ReLU (most common, fast, avoids vanishing gradients), SELU (self-normalizing, good for deep networks), or Tanh (bounded output). Applied element-wise after each hidden layer's linear transformation.</li>
                        
                        <li><strong>Dropout Layers:</strong> Regularization via random neuron deactivation during training. Drop rate typically 0.1-0.5. Higher dropout for smaller datasets. Reduces overfitting by preventing co-adaptation of neurons.</li>
                        
                        <li><strong>Batch Normalization:</strong> Normalizes layer inputs to have zero mean and unit variance. Stabilizes training, allows higher learning rates, acts as regularizer. Applied before or after activation.</li>
                        
                        <li><strong>Output Layer:</strong> Single neuron with linear activation producing log-hazard ratio log h(t|X). No softmax or sigmoid needed since we're not doing classification. Output can be any real number.</li>
                    </ul>
                    
                    <div class="math-box"># Example architecture specification
Layer 1 (Input):        p neurons  (features)
Layer 2 (Hidden 1):     128 neurons + ReLU + Dropout(0.3) + BatchNorm
Layer 3 (Hidden 2):     64 neurons  + ReLU + Dropout(0.3) + BatchNorm
Layer 4 (Hidden 3):     32 neurons  + ReLU + Dropout(0.2)
Layer 5 (Output):       1 neuron    (linear activation)

Forward pass:
  z1 = X
  z2 = ReLU(BatchNorm(W1¬∑z1 + b1))  # Apply dropout in training
  z3 = ReLU(BatchNorm(W2¬∑z2 + b2))
  z4 = ReLU(W3¬∑z3 + b3)
  output = W4¬∑z4 + b4  # log hazard</div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Training Process & Optimization</div>
                    <div class="subsection-content">
                        DeepSurv is trained using mini-batch stochastic gradient descent with the Cox partial likelihood loss:
                    </div>
                    
                    <ul>
                        <li><strong>Batch Formation:</strong> Divide training data into mini-batches of size B (typically 32-256). Each batch should ideally contain a mix of events and censored observations.</li>
                        
                        <li><strong>Forward Propagation:</strong> Pass batch through network to compute log-hazards: ≈∑·µ¢ = NN(X·µ¢; Œ∏) for each sample i in batch.</li>
                        
                        <li><strong>Loss Computation:</strong> Calculate negative Cox partial log-likelihood on batch. For each observed event at time t·µ¢ with Œ¥·µ¢=1, compute log likelihood contribution: ≈∑·µ¢ - log(‚àë‚±º‚ààR·µ¢ exp(≈∑‚±º)) where R·µ¢ is the risk set.</li>
                        
                        <li><strong>Backpropagation:</strong> Compute gradients ‚àáŒ∏ L(Œ∏) via automatic differentiation (chain rule applied through all layers). Modern frameworks (PyTorch, TensorFlow) handle this automatically.</li>
                        
                        <li><strong>Weight Update:</strong> Update parameters using optimizer (Adam recommended): Œ∏ ‚Üê Œ∏ - Œ±¬∑‚àáŒ∏L(Œ∏) where Œ± is learning rate. Adam adapts learning rate per parameter based on gradient history.</li>
                        
                        <li><strong>Iteration:</strong> Repeat for all batches (one epoch), then repeat for multiple epochs (50-500 typical) until convergence or early stopping triggered.</li>
                    </ul>
                </div>

                <div class="highlight-box">
                    <div class="highlight-box-title">‚ö° Training Best Practices</div>
                    <div class="highlight-box-content">
                        <strong>Learning Rate Strategy:</strong> Start with 0.001 (Adam default). Use ReduceLROnPlateau to decrease by factor of 10 when validation loss plateaus for 10+ epochs. Or use cyclic learning rates for better convergence.<br><br>
                        
                        <strong>Early Stopping:</strong> Monitor validation C-index every epoch. Stop if no improvement for 20-50 consecutive epochs. Save model with best validation performance, not the final epoch.<br><br>
                        
                        <strong>Regularization Balance:</strong> Start with moderate dropout (0.3) and L2 penalty (Œª=0.01). If overfitting, increase. If underfitting, decrease. Can also use L1 for feature selection.<br><br>
                        
                        <strong>Batch Size Selection:</strong> Larger batches (128-256) give more stable gradients but less regularization. Smaller batches (32-64) add noise that can help escape local minima. GPU memory constrains maximum size.<br><br>
                        
                        <strong>Initialization Matters:</strong> Use He initialization for ReLU (variance scales with 2/n·µ¢‚Çô) or Xavier/Glorot for Tanh/Sigmoid. Poor initialization can cause vanishing/exploding gradients.<br><br>
                        
                        <strong>Validation Strategy:</strong> Use k-fold cross-validation or hold-out validation set. Never tune on test set. Monitor both C-index and calibration during training.
                    </div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Implementation Example</div>
                    
                    <div class="math-box"># PyTorch DeepSurv Implementation
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.preprocessing import StandardScaler

class DeepSurv(nn.Module):
    def __init__(self, in_features, layers=[128, 64, 32], dropout=0.3):
        super(DeepSurv, self).__init__()
        
        # Build network layers
        modules = []
        prev_size = in_features
        
        for i, layer_size in enumerate(layers):
            # Fully connected layer
            modules.append(nn.Linear(prev_size, layer_size))
            # Batch normalization
            modules.append(nn.BatchNorm1d(layer_size))
            # Activation
            modules.append(nn.ReLU())
            # Dropout (less in final layers)
            drop_rate = dropout if i < len(layers)-1 else dropout*0.5
            modules.append(nn.Dropout(drop_rate))
            prev_size = layer_size
        
        # Output layer (log hazard)
        modules.append(nn.Linear(prev_size, 1))
        
        self.network = nn.Sequential(*modules)
    
    def forward(self, x):
        return self.network(x)

# Cox Partial Likelihood Loss
def cox_loss(log_hazards, times, events):
    # Sort by time (descending for risk set computation)
    idx = torch.argsort(times, descending=True)
    log_hazards = log_hazards[idx]
    events = events[idx]
    
    # Compute log risk = log(sum of exp(log_hazard) for risk set)
    # Use logsumexp for numerical stability
    hazard_ratio = torch.exp(log_hazards)
    log_risk = torch.log(torch.cumsum(hazard_ratio, dim=0))
    
    # Negative log partial likelihood (only for observed events)
    uncensored_likelihood = log_hazards - log_risk
    loss = -torch.sum(uncensored_likelihood * events) / torch.sum(events)
    
    return loss

# Training setup
model = DeepSurv(in_features=100, layers=[128, 64, 32], dropout=0.3)
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

# Training loop
best_c_index = 0
patience_counter = 0

for epoch in range(500):
    model.train()
    epoch_loss = 0
    
    # Mini-batch training
    for batch_idx in range(0, len(X_train_scaled), batch_size):
        batch_X = torch.FloatTensor(
            X_train_scaled[batch_idx:batch_idx+batch_size])
        batch_times = torch.FloatTensor(
            times_train[batch_idx:batch_idx+batch_size])
        batch_events = torch.FloatTensor(
            events_train[batch_idx:batch_idx+batch_size])
        
        optimizer.zero_grad()
        log_hazards = model(batch_X)
        loss = cox_loss(log_hazards, batch_times, batch_events)
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
    
    # Validation
    model.eval()
    with torch.no_grad():
        val_log_hazards = model(torch.FloatTensor(X_val_scaled))
        c_index = concordance_index(
            times_val, -val_log_hazards.numpy(), events_val)
    
    scheduler.step(epoch_loss)
    
    if c_index > best_c_index:
        best_c_index = c_index
        torch.save(model.state_dict(), 'best_model.pth')
        patience_counter = 0
    else:
        patience_counter += 1
    
    if patience_counter >= 30:
        print(f"Early stopping at epoch {epoch}")
        break
    
    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {epoch_loss:.4f}, "
              f"Val C-index: {c_index:.4f}")

# Load best model for final predictions
model.load_state_dict(torch.load('best_model.pth'))
model.eval()</div>
                </div>

                <div class="info-box">
                    <div class="info-box-title">üìö When to Use DeepSurv</div>
                    <div class="info-box-content">
                        <strong>Ideal scenarios:</strong><br>
                        ‚Ä¢ High-dimensional data (p >> n): genomics, imaging features<br>
                        ‚Ä¢ Highly non-linear relationships expected<br>
                        ‚Ä¢ Complex feature interactions present<br>
                        ‚Ä¢ Sufficient training data available (n > 500 ideally)<br>
                        ‚Ä¢ Computational resources available (GPU helpful)<br>
                        ‚Ä¢ Want to leverage transfer learning from related domains<br><br>
                        
                        <strong>Less ideal for:</strong><br>
                        ‚Ä¢ Small sample sizes (n < 100)<br>
                        ‚Ä¢ Simple linear relationships (Cox PHM may suffice)<br>
                        ‚Ä¢ Need for explicit feature effect estimates<br>
                        ‚Ä¢ Limited computational resources<br>
                        ‚Ä¢ Interpretability is paramount over prediction accuracy<br>
                        ‚Ä¢ Quick prototyping (training can take hours/days)
                    </div>
                </div>

            </div>
        </div>


        <!-- SECTION 3: Discrete Time Models -->
        <div id="discrete" class="detailed-section">
            <div class="section-header">
                <div class="section-number">METHOD 3</div>
                <div class="section-title">Discrete Time Survival Models</div>
            </div>
            <div class="section-content">
                
                <div class="subsection">
                    <div class="subsection-title">Overview & Core Concept</div>
                    <div class="subsection-content">
                        Discrete time models reformulate survival analysis as a sequence of binary classification problems. Instead of modeling continuous time directly, the follow-up period is divided into discrete intervals, and for each interval, we predict whether an individual will experience the event during that specific interval, given they survived up to that point. This transforms the complex censored survival problem into a series of easier-to-model conditional probabilities: P(event in interval j | survived to interval j). The beauty of this approach is that it allows us to use any standard binary classification algorithm (logistic regression, random forests, gradient boosting, neural networks) while properly handling censored data through the data expansion process.
                    </div>
                </div>

                <div class="diagram-container">
                    <div class="diagram-title">‚è±Ô∏è Discrete Time Framework: From Continuous to Intervals</div>
                    <svg width="1100" height="500" viewBox="0 0 1100 500">
                        <!-- Continuous timeline -->
                        <g transform="translate(50,30)">
                            <rect x="0" y="0" width="1000" height="80" fill="#f8fbff" stroke="#1E64C8" stroke-width="3" rx="8"/>
                            <text x="500" y="25" text-anchor="middle" font-size="16" font-weight="700" fill="#1E64C8">Continuous Time (Original Data)</text>
                            
                            <line x1="50" y1="55" x2="950" y2="55" stroke="#333" stroke-width="3"/>
                            <text x="50" y="75" text-anchor="middle" font-size="12" fill="#666" font-weight="600">0</text>
                            <text x="950" y="75" text-anchor="middle" font-size="12" fill="#666" font-weight="600">T_max</text>
                            
                            <!-- Example events -->
                            <circle cx="220" cy="55" r="6" fill="#e74c3c"/>
                            <text x="220" y="40" text-anchor="middle" font-size="11" fill="#e74c3c" font-weight="600">Event</text>
                            <text x="220" y="98" text-anchor="middle" font-size="10" fill="#666">t=2.3</text>
                            
                            <circle cx="500" cy="55" r="6" fill="#28a745"/>
                            <text x="500" y="40" text-anchor="middle" font-size="11" fill="#28a745" font-weight="600">Censored</text>
                            <text x="500" y="98" text-anchor="middle" font-size="10" fill="#666">t=5.1</text>
                            
                            <circle cx="760" cy="55" r="6" fill="#e74c3c"/>
                            <text x="760" y="40" text-anchor="middle" font-size="11" fill="#e74c3c" font-weight="600">Event</text>
                            <text x="760" y="98" text-anchor="middle" font-size="10" fill="#666">t=8.7</text>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 550,125 L 550,155" stroke="#1E64C8" stroke-width="4" marker-end="url(#arrow4)"/>
                        <text x="590" y="142" font-size="14" fill="#1E64C8" font-weight="700">Discretize into intervals</text>
                        
                        <!-- Discrete intervals -->
                        <g transform="translate(50,165)">
                            <rect x="0" y="0" width="1000" height="130" fill="#f8fbff" stroke="#1E64C8" stroke-width="3" rx="8"/>
                            <text x="500" y="25" text-anchor="middle" font-size="16" font-weight="700" fill="#1E64C8">Discrete Time Intervals</text>
                            
                            <line x1="50" y1="70" x2="950" y2="70" stroke="#333" stroke-width="3"/>
                            
                            <!-- Interval 1 -->
                            <rect x="50" y="52" width="175" height="36" fill="#1E64C8" opacity="0.2" stroke="#1E64C8" stroke-width="2"/>
                            <text x="137" y="75" text-anchor="middle" font-size="16" fill="#1E64C8" font-weight="700">Interval 1</text>
                            <text x="137" y="110" text-anchor="middle" font-size="12" fill="#666">[0, 2)</text>
                            
                            <!-- Interval 2 -->
                            <rect x="225" y="52" width="175" height="36" fill="#1E64C8" opacity="0.2" stroke="#1E64C8" stroke-width="2"/>
                            <text x="312" y="75" text-anchor="middle" font-size="16" fill="#1E64C8" font-weight="700">Interval 2</text>
                            <text x="312" y="110" text-anchor="middle" font-size="12" fill="#666">[2, 4)</text>
                            
                            <!-- Interval 3 -->
                            <rect x="400" y="52" width="175" height="36" fill="#1E64C8" opacity="0.2" stroke="#1E64C8" stroke-width="2"/>
                            <text x="487" y="75" text-anchor="middle" font-size="16" fill="#1E64C8" font-weight="700">Interval 3</text>
                            <text x="487" y="110" text-anchor="middle" font-size="12" fill="#666">[4, 6)</text>
                            
                            <!-- Interval 4 -->
                            <rect x="575" y="52" width="175" height="36" fill="#1E64C8" opacity="0.2" stroke="#1E64C8" stroke-width="2"/>
                            <text x="662" y="75" text-anchor="middle" font-size="16" fill="#1E64C8" font-weight="700">Interval 4</text>
                            <text x="662" y="110" text-anchor="middle" font-size="12" fill="#666">[6, 8)</text>
                            
                            <!-- Interval 5+ -->
                            <rect x="750" y="52" width="200" height="36" fill="#1E64C8" opacity="0.2" stroke="#1E64C8" stroke-width="2"/>
                            <text x="850" y="75" text-anchor="middle" font-size="16" fill="#1E64C8" font-weight="700">Interval 5</text>
                            <text x="850" y="110" text-anchor="middle" font-size="12" fill="#666">[8, ‚àû)</text>
                        </g>
                        
                        <!-- Arrow -->
                        <path d="M 550,310 L 550,340" stroke="#1E64C8" stroke-width="4" marker-end="url(#arrow4)"/>
                        <text x="590" y="327" font-size="14" fill="#1E64C8" font-weight="700">Expand dataset</text>
                        
                        <!-- Expanded data table -->
                        <g transform="translate(80,350)">
                            <rect x="0" y="0" width="940" height="140" fill="#fff3cd" stroke="#ffc107" stroke-width="3" rx="8"/>
                            <text x="470" y="25" text-anchor="middle" font-size="16" font-weight="700" fill="#856404">Expanded Dataset for Binary Classification</text>
                            
                            <!-- Table -->
                            <g transform="translate(30,45)">
                                <!-- Header row -->
                                <rect x="0" y="0" width="880" height="25" fill="#ffc107" opacity="0.3"/>
                                <text x="40" y="17" font-size="13" font-weight="700" fill="#333">Patient</text>
                                <text x="140" y="17" font-size="13" font-weight="700" fill="#333">Covariates</text>
                                <text x="280" y="17" font-size="13" font-weight="700" fill="#333">Interval</text>
                                <text x="400" y="17" font-size="13" font-weight="700" fill="#333">Start Time</text>
                                <text x="540" y="17" font-size="13" font-weight="700" fill="#333">End Time</text>
                                <text x="680" y="17" font-size="13" font-weight="700" fill="#333">Event in Interval</text>
                                
                                <!-- Patient A (event in interval 2) -->
                                <rect x="0" y="25" width="880" height="18" fill="white" opacity="0.8"/>
                                <text x="40" y="38" font-size="12" fill="#333">A</text>
                                <text x="140" y="38" font-size="11" fill="#666">x‚ÇÅ, x‚ÇÇ, ...</text>
                                <text x="280" y="38" font-size="12" fill="#1E64C8" font-weight="600">1</text>
                                <text x="400" y="38" font-size="12" fill="#666">0</text>
                                <text x="540" y="38" font-size="12" fill="#666">2</text>
                                <text x="680" y="38" font-size="12" fill="#28a745" font-weight="700">0 (survived)</text>
                                
                                <rect x="0" y="43" width="880" height="18" fill="#f8fbff"/>
                                <text x="40" y="56" font-size="12" fill="#333">A</text>
                                <text x="140" y="56" font-size="11" fill="#666">x‚ÇÅ, x‚ÇÇ, ...</text>
                                <text x="280" y="56" font-size="12" fill="#1E64C8" font-weight="600">2</text>
                                <text x="400" y="56" font-size="12" fill="#666">2</text>
                                <text x="540" y="56" font-size="12" fill="#666">4</text>
                                <text x="680" y="56" font-size="12" fill="#e74c3c" font-weight="700">1 (event)</text>
                                
                                <!-- Patient B (censored in interval 3) -->
                                <rect x="0" y="61" width="880" height="18" fill="white" opacity="0.8"/>
                                <text x="40" y="74" font-size="12" fill="#333">B</text>
                                <text x="140" y="74" font-size="11" fill="#666">x‚ÇÅ, x‚ÇÇ, ...</text>
                                <text x="280" y="74" font-size="12" fill="#1E64C8" font-weight="600">1</text>
                                <text x="400" y="74" font-size="12" fill="#666">0</text>
                                <text x="540" y="74" font-size="12" fill="#666">2</text>
                                <text x="680" y="74" font-size="12" fill="#28a745" font-weight="700">0 (survived)</text>
                                
                                <rect x="0" y="79" width="880" height="18" fill="#f8fbff"/>
                                <text x="40" y="92" font-size="12" fill="#333">B</text>
                                <text x="140" y="92" font-size="11" fill="#666">x‚ÇÅ, x‚ÇÇ, ...</text>
                                <text x="280" y="92" font-size="12" fill="#1E64C8" font-weight="600">2</text>
                                <text x="400" y="92" font-size="12" fill="#666">2</text>
                                <text x="540" y="92" font-size="12" fill="#666">4</text>
                                <text x="680" y="92" font-size="12" fill="#28a745" font-weight="700">0 (survived)</text>
                                
                                <text x="440" y="110" text-anchor="middle" font-size="11" fill="#666" font-style="italic">Each patient contributes one row per interval until event or censoring occurs</text>
                            </g>
                        </g>
                        
                        <defs>
                            <marker id="arrow4" markerWidth="12" markerHeight="12" refX="10" refY="4" orient="auto">
                                <path d="M0,0 L0,8 L12,4 z" fill="#1E64C8"/>
                            </marker>
                        </defs>
                    </svg>
                    <div class="diagram-caption">
                        Transformation from continuous survival data to discrete time format. Continuous timeline is divided into intervals, and the dataset is expanded so each patient contributes one observation per interval they are at risk. Binary outcome indicates whether event occurred in that interval.
                    </div>
                </div>


                <div class="subsection">
                    <div class="subsection-title">Mathematical Framework</div>
                    <div class="subsection-content">
                        The discrete time model estimates the <strong>discrete hazard</strong> Œª‚±º(X) for each interval j:
                    </div>
                    
                    <div class="math-box">Discrete Hazard (probability of event in interval j):

Œª‚±º(X) = P(T = t‚±º | T ‚â• t‚±º, X)

This is the conditional probability that an individual with covariates X
experiences the event in interval j, given they survived until the start
of that interval.

We model this using logistic regression:

logit[Œª‚±º(X)] = log[Œª‚±º(X) / (1 - Œª‚±º(X))] = Œ±‚ÇÄ‚±º + Œ≤‚ÇÅX‚ÇÅ + Œ≤‚ÇÇX‚ÇÇ + ... + Œ≤‚ÇöX‚Çö

where:
  ‚Ä¢ Œ±‚ÇÄ‚±º = baseline log-odds for interval j (interval-specific intercept)
  ‚Ä¢ Œ≤ = covariate effects (shared across all intervals by default)
  ‚Ä¢ Can allow time-varying effects: Œ≤‚±º different for each interval

Survival function at time t‚±º:

S(t‚±º|X) = P(T > t‚±º|X) = ‚àè·µ¢‚Çå‚ÇÅ ≤ [1 - Œª·µ¢(X)]

This is the product of surviving each interval from 1 to j.

Probability of event in interval j:

P(T = t‚±º|X) = Œª‚±º(X) √ó S(t‚±º‚Çã‚ÇÅ|X) = Œª‚±º(X) √ó ‚àè·µ¢‚Çå‚ÇÅ ≤‚Åª¬π [1 - Œª·µ¢(X)]</div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Key Features & Advantages</div>
                    <div class="feature-grid">
                        <div class="feature-box">
                            <div class="feature-box-title">üéØ Simplicity & Flexibility</div>
                            <div class="feature-box-content">
                                Converts survival analysis into standard binary classification. Can use ANY classification algorithm: logistic regression, random forests, gradient boosting, neural networks, SVM. No specialized survival software needed.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">‚è±Ô∏è Time-varying Effects</div>
                            <div class="feature-box-content">
                                Easily model non-proportional hazards by allowing covariate effects to vary across intervals. Include interval indicators or interval √ó covariate interactions.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üìä Interpretable Probabilities</div>
                            <div class="feature-box-content">
                                Direct probability predictions for each interval. Easy to communicate: "30% chance of event in next 6 months given survival so far." More intuitive than hazard ratios for some audiences.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üîß Easy Implementation</div>
                            <div class="feature-box-content">
                                Simple data preparation (expand to person-period format). Standard ML libraries (scikit-learn, XGBoost) work directly. Mature ecosystem of tools and techniques.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">üìà Handles Competing Risks</div>
                            <div class="feature-box-content">
                                Naturally extends to competing risks by using multinomial classification instead of binary. Can model multiple event types simultaneously with separate probabilities.
                            </div>
                        </div>
                        <div class="feature-box">
                            <div class="feature-box-title">‚ö° Computational Efficiency</div>
                            <div class="feature-box-content">
                                Training is typically faster than RSF or DeepSurv. Standard optimized libraries. Predictions are very fast: just evaluate classifier for each interval.
                            </div>
                        </div>
                    </div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Implementation Steps</div>
                    <div class="subsection-content">
                        <strong>Step-by-step guide to implementing discrete time models:</strong>
                    </div>
                    
                    <ul>
                        <li><strong>Step 1 - Define Intervals:</strong> Choose interval boundaries based on domain knowledge or data distribution. Options: equal width (e.g., every 6 months), equal frequency (quantiles of event times), or clinically meaningful periods.</li>
                        
                        <li><strong>Step 2 - Expand Dataset:</strong> Transform data to person-period format. Each individual contributes one row per interval they are at risk. Include covariates and interval identifier for each row.</li>
                        
                        <li><strong>Step 3 - Create Binary Outcome:</strong> For each row, outcome = 1 if event occurred in that interval, 0 if individual survived the interval. Exclude rows after event or censoring.</li>
                        
                        <li><strong>Step 4 - Add Interval Indicators:</strong> Include dummy variables or numeric indicators for each interval. This allows baseline hazard to vary across time. Can use one-hot encoding or ordinal encoding.</li>
                        
                        <li><strong>Step 5 - Fit Classification Model:</strong> Train any binary classifier on expanded dataset. Logistic regression for interpretability, tree-based methods for flexibility, neural networks for complex patterns.</li>
                        
                        <li><strong>Step 6 - Predict Survival Curves:</strong> For new individual, predict probability for each interval sequentially. Multiply survival probabilities: S(t‚±º) = ‚àè·µ¢‚Çå‚ÇÅ ≤ (1 - PÃÇ·µ¢) where PÃÇ·µ¢ is predicted probability for interval i.</li>
                        
                        <li><strong>Step 7 - Model Evaluation:</strong> Use time-dependent C-index, Brier score, or calibration plots. Can evaluate within specific intervals or overall. Assess calibration by comparing predicted vs. observed event rates.</li>
                    </ul>
                </div>

                <div class="highlight-box">
                    <div class="highlight-box-title">‚öôÔ∏è Design Choices & Considerations</div>
                    <div class="highlight-box-content">
                        <strong>Interval Selection:</strong> Too few intervals = loss of temporal resolution. Too many intervals = sparse data per interval, increased variance. Typical: 5-20 intervals. Use event distribution to guide choice.<br><br>
                        
                        <strong>Handling Ties:</strong> Multiple events at same time are naturally handled since they fall in same interval. Unlike Cox models which require special handling.<br><br>
                        
                        <strong>Time-varying Covariates:</strong> Easy to incorporate! Just include time-updated covariate values in each row. Example: treatment changes, lab values, biomarker levels.<br><br>
                        
                        <strong>Class Imbalance:</strong> Typically few events per interval = imbalanced classes. Use: class weights, SMOTE, focal loss, or stratified sampling to address.<br><br>
                        
                        <strong>Interval Effects:</strong> Shared effects (Œ≤ constant) assumes proportional odds. Time-varying effects (Œ≤‚±º) allows non-proportional hazards. Trade-off: flexibility vs. overfitting.
                    </div>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Practical Example & Code</div>
                    
                    <div class="math-box"># Python implementation with pandas and scikit-learn
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from lifelines.utils import concordance_index

def create_person_period(df, time_col, event_col, interval_breaks):
    """
    Expand survival data to person-period format
    
    Parameters:
    -----------
    df : DataFrame with survival data
    time_col : name of time column
    event_col : name of event indicator column (1=event, 0=censored)
    interval_breaks : list of interval boundaries [0, 2, 4, 6, 8, inf]
    
    Returns:
    --------
    Expanded DataFrame in person-period format
    """
    expanded_rows = []
    
    for idx, row in df.iterrows():
        time = row[time_col]
        event = row[event_col]
        
        # Determine which interval the event/censoring falls in
        interval_idx = np.searchsorted(interval_breaks, time, side='right') - 1
        
        # Create row for each interval up to event/censoring
        for j in range(interval_idx + 1):
            new_row = row.copy()
            new_row['interval'] = j
            new_row['interval_start'] = interval_breaks[j]
            new_row['interval_end'] = interval_breaks[j+1]
            
            # Event indicator for this interval
            if j < interval_idx:
                new_row['event_in_interval'] = 0  # Survived this interval
            else:
                new_row['event_in_interval'] = event  # Event or censored
            
            expanded_rows.append(new_row)
    
    return pd.DataFrame(expanded_rows)

# Example usage
# Original data
survival_data = pd.DataFrame({
    'time': [2.3, 5.1, 8.7, 3.2, 6.8],
    'event': [1, 0, 1, 1, 0],
    'age': [65, 72, 58, 61, 69],
    'treatment': ['A', 'B', 'A', 'B', 'A'],
    'biomarker': [2.3, 1.8, 3.1, 2.5, 1.9]
})

# Define intervals
interval_breaks = [0, 2, 4, 6, 8, np.inf]

# Expand to person-period format
pp_data = create_person_period(
    survival_data, 'time', 'event', interval_breaks
)

# Prepare features
# One-hot encode categorical variables
pp_data = pd.get_dummies(pp_data, columns=['treatment'])

# Create interval dummy variables (baseline hazard)
pp_data = pd.get_dummies(pp_data, columns=['interval'], prefix='int')

# Select features for modeling
feature_cols = ['age', 'biomarker', 'treatment_A', 'treatment_B',
                'int_0', 'int_1', 'int_2', 'int_3', 'int_4']
X = pp_data[feature_cols]
y = pp_data['event_in_interval']

# Fit logistic regression (or any classifier)
model = LogisticRegression(class_weight='balanced', max_iter=1000)
# Alternative: Gradient Boosting for non-linear relationships
# model = GradientBoostingClassifier(n_estimators=100)

model.fit(X, y)

# Predict survival curve for new patient
def predict_survival_curve(model, patient_data, interval_breaks):
    """Predict survival probability for each interval"""
    n_intervals = len(interval_breaks) - 1
    survival_probs = []
    survival_cum = 1.0
    
    for j in range(n_intervals):
        # Create features for interval j
        patient_data['interval'] = j
        patient_data_encoded = pd.get_dummies(
            patient_data, columns=['interval'], prefix='int'
        )
        
        # Predict probability of event in interval j
        prob_event = model.predict_proba(
            patient_data_encoded[feature_cols]
        )[0, 1]
        
        # Update cumulative survival
        survival_cum *= (1 - prob_event)
        survival_probs.append(survival_cum)
    
    return np.array(survival_probs)

# Predict for new patient
new_patient = pd.DataFrame({
    'age': [60],
    'biomarker': [2.0],
    'treatment': ['A']
})

surv_curve = predict_survival_curve(
    model, new_patient, interval_breaks
)

print("Survival probabilities by interval:", surv_curve)</div>
                </div>

                <div class="info-box">
                    <div class="info-box-title">üìö When to Use Discrete Time Models</div>
                    <div class="info-box-content">
                        <strong>Ideal scenarios:</strong><br>
                        ‚Ä¢ Time naturally discrete (monthly follow-ups, yearly events)<br>
                        ‚Ä¢ Want to use standard ML libraries and tools<br>
                        ‚Ä¢ Need time-varying covariate effects<br>
                        ‚Ä¢ Prefer probability interpretations over hazards<br>
                        ‚Ä¢ Have competing risks to model<br>
                        ‚Ä¢ Want fast training and simple implementation<br>
                        ‚Ä¢ Team familiar with classification but not survival analysis<br><br>
                        
                        <strong>Less ideal for:</strong><br>
                        ‚Ä¢ Precisely measured continuous time is critical<br>
                        ‚Ä¢ Need smooth hazard function estimates<br>
                        ‚Ä¢ Very fine time resolution required<br>
                        ‚Ä¢ Small sample size with many intervals (overfitting risk)<br>
                        ‚Ä¢ Strong preference for proportional hazards framework<br>
                        ‚Ä¢ Want traditional hazard ratio interpretations
                    </div>
                </div>

            </div>
        </div>

        <!-- Comparison Section -->
        <div id="comparison" class="detailed-section">
            <div class="section-header">
                <div class="section-number">SECTION 5</div>
                <div class="section-title">Method Comparison & Selection Guide</div>
            </div>
            <div class="section-content">
                
                <div class="subsection">
                    <div class="subsection-title">Comprehensive Comparison Table</div>
                    
                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Aspect</th>
                                <th>Random Survival Forests</th>
                                <th>DeepSurv</th>
                                <th>Discrete Time Models</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Core Approach</strong></td>
                                <td>Ensemble of survival trees with bootstrap aggregation</td>
                                <td>Deep neural network with Cox loss</td>
                                <td>Sequential binary classification per interval</td>
                            </tr>
                            <tr>
                                <td><strong>Assumptions</strong></td>
                                <td>None (fully non-parametric)</td>
                                <td>Proportional hazards (like Cox)</td>
                                <td>Proportional odds (can relax with interactions)</td>
                            </tr>
                            <tr>
                                <td><strong>Handles Non-linearity</strong></td>
                                <td>‚úÖ Excellent (tree splits)</td>
                                <td>‚úÖ Excellent (deep layers)</td>
                                <td>‚úÖ Good (depends on classifier choice)</td>
                            </tr>
                            <tr>
                                <td><strong>Feature Interactions</strong></td>
                                <td>‚úÖ Automatic (implicit in trees)</td>
                                <td>‚úÖ Automatic (hidden layers)</td>
                                <td>‚ö†Ô∏è Manual specification often needed</td>
                            </tr>
                            <tr>
                                <td><strong>High-dimensional Data (p >> n)</strong></td>
                                <td>‚úÖ Good (random feature selection)</td>
                                <td>‚úÖ Excellent (designed for this)</td>
                                <td>‚ö†Ô∏è Moderate (needs regularization)</td>
                            </tr>
                            <tr>
                                <td><strong>Sample Size Required</strong></td>
                                <td>Moderate (n > 100 preferable)</td>
                                <td>Large (n > 500 ideal)</td>
                                <td>Small-Moderate (n > 50 often sufficient)</td>
                            </tr>
                            <tr>
                                <td><strong>Missing Data Handling</strong></td>
                                <td>‚úÖ Native support (surrogate splits)</td>
                                <td>‚ùå Requires imputation</td>
                                <td>‚ùå Requires imputation</td>
                            </tr>
                            <tr>
                                <td><strong>Interpretability</strong></td>
                                <td>‚ö†Ô∏è Variable importance, partial dependence</td>
                                <td>‚ùå Black box (can use SHAP/LIME)</td>
                                <td>‚úÖ Good (especially with logistic regression)</td>
                            </tr>
                            <tr>
                                <td><strong>Training Time</strong></td>
                                <td>Moderate (parallelizable)</td>
                                <td>Long (GPU helps significantly)</td>
                                <td>Fast (standard classification)</td>
                            </tr>
                            <tr>
                                <td><strong>Prediction Speed</strong></td>
                                <td>Fast</td>
                                <td>Very fast (once trained)</td>
                                <td>Very fast</td>
                            </tr>
                            <tr>
                                <td><strong>Implementation Complexity</strong></td>
                                <td>Low (good packages available)</td>
                                <td>Moderate-High (need DL framework)</td>
                                <td>Low (standard ML tools)</td>
                            </tr>
                            <tr>
                                <td><strong>Time-varying Effects</strong></td>
                                <td>‚ö†Ô∏è Possible but complex</td>
                                <td>‚ö†Ô∏è Requires architecture changes</td>
                                <td>‚úÖ Easy (interval √ó covariate interactions)</td>
                            </tr>
                            <tr>
                                <td><strong>Best For</strong></td>
                                <td>Moderate data, need variable importance, non-linear patterns</td>
                                <td>Large datasets, genomics, complex non-linearity, deep patterns</td>
                                <td>Discrete time, simple implementation, time-varying effects</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <div class="subsection">
                    <div class="subsection-title">Decision Flowchart</div>
                    <div class="subsection-content">
                        When choosing a method, consider these key questions:
                    </div>
                    
                    <ul>
                        <li><strong>Q1: What is your sample size?</strong>
                            <ul>
                                <li>Small (n < 100): Discrete Time Models or traditional Cox</li>
                                <li>Moderate (100 < n < 500): Random Survival Forests</li>
                                <li>Large (n > 500): DeepSurv becomes viable</li>
                            </ul>
                        </li>
                        
                        <li><strong>Q2: How many features do you have relative to sample size?</strong>
                            <ul>
                                <li>p >> n (high-dimensional): DeepSurv or RSF with feature selection</li>
                                <li>p < n (low-dimensional): Any method works</li>
                            </ul>
                        </li>
                        
                        <li><strong>Q3: Do you suspect strong non-linear relationships?</strong>
                            <ul>
                                <li>Yes: RSF or DeepSurv</li>
                                <li>No/Uncertain: Start with Discrete Time + Logistic Regression</li>
                            </ul>
                        </li>
                        
                        <li><strong>Q4: How important is interpretability?</strong>
                            <ul>
                                <li>Critical: Discrete Time with Logistic Regression</li>
                                <li>Moderate: RSF (variable importance available)</li>
                                <li>Not critical: DeepSurv (focus on prediction)</li>
                            </ul>
                        </li>
                        
                        <li><strong>Q5: Do you need to model time-varying effects?</strong>
                            <ul>
                                <li>Yes: Discrete Time Models (easiest)</li>
                                <li>No: Any method works</li>
                            </ul>
                        </li>
                        
                        <li><strong>Q6: What computational resources do you have?</strong>
                            <ul>
                                <li>Limited: Discrete Time Models (fastest)</li>
                                <li>Moderate: RSF (parallelizable)</li>
                                <li>Substantial (GPU access): DeepSurv</li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <div class="highlight-box">
                    <div class="highlight-box-title">üí° Practical Recommendations</div>
                    <div class="highlight-box-content">
                        <strong>For most applications, start with Random Survival Forests:</strong> Good balance of performance, interpretability, and ease of use. Handles non-linearity well and provides variable importance.<br><br>
                        
                        <strong>Use DeepSurv when you have:</strong> Very large sample size (n > 1000), high-dimensional features (genomics, images), or complex non-linear patterns that RSF doesn't capture well.<br><br>
                        
                        <strong>Choose Discrete Time Models when:</strong> Time is naturally discrete, you need simple implementation with standard tools, or you want to model time-varying covariate effects easily.<br><br>
                        
                        <strong>Best practice: Try multiple methods!</strong> Use cross-validation to compare C-index, calibration, and Brier scores. The "best" method is dataset-specific. Ensemble predictions from multiple methods often works best.
                    </div>
                </div>

            </div>
        </div>

        <!-- Summary -->
        <div class="summary-section">
            <div class="summary-title">üéØ Key Takeaways</div>
            <ul style="font-size:17px; line-height:2; color:#333;">
                <li><strong>Random Survival Forests</strong> offer robust, non-parametric predictions with automatic variable importance. Great default choice for moderate-sized datasets.</li>
                
                <li><strong>DeepSurv</strong> leverages deep learning to capture highly complex patterns in high-dimensional data. Best for large samples and genomic/imaging applications.</li>
                
                <li><strong>Discrete Time Models</strong> simplify survival analysis to binary classification, enabling use of any ML algorithm. Ideal for discrete time and time-varying effects.</li>
                
                <li><strong>No universally "best" method</strong> exists. Choice depends on: sample size, dimensionality, interpretability needs, computational resources, and domain requirements.</li>
                
                <li><strong>Evaluation is critical:</strong> Use time-dependent C-index, calibration plots, and Brier scores. Validate on held-out data or via cross-validation.</li>
                
                <li><strong>Consider ensembles:</strong> Combining predictions from multiple methods often improves performance and robustness.</li>
            </ul>
        </div>

    </div>
</body>
</html>